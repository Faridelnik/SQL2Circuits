{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90e91ad4-1678-49ef-98b5-138506d3f71b",
   "metadata": {},
   "source": [
    "# Circuit learning module: Pennylane with SPSA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a844d57-1aa2-4424-93c7-f5057dfdd233",
   "metadata": {},
   "source": [
    "This code is inspired by [Quanthoven](https://github.com/CQCL/Quanthoven/blob/main/experiment.ipynb) and [Pennylane demo](https://pennylane.ai/qml/demos/spsa.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "caf53928-c1ab-4797-af22-b9f6a6aa1326",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import warnings\n",
    "import collections\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pickle\n",
    "import pennylane as qml\n",
    "from sympy import default_sort_key\n",
    "import torch\n",
    "from discopy.quantum.pennylane import to_pennylane, PennyLaneCircuit\n",
    "from inspect import signature\n",
    "from noisyopt import minimizeSPSA\n",
    "from utils import transform_into_pennylane_circuits, read_diagrams, get_symbols, create_labeled_classes, multi_class_loss\n",
    "\n",
    "this_folder = os.path.abspath(os.getcwd())\n",
    "nshot = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38c185b2-c392-4067-bfa9-68feaae9ca09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def genbin(n, bs=''):\n",
    "    if len(bs) == n:\n",
    "        return bs\n",
    "    else:\n",
    "        return np.array([genbin(n, bs + '0'), genbin(n, bs + '1')]).flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "125bf2c8-31c0-475c-b1da-83da76fae4cb",
   "metadata": {},
   "source": [
    "## Read circuit data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e190199-b144-47da-b296-771a0118a66e",
   "metadata": {},
   "source": [
    "We read the circuits from the pickled files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ccec433e-daee-4404-a3b0-a8cd629d9c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select workload\n",
    "#workload = \"execution_time\"\n",
    "workload = \"cardinality\"\n",
    "\n",
    "# Select workload size\n",
    "#workload_size = \"small\"\n",
    "#workload_size = \"medium\"\n",
    "#workload_size = \"large\"\n",
    "workload_size = \"main\"\n",
    "\n",
    "classification = 2\n",
    "layers = 1\n",
    "single_qubit_params = 3\n",
    "n_wire_count = 1\n",
    "\n",
    "# Access the selected circuits\n",
    "path_name = this_folder + \"//simplified-JOB-diagrams//\"\\\n",
    "            + workload + \"//\" + workload_size + \"//circuits//\"\\\n",
    "            + str(classification) + \"//\" + str(layers) + \"_layer//\"\\\n",
    "           + str(single_qubit_params) + \"_single_qubit_params//\" + str(n_wire_count)\\\n",
    "            + \"_n_wire_count//\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "508f9dd1-fea9-47cc-a916-92a98ed9ef0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_circuits_paths = glob.glob(path_name + \"training//[0-9]*.p\")\n",
    "validation_circuits_paths = glob.glob(path_name + \"validation//[0-9]*.p\")\n",
    "test_circuits_paths = glob.glob(path_name + \"test//[0-9]*.p\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf3f48df-bc14-4fd0-a56f-88d794e9856f",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_circuits = read_diagrams(training_circuits_paths)\n",
    "validation_circuits = read_diagrams(validation_circuits_paths)\n",
    "test_circuits = read_diagrams(test_circuits_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1459ed37-5054-4542-ab59-39896edd9b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_qubits = 15\n",
    "dev = qml.device(\"lightning.qubit\", wires=n_qubits, shots=nshot)\n",
    "\n",
    "qml_training_circuits, train_symbols = transform_into_pennylane_circuits(training_circuits, n_qubits, dev)\n",
    "qml_test_circuits, test_symbols = transform_into_pennylane_circuits(test_circuits, n_qubits, dev)\n",
    "qml_validation_circuits, val_symbols = transform_into_pennylane_circuits(validation_circuits, n_qubits, dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2487a768-6603-4037-a765-23f50cb53fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training_qnodes = qml.QNodeCollection([c[\"qml_circuit\"] for c in qml_training_circuits.values()])\n",
    "#validation_qnodes = qml.QNodeCollection([c[\"qml_circuit\"] for c in qml_validation_circuits.values()])\n",
    "#test_qnodes = qml.QNodeCollection([c[\"qml_circuit\"] for c in qml_test_circuits.values()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "421b5bed-c0ae-4eea-8215-bef4d711d014",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training circuits:  448\n",
      "Number of validation circuits:  113\n",
      "Number of test circuits:  112\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of training circuits: \", len(qml_training_circuits))\n",
    "print(\"Number of validation circuits: \", len(qml_validation_circuits))\n",
    "print(\"Number of test circuits: \", len(qml_test_circuits))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "710f034f-9b35-4254-afe6-d91784a3f941",
   "metadata": {},
   "source": [
    "## Read training and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c0b3e68e-73e6-460c-93a1-0e4a44af926d",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data, test_data, validation_data = None, None, None\n",
    "data_path = this_folder + \"//data//\" + workload + \"//\" + workload_size + \"//\"\n",
    "\n",
    "with open(data_path + \"training_data.json\", \"r\") as inputfile:\n",
    "    training_data = json.load(inputfile)['training_data']\n",
    "with open(data_path + \"test_data.json\", \"r\") as inputfile:\n",
    "    test_data = json.load(inputfile)['test_data']\n",
    "with open(data_path + \"validation_data.json\", \"r\") as inputfile:\n",
    "    validation_data = json.load(inputfile)['validation_data']\n",
    "\n",
    "training_data_labels = create_labeled_classes(training_data, classification, workload)\n",
    "test_data_labels = create_labeled_classes(test_data, classification, workload)\n",
    "validation_data_labels = create_labeled_classes(validation_data, classification, workload)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e39dcd08-662f-48b7-8ba8-d60165103c57",
   "metadata": {},
   "source": [
    "## Post-selection"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c6600c29-d643-4f82-a52e-fe62a3ee3cf8",
   "metadata": {},
   "source": [
    "def post_select_shot(shot, post_selection):\n",
    "    diff = len(shot) - len(post_selection)\n",
    "    for i in range(len(post_selection)):\n",
    "        if shot[i + diff] != post_selection[i]:\n",
    "            return []\n",
    "    else:\n",
    "        return shot\n",
    "    \n",
    "def post_select_circuit_samples(circuit_samples):\n",
    "    selected_samples = []\n",
    "    for circuit_sample in circuit_samples:\n",
    "        selected = []\n",
    "        for shot in circuit_sample:\n",
    "            post_selected = post_select_shot(shot, [0]*(len(shot) - 1))\n",
    "            if len(post_selected) > 0:\n",
    "                if post_selected[0] == 0:\n",
    "                    selected.append([1, 0])\n",
    "                else:\n",
    "                    selected.append([0, 1])\n",
    "        selected_samples.append(selected)\n",
    "    return selected_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d4753403-0692-49c1-992a-2223dc2837c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_select_circuit_samples(circuit_samples, n_qubits, post_selection):\n",
    "    selected_samples = []\n",
    "    post_select_array = np.array([0]*(n_qubits - post_selection))\n",
    "    for circuit_sample in circuit_samples:\n",
    "        if np.array_equal(circuit_sample[post_selection - 1 :-1], post_select_array):\n",
    "            res = circuit_sample[0:post_selection]\n",
    "            selected_samples.append(res)\n",
    "            #if circuit_sample[0] == 1:\n",
    "            #    selected_samples.append(1)\n",
    "            #else:\n",
    "            #    selected_samples.append(0)\n",
    "    return selected_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c259f7cb-2a2c-4e3a-a8f8-6f79152b4b20",
   "metadata": {},
   "source": [
    "## Cost function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7725dcd8-5461-4517-af83-1772bd55d9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_pred_fn(circuits):\n",
    "    def predict(params):\n",
    "        outputs = Circuit.eval(*(c(*params) for c in circuit_fns), backend = backend)\n",
    "        res = []\n",
    "        \n",
    "        for output in outputs:\n",
    "            predictions = np.abs(output.array) + 1e-9\n",
    "            ratio = predictions / predictions.sum()\n",
    "            res.append(ratio)\n",
    "            \n",
    "        return np.array(res)\n",
    "    return predict"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5fc25341-5eff-4998-9bb0-a6204359912b",
   "metadata": {},
   "source": [
    "#rng = np.random.default_rng(0)\n",
    "#init_params_spsa = np.array(rng.random(len(symbols)))\n",
    "#cost_spsa(init_params_spsa)\n",
    "\n",
    "def most_common(lst):\n",
    "    counts = {}\n",
    "    for e in lst:\n",
    "        if tuple(e) in counts:\n",
    "            counts[tuple(e)] += 1\n",
    "        else:\n",
    "            counts[tuple(e)] = 1\n",
    "    return [counts[(1,0)]/len(lst), counts[(0,1)]/len(lst)] \n",
    "\n",
    "#rng = np.random.default_rng(SEED)\n",
    "#init_params_spsa = np.array(rng.random(len(symbols)))\n",
    "#circuit_samples = training_qnodes(init_params_spsa)\n",
    "#predictions = post_select_circuit_samples(circuit_samples)\n",
    "#print(predictions[0])\n",
    "#print(most_common(predictions[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8437abb6-ef4e-478e-8dc4-b2254339b6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def acc_from_dict(dict_predictions, dict_labels):\n",
    "    total_acc = 0\n",
    "    for query_id in dict_predictions:\n",
    "        y_meas = np.array(dict_predictions[query_id]).flatten()\n",
    "        max_index = np.argmax(y_meas)\n",
    "        total_acc += int(int(dict_labels[query_id][max_index]) == 1)\n",
    "    return total_acc / len(dict_predictions)\n",
    "\n",
    "\n",
    "def loss_from_dict(dict_predictions, dict_labels):\n",
    "    total_loss = 0\n",
    "    for query_id in dict_predictions:\n",
    "        x = np.array(dict_labels[query_id])\n",
    "        y_pred = np.array(dict_predictions[query_id]).flatten()\n",
    "        #print(x, y_pred)\n",
    "        total_loss += -np.sum(x * np.log(y_pred)) / len(x)\n",
    "        #print(total_loss)\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e35e93ae-ee26-437b-83ba-93e3315d2efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_cost_fn(qnodes, labels):    \n",
    "    def cost_spsa(params, **kwargs):\n",
    "        predictions = {}\n",
    "        for i, q in enumerate(qnodes):\n",
    "            circuit = qnodes[q][\"qml_circuit\"]\n",
    "            measurement = circuit(params)\n",
    "            post_selected_samples = post_select_circuit_samples(measurement, n_qubits, 2)\n",
    "            post_selected_samples = [tuple(map(int, t)) for t in post_selected_samples]\n",
    "            #print(post_selected_samples)\n",
    "            counts = collections.Counter(post_selected_samples)\n",
    "            res = []\n",
    "            for s in genbin(classification):\n",
    "                t = tuple(map(int, s))\n",
    "                #print(t, counts)\n",
    "                if t in counts:\n",
    "                    #print(counts[t]/len(post_selected_samples))\n",
    "                    res.append(counts[t]/len(post_selected_samples))\n",
    "                else:\n",
    "                    res.append(1e-9)\n",
    "            predictions[q] = res\n",
    "            #if i == 4:\n",
    "            #    break\n",
    "        #print(predictions)\n",
    "        cost = loss_from_dict(predictions, labels) #-np.sum(labels * np.log(predictions)) / len(labels)  # binary cross-entropy loss\n",
    "        #print(cost)\n",
    "        costs.append(cost)\n",
    "\n",
    "        accuracy = acc_from_dict(predictions, labels) #np.sum(np.round(predictions) == labels) / len(labels) / 2  # half due to double-counting\n",
    "        #print(accuracy)\n",
    "        accuracies.append(accuracy)\n",
    "        \n",
    "        return cost\n",
    "    \n",
    "    costs, accuracies = [], []\n",
    "    return cost_spsa, costs, accuracies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1464e9bc-0aec-4dce-8d8f-6022c3979f66",
   "metadata": {},
   "source": [
    "## SPSA minimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ea4e4bcd-663c-4a38-9136-653d5fc88b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 100\n",
    "SEED = 0\n",
    "result_file = workload + \"_\" + workload_size + \"_pennylane_\" + str(classification) + \"_\" + str(layers) + \"_\" + str(single_qubit_params)\n",
    "\n",
    "rng = np.random.default_rng(SEED)\n",
    "init_params_spsa = np.array(rng.random(len(train_symbols)))\n",
    "np.random.seed(SEED)\n",
    "\n",
    "train_cost_fn, train_costs, train_accs = make_cost_fn(qml_training_circuits, training_data_labels)\n",
    "dev_cost_fn, dev_costs, dev_accs = make_cost_fn(qml_validation_circuits, validation_data_labels)\n",
    "\n",
    "def callback_fn(xk):\n",
    "    valid_loss = dev_cost_fn(xk)\n",
    "    train_loss = numpy.around(min(float(train_costs[-1]), float(train_costs[-2])), 4)\n",
    "    train_acc = numpy.around(min(float(train_accs[-1]), float(train_accs[-2])), 4)\n",
    "    valid_acc = numpy.around(float(dev_accs[-1]), 4)\n",
    "    iters = int(len(train_accs)/2)\n",
    "    #if iters % 200 == 0:\n",
    "    info = f\"Epoch: {iters}   \"\\\n",
    "    + f\"train/loss: {train_loss}   \"\\\n",
    "    + f\"valid/loss: {numpy.around(float(valid_loss), 4)}   \"\\\n",
    "    + f\"train/acc: {train_acc}   \"\\\n",
    "    + f\"valid/acc: {valid_acc}\"\n",
    "\n",
    "    with open(\"results//\" + result_file + \".txt\", \"a\") as f:\n",
    "        f.write(info + \"\\n\")\n",
    "\n",
    "    print(info, file=sys.stderr)\n",
    "    return valid_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c814211-8d9a-45aa-bacd-1cd879545b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = minimizeSPSA(train_cost_fn, \n",
    "                      x0 = init_params_spsa.copy(), \n",
    "                      a = 0.0053, \n",
    "                      c = 0.00185, \n",
    "                      niter=EPOCHS, \n",
    "                      paired=False, \n",
    "                      callback=callback_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3da9415-0d92-4207-8a70-bb42fe1205f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
