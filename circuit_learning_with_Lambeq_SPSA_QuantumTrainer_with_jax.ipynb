{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b09952d6-99a3-41a5-865f-2170e9ee0247",
   "metadata": {},
   "source": [
    "# Circuit learning module: Lambeq's QuantumTrainer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb811fe4-d729-4a44-838d-9c02db4a644d",
   "metadata": {},
   "source": [
    "This module performs the optimization with Lambeq's native optimizer. Because the circuits are constructed with Lambeq and DisCoPy, this optimizer is the natural choice. The code is based on the workflow presented in https://github.com/CQCL/lambeq/blob/main/docs/examples/quantum_pipeline.ipynb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9a5783f-901a-4bfe-a622-4003b345fb1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import json\n",
    "import os\n",
    "import glob\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from discopy.utils import loads\n",
    "from pytket.extensions.qiskit import AerBackend\n",
    "from lambeq import TketModel, NumpyModel\n",
    "from lambeq import QuantumTrainer, SPSAOptimizer\n",
    "from lambeq import Dataset\n",
    "\n",
    "this_folder = os.path.abspath(os.getcwd())\n",
    "os.environ['TOKENIZERS_PARALLELISM'] = 'true'\n",
    "#os.environ[\"JAX_PLATFORMS\"] = \"cpu\"\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 100\n",
    "SEED = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238fca40-5d8d-4ace-a65f-693885a8caf8",
   "metadata": {},
   "source": [
    "## Read circuit data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f6f00d7-b573-4c5d-a0d6-d5eafc54745e",
   "metadata": {},
   "source": [
    "We read the circuits from the pickled files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ff0a551-444c-40a7-bf66-8e929bc49a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_circuits_paths = glob.glob(this_folder + \"//simplified-JOB-diagrams//circuits//binary_classification//training//[0-9]*.p\")\n",
    "#validation_circuits_paths = glob.glob(this_folder + \"//simplified-JOB-diagrams//circuits//binary_classification//validation//[0-9]*.p\")\n",
    "test_circuits_paths = glob.glob(this_folder + \"//simplified-JOB-diagrams//circuits//binary_classification//test//[0-9]*.p\")\n",
    "\n",
    "def read_diagrams(circuit_paths):\n",
    "    circuits = {}\n",
    "    for serialized_diagram in circuit_paths:\n",
    "        base_name = Path(serialized_diagram).stem\n",
    "        f = open(serialized_diagram, \"rb\")\n",
    "        diagram = pickle.load(f)\n",
    "        circuits[base_name] = diagram\n",
    "    return circuits\n",
    "\n",
    "\n",
    "training_circuits = read_diagrams(training_circuits_paths[:100])\n",
    "#for key in training_circuits:\n",
    "#    print(\"training query: \", key)\n",
    "test_circuits = read_diagrams(test_circuits_paths) #+ [test_circuits_paths[2]] + test_circuits_paths[8:])\n",
    "#test_circuits = read_diagrams([test_circuits_paths[2]])\n",
    "#for key in test_circuits:\n",
    "#    print(\"test query: \", key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2da3a7c-6a93-44e9-9640-7e9ead005cb2",
   "metadata": {},
   "source": [
    "## Read training and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "774e9f52-69c9-4e1c-8a70-76e1198d12f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data, test_data = None, None\n",
    "with open(this_folder + \"//data//training_data.json\", \"r\") as inputfile:\n",
    "    training_data = json.load(inputfile)['training_data']\n",
    "with open(this_folder + \"//data//test_data.json\", \"r\") as inputfile:\n",
    "    test_data = json.load(inputfile)['test_data']\n",
    "    \n",
    "\n",
    "def time_to_states(data, circuits):\n",
    "    labeled_data = {}\n",
    "    for elem in data:\n",
    "        if elem[\"name\"] in circuits.keys():\n",
    "            if elem[\"time\"] < 5000:\n",
    "                labeled_data[elem[\"name\"]] = [1,0] # corresponds to |0>\n",
    "            else:\n",
    "                labeled_data[elem[\"name\"]] = [0,1] # corresponds to |1>\n",
    "    return labeled_data\n",
    "\n",
    "\n",
    "training_data_labels = time_to_states(training_data, training_circuits)\n",
    "test_data_labels = time_to_states(test_data, test_circuits)\n",
    "\n",
    "#for key in training_data_labels:\n",
    "#    print(\"training: \", key)\n",
    "#for key in test_data_labels:\n",
    "#    print(\"test \", key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6cad830-e6c3-4c29-9ce6-0d6bec2794bc",
   "metadata": {},
   "source": [
    "## Lambeq optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce559dbf-2b4b-4853-82ed-58832aa11e61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test circuits need to share training circuits' parameters. The parameters that are not covered:  {'mini biography'__n.l_2, 'top 250 rank'__n.l_2, 'character-name-in-title'__n.l_2, '[us]'__n.l_2, 'character-name-in-title'__n.l_1, 'character-name-in-title'__n.l_0, country_code__n.l_0, country_code__n.l_1, 'Volker Boehm'__n.l_1, '%Film%'__n.l_2, '%Film%'__n.l_0, 'Volker Boehm'__n.l_2, '%sequel%'__n.l_1, '%Film%'__n.l_1, 'mini biography'__n.l_0, 'bottom 10 rank'__n.l_1, 'bottom 10 rank'__n.l_0, '%sequel%'__n.l_2, '%sequel%'__n.l_0, 'Volker Boehm'__n.l_0, 'mini biography'__n.l_1, 'top 250 rank'__n.l_1, '[us]'__n.l_1, '[us]'__n.l_0, country_code__n.l_2, 'bottom 10 rank'__n.l_2, 'top 250 rank'__n.l_0}\n",
      "Total number of circuits:  290\n",
      "Total number of variables:  207\n"
     ]
    }
   ],
   "source": [
    "#all_circuits = list(training_circuits.values()) + list(test_circuits.values())\n",
    "\n",
    "training_circuits_l = []\n",
    "test_circuits_l = []\n",
    "training_data_labels_l = []\n",
    "test_data_labels_l = []\n",
    "\n",
    "# Organize circuits and labels in correct order into two lists which will be input for training the model\n",
    "for key in training_data_labels:\n",
    "    training_circuits_l.append(training_circuits[key])\n",
    "    training_data_labels_l.append(training_data_labels[key])\n",
    "\n",
    "for key in test_data_labels:\n",
    "    test_circuits_l.append(test_circuits[key])\n",
    "    test_data_labels_l.append(test_data_labels[key])\n",
    "\n",
    "all_circuits = training_circuits_l + test_circuits_l\n",
    "\n",
    "train_syms = set([sym for circuit in training_circuits.values() for sym in circuit.free_symbols])\n",
    "test_syms = set([sym for circuit in test_circuits.values() for sym in circuit.free_symbols])\n",
    "\n",
    "print(\"Test circuits need to share training circuits' parameters. The parameters that are not covered: \", test_syms.difference(train_syms))\n",
    "\n",
    "print(\"Total number of circuits: \", len(all_circuits))\n",
    "print(\"Total number of variables: \", len(train_syms))\n",
    "\n",
    "backend = AerBackend()\n",
    "backend_config = {\n",
    "    'backend': backend,\n",
    "    'compilation': backend.default_compilation_pass(2),\n",
    "    'shots': 32768\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "572abfc1-cc81-4fdb-b8bb-6813fe658dd6",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "550e15cc-550a-4c30-8aa5-05f46678ab5f",
   "metadata": {},
   "source": [
    "Select the used model between `TketModel` or `NumpyModel`. `NumpyModel` can use JAX which speeds up the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04c65634-fa13-47b3-915c-83361d0e1baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = TketModel.from_diagrams(all_circuits, backend_config=backend_config)\n",
    "model = NumpyModel.from_diagrams(all_circuits, use_jit=True)\n",
    "model.initialise_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "868cf7e7-fcbf-4bad-b8bc-4ff0e6b29294",
   "metadata": {},
   "source": [
    "## Loss function and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7cde594c-ad61-4dd6-ac79-85496f2cfed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def acc(y_hat, y):\n",
    "    #print(\"y_hat: \", y_hat)\n",
    "    #print(\"y: \", y)\n",
    "    return (np.sum(np.round(y_hat) == y) / len(y)) / 2\n",
    "\n",
    "loss = lambda y_hat, y: -np.sum(y * np.log(y_hat)) / len(y)  # binary cross-entropy loss\n",
    "#acc = lambda y_hat, y: np.sum(np.round(y_hat) == y) / len(y) / 2  # half due to double-counting\n",
    "\n",
    "eval_metrics = {\"acc\": acc}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3bb6805-facb-4ec9-9c38-8d1df42022b2",
   "metadata": {},
   "source": [
    "## Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "47dbc0e6-4261-498f-92fc-f71e28a8aab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = QuantumTrainer(\n",
    "    model,\n",
    "    loss_function=loss,\n",
    "    epochs=EPOCHS,\n",
    "    optimizer=SPSAOptimizer,\n",
    "    optim_hyperparams={'a': 1, 'c': 0.1, 'A':0.01*EPOCHS},\n",
    "    evaluate_functions=eval_metrics,\n",
    "    evaluate_on_train=True,\n",
    "    verbose = 'text',\n",
    "    seed=SEED\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a9dfb7-5f6d-4128-867b-54e9c4e21f0b",
   "metadata": {},
   "source": [
    "## Training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c9ee9919-b926-4b12-9e3a-8eef9330bddf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:    train/loss: 0.6051   valid/loss: -----   train/acc: 0.7826   valid/acc: -----\n",
      "Epoch 2:    train/loss: 0.7127   valid/loss: -----   train/acc: 0.2174   valid/acc: -----\n",
      "Epoch 3:    train/loss: 0.6745   valid/loss: -----   train/acc: 0.7283   valid/acc: -----\n",
      "Epoch 4:    train/loss: 0.6818   valid/loss: -----   train/acc: 0.7283   valid/acc: -----\n",
      "Epoch 5:    train/loss: 0.6810   valid/loss: -----   train/acc: 0.7283   valid/acc: -----\n",
      "Epoch 6:    train/loss: 0.6764   valid/loss: -----   train/acc: 0.7283   valid/acc: -----\n",
      "Epoch 7:    train/loss: 0.6530   valid/loss: -----   train/acc: 0.7283   valid/acc: -----\n",
      "Epoch 8:    train/loss: 0.5914   valid/loss: -----   train/acc: 0.7283   valid/acc: -----\n",
      "Epoch 9:    train/loss: 0.6719   valid/loss: -----   train/acc: 0.7826   valid/acc: -----\n",
      "Epoch 10:   train/loss: 0.7095   valid/loss: -----   train/acc: 0.2174   valid/acc: -----\n",
      "Epoch 11:   train/loss: 0.6771   valid/loss: -----   train/acc: 0.7283   valid/acc: -----\n",
      "Epoch 12:   train/loss: 0.6742   valid/loss: -----   train/acc: 0.7283   valid/acc: -----\n",
      "Epoch 13:   train/loss: 0.6882   valid/loss: -----   train/acc: 0.7283   valid/acc: -----\n",
      "Epoch 14:   train/loss: 0.6848   valid/loss: -----   train/acc: 0.7283   valid/acc: -----\n",
      "Epoch 15:   train/loss: 0.6843   valid/loss: -----   train/acc: 0.7283   valid/acc: -----\n",
      "Epoch 16:   train/loss: 0.6628   valid/loss: -----   train/acc: 0.7283   valid/acc: -----\n",
      "Epoch 17:   train/loss: 0.6319   valid/loss: -----   train/acc: 0.7283   valid/acc: -----\n",
      "Epoch 18:   train/loss: 0.5824   valid/loss: -----   train/acc: 0.7283   valid/acc: -----\n",
      "Epoch 19:   train/loss: 0.5722   valid/loss: -----   train/acc: 0.7826   valid/acc: -----\n",
      "Epoch 20:   train/loss: 0.5631   valid/loss: -----   train/acc: 0.7826   valid/acc: -----\n",
      "Epoch 21:   train/loss: 0.5463   valid/loss: -----   train/acc: 0.7826   valid/acc: -----\n",
      "Epoch 22:   train/loss: 0.5651   valid/loss: -----   train/acc: 0.7826   valid/acc: -----\n",
      "Epoch 23:   train/loss: 0.5415   valid/loss: -----   train/acc: 0.7826   valid/acc: -----\n",
      "Epoch 24:   train/loss: 0.5411   valid/loss: -----   train/acc: 0.7826   valid/acc: -----\n",
      "Epoch 25:   train/loss: 0.5680   valid/loss: -----   train/acc: 0.7826   valid/acc: -----\n",
      "Epoch 26:   train/loss: 0.5644   valid/loss: -----   train/acc: 0.7826   valid/acc: -----\n",
      "Epoch 27:   train/loss: 0.5616   valid/loss: -----   train/acc: 0.7826   valid/acc: -----\n",
      "Epoch 28:   train/loss: 0.5624   valid/loss: -----   train/acc: 0.7826   valid/acc: -----\n",
      "Epoch 29:   train/loss: 0.5449   valid/loss: -----   train/acc: 0.7826   valid/acc: -----\n",
      "Epoch 30:   train/loss: 0.5612   valid/loss: -----   train/acc: 0.7826   valid/acc: -----\n",
      "Epoch 31:   train/loss: 0.5615   valid/loss: -----   train/acc: 0.7826   valid/acc: -----\n",
      "Epoch 32:   train/loss: 0.5434   valid/loss: -----   train/acc: 0.7826   valid/acc: -----\n",
      "Epoch 33:   train/loss: 0.5597   valid/loss: -----   train/acc: 0.7826   valid/acc: -----\n",
      "Epoch 34:   train/loss: 0.5637   valid/loss: -----   train/acc: 0.7826   valid/acc: -----\n",
      "Epoch 35:   train/loss: 0.5622   valid/loss: -----   train/acc: 0.7826   valid/acc: -----\n",
      "Epoch 36:   train/loss: 0.5584   valid/loss: -----   train/acc: 0.7826   valid/acc: -----\n",
      "Epoch 37:   train/loss: 0.5411   valid/loss: -----   train/acc: 0.7826   valid/acc: -----\n",
      "Epoch 38:   train/loss: 0.5574   valid/loss: -----   train/acc: 0.7826   valid/acc: -----\n",
      "Epoch 39:   train/loss: 0.5375   valid/loss: -----   train/acc: 0.7826   valid/acc: -----\n",
      "Epoch 40:   train/loss: 0.5614   valid/loss: -----   train/acc: 0.7826   valid/acc: -----\n",
      "Epoch 41:   train/loss: 0.5402   valid/loss: -----   train/acc: 0.7826   valid/acc: -----\n",
      "Epoch 42:   train/loss: 0.5392   valid/loss: -----   train/acc: 0.7826   valid/acc: -----\n",
      "Epoch 43:   train/loss: 0.5537   valid/loss: -----   train/acc: 0.7826   valid/acc: -----\n",
      "Epoch 44:   train/loss: 0.5578   valid/loss: -----   train/acc: 0.7826   valid/acc: -----\n",
      "Epoch 45:   train/loss: 0.5525   valid/loss: -----   train/acc: 0.7826   valid/acc: -----\n",
      "Epoch 46:   train/loss: 0.5335   valid/loss: -----   train/acc: 0.7826   valid/acc: -----\n",
      "Epoch 47:   train/loss: 0.5334   valid/loss: -----   train/acc: 0.7826   valid/acc: -----\n",
      "Epoch 48:   train/loss: 0.5332   valid/loss: -----   train/acc: 0.7826   valid/acc: -----\n",
      "Epoch 49:   train/loss: 0.5332   valid/loss: -----   train/acc: 0.7826   valid/acc: -----\n",
      "Epoch 50:   train/loss: 0.5544   valid/loss: -----   train/acc: 0.7826   valid/acc: -----\n",
      "Epoch 51:   train/loss: 0.5546   valid/loss: -----   train/acc: 0.7826   valid/acc: -----\n",
      "Epoch 52:   train/loss: 0.5517   valid/loss: -----   train/acc: 0.7826   valid/acc: -----\n",
      "Epoch 53:   train/loss: 0.5518   valid/loss: -----   train/acc: 0.7826   valid/acc: -----\n",
      "Epoch 54:   train/loss: 0.5517   valid/loss: -----   train/acc: 0.7826   valid/acc: -----\n",
      "Epoch 55:   train/loss: 0.5510   valid/loss: -----   train/acc: 0.7826   valid/acc: -----\n",
      "Epoch 56:   train/loss: 0.5319   valid/loss: -----   train/acc: 0.7826   valid/acc: -----\n",
      "Epoch 57:   train/loss: 0.5526   valid/loss: -----   train/acc: 0.7826   valid/acc: -----\n",
      "Epoch 58:   train/loss: 0.5529   valid/loss: -----   train/acc: 0.7826   valid/acc: -----\n",
      "Epoch 59:   train/loss: 0.5497   valid/loss: -----   train/acc: 0.7826   valid/acc: -----\n",
      "Epoch 60:   train/loss: 0.5520   valid/loss: -----   train/acc: 0.7826   valid/acc: -----\n",
      "Epoch 61:   train/loss: 0.5490   valid/loss: -----   train/acc: 0.7826   valid/acc: -----\n",
      "Epoch 62:   train/loss: 0.5507   valid/loss: -----   train/acc: 0.7826   valid/acc: -----\n",
      "Epoch 63:   train/loss: 0.5507   valid/loss: -----   train/acc: 0.7826   valid/acc: -----\n",
      "Epoch 64:   train/loss: 0.5302   valid/loss: -----   train/acc: 0.7826   valid/acc: -----\n",
      "Epoch 65:   train/loss: 0.5299   valid/loss: -----   train/acc: 0.7826   valid/acc: -----\n",
      "Epoch 66:   train/loss: 0.5496   valid/loss: -----   train/acc: 0.7826   valid/acc: -----\n",
      "Epoch 67:   train/loss: 0.5301   valid/loss: -----   train/acc: 0.7826   valid/acc: -----\n",
      "Epoch 68:   train/loss: 0.5501   valid/loss: -----   train/acc: 0.7826   valid/acc: -----\n",
      "Epoch 69:   train/loss: 0.5311   valid/loss: -----   train/acc: 0.7826   valid/acc: -----\n",
      "Epoch 70:   train/loss: 0.5310   valid/loss: -----   train/acc: 0.7826   valid/acc: -----\n",
      "Epoch 71:   train/loss: 0.5479   valid/loss: -----   train/acc: 0.7826   valid/acc: -----\n",
      "Epoch 72:   train/loss: 0.5306   valid/loss: -----   train/acc: 0.7826   valid/acc: -----\n",
      "Epoch 73:   train/loss: 0.5469   valid/loss: -----   train/acc: 0.7826   valid/acc: -----\n",
      "Epoch 74:   train/loss: 0.5293   valid/loss: -----   train/acc: 0.7826   valid/acc: -----\n",
      "Epoch 75:   train/loss: 0.5289   valid/loss: -----   train/acc: 0.7826   valid/acc: -----\n",
      "Epoch 76:   train/loss: 0.5480   valid/loss: -----   train/acc: 0.7826   valid/acc: -----\n",
      "Epoch 77:   train/loss: 0.5464   valid/loss: -----   train/acc: 0.7826   valid/acc: -----\n",
      "Epoch 78:   train/loss: 0.5474   valid/loss: -----   train/acc: 0.7826   valid/acc: -----\n",
      "Epoch 79:   train/loss: 0.5284   valid/loss: -----   train/acc: 0.7826   valid/acc: -----\n",
      "Epoch 80:   train/loss: 0.5283   valid/loss: -----   train/acc: 0.7826   valid/acc: -----\n",
      "Epoch 81:   train/loss: 0.5469   valid/loss: -----   train/acc: 0.7826   valid/acc: -----\n",
      "Epoch 82:   train/loss: 0.5458   valid/loss: -----   train/acc: 0.7826   valid/acc: -----\n",
      "Epoch 83:   train/loss: 0.5291   valid/loss: -----   train/acc: 0.7826   valid/acc: -----\n",
      "Epoch 84:   train/loss: 0.5292   valid/loss: -----   train/acc: 0.7826   valid/acc: -----\n",
      "Epoch 85:   train/loss: 0.5453   valid/loss: -----   train/acc: 0.7826   valid/acc: -----\n",
      "Epoch 86:   train/loss: 0.5291   valid/loss: -----   train/acc: 0.7826   valid/acc: -----\n",
      "Epoch 87:   train/loss: 0.5289   valid/loss: -----   train/acc: 0.7826   valid/acc: -----\n",
      "Epoch 88:   train/loss: 0.5288   valid/loss: -----   train/acc: 0.7826   valid/acc: -----\n",
      "Epoch 89:   train/loss: 0.5447   valid/loss: -----   train/acc: 0.7826   valid/acc: -----\n",
      "Epoch 90:   train/loss: 0.5456   valid/loss: -----   train/acc: 0.7826   valid/acc: -----\n",
      "Epoch 91:   train/loss: 0.5458   valid/loss: -----   train/acc: 0.7826   valid/acc: -----\n",
      "Epoch 92:   train/loss: 0.5275   valid/loss: -----   train/acc: 0.7826   valid/acc: -----\n",
      "Epoch 93:   train/loss: 0.5275   valid/loss: -----   train/acc: 0.7826   valid/acc: -----\n",
      "Epoch 94:   train/loss: 0.5274   valid/loss: -----   train/acc: 0.7826   valid/acc: -----\n",
      "Epoch 95:   train/loss: 0.5273   valid/loss: -----   train/acc: 0.7826   valid/acc: -----\n",
      "Epoch 96:   train/loss: 0.5273   valid/loss: -----   train/acc: 0.7826   valid/acc: -----\n",
      "Epoch 97:   train/loss: 0.5459   valid/loss: -----   train/acc: 0.7826   valid/acc: -----\n",
      "Epoch 98:   train/loss: 0.5273   valid/loss: -----   train/acc: 0.7826   valid/acc: -----\n",
      "Epoch 99:   train/loss: 0.5457   valid/loss: -----   train/acc: 0.7826   valid/acc: -----\n",
      "Epoch 100:  train/loss: 0.5455   valid/loss: -----   train/acc: 0.7826   valid/acc: -----\n",
      "\n",
      "Training completed!\n"
     ]
    }
   ],
   "source": [
    "train_dataset = Dataset(training_circuits_l, training_data_labels_l)\n",
    "\n",
    "#test_dataset = Dataset(test_circuits_l, test_data_labels_l, shuffle=False)\n",
    "\n",
    "trainer.fit(train_dataset, evaluation_step=1, logging_step=1)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9817e2f2-560d-4411-8637-52815d2446e8",
   "metadata": {},
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ((ax_tl, ax_tr), (ax_bl, ax_br)) = plt.subplots(2, 2, sharex=True, sharey='row', figsize=(10, 6))\n",
    "ax_tl.set_title('Training set')\n",
    "ax_tr.set_title('Development set')\n",
    "ax_bl.set_xlabel('Iterations')\n",
    "ax_br.set_xlabel('Iterations')\n",
    "ax_bl.set_ylabel('Accuracy')\n",
    "ax_tl.set_ylabel('Loss')\n",
    "\n",
    "colours = iter(plt.rcParams['axes.prop_cycle'].by_key()['color'])\n",
    "ax_tl.plot(trainer.train_epoch_costs[::10], color=next(colours))\n",
    "ax_bl.plot(trainer.train_results['acc'][::10], color=next(colours))\n",
    "ax_tr.plot(trainer.val_costs[::10], color=next(colours))\n",
    "ax_br.plot(trainer.val_results['acc'][::10], color=next(colours))\n",
    "\n",
    "for e in model(test_circuits_l):\n",
    "    print(e)\n",
    "for e in test_data_labels_l:\n",
    "    print(e)\n",
    "\n",
    "# print test accuracy\n",
    "test_acc = acc(model(test_circuits_l), test_data_labels_l)\n",
    "print('Validation accuracy:', test_acc.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7babeae9-602f-4cd4-acd8-cfe59d1b607d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
