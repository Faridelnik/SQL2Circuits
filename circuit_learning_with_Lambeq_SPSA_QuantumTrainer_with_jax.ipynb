{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b09952d6-99a3-41a5-865f-2170e9ee0247",
   "metadata": {},
   "source": [
    "# Circuit learning module: Lambeq's QuantumTrainer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb811fe4-d729-4a44-838d-9c02db4a644d",
   "metadata": {},
   "source": [
    "This module performs the optimization with Lambeq's native optimizer. Because the circuits are constructed with Lambeq and DisCoPy, this optimizer is the natural choice. The code is based on the workflow presented in https://github.com/CQCL/lambeq/blob/main/docs/examples/quantum_pipeline.ipynb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9a5783f-901a-4bfe-a622-4003b345fb1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import json\n",
    "import os\n",
    "import glob\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pickle\n",
    "import math\n",
    "\n",
    "from discopy.utils import loads\n",
    "from pytket.extensions.qiskit import AerBackend\n",
    "from lambeq import TketModel, NumpyModel\n",
    "from lambeq import QuantumTrainer, SPSAOptimizer\n",
    "from lambeq import Dataset\n",
    "\n",
    "from calibrate import calibrate\n",
    "from utils import read_diagrams, create_labeled_classes, bin_class_loss, multi_class_loss, bin_class_acc, multi_class_acc\n",
    "\n",
    "this_folder = os.path.abspath(os.getcwd())\n",
    "os.environ['TOKENIZERS_PARALLELISM'] = 'true'\n",
    "\n",
    "# Uncomment if you do not want to access GPU\n",
    "#os.environ[\"JAX_PLATFORMS\"] = \"cpu\"\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 10000\n",
    "SEED = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41db742d-857e-4c75-99f7-aa37a34cc077",
   "metadata": {},
   "source": [
    "## Select workload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98139440-66a4-473d-9353-3eaa5387a032",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select workload\n",
    "workload = \"small\"\n",
    "#workload = \"medium\"\n",
    "#workload = \"large\"\n",
    "\n",
    "# Select if we perform binary classification or multi-class classification\n",
    "# Give number of qubits to create classes:\n",
    "# 1 -> 2^1 = 2 classes i.e. binary classification\n",
    "# 2 -> 2^2 = 4 classes\n",
    "# ...\n",
    "# 5 -> 2^5 = 32 classes, etc.\n",
    "\n",
    "classification = 2\n",
    "acc = None\n",
    "loss = None\n",
    "\n",
    "if classification == 1:\n",
    "    loss = bin_class_loss\n",
    "    acc = bin_class_acc\n",
    "else:\n",
    "    loss = multi_class_loss\n",
    "    acc = multi_class_acc\n",
    "\n",
    "# Access the selected circuits\n",
    "path_name = this_folder + \"//simplified-JOB-diagrams//\" + workload + \"//circuits//\" + str(classification) + \"//\"\n",
    "\n",
    "training_circuits_paths = glob.glob(path_name + \"training//[0-9]*.p\")\n",
    "validation_circuits_paths = glob.glob(path_name + \"validation//[0-9]*.p\")\n",
    "test_circuits_paths = glob.glob(path_name + \"test//[0-9]*.p\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238fca40-5d8d-4ace-a65f-693885a8caf8",
   "metadata": {},
   "source": [
    "## Read circuits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f6f00d7-b573-4c5d-a0d6-d5eafc54745e",
   "metadata": {},
   "source": [
    "We read the circuits from the pickled files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ff0a551-444c-40a7-bf66-8e929bc49a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_circuits = read_diagrams(training_circuits_paths)\n",
    "validation_circuits = read_diagrams(validation_circuits_paths)\n",
    "test_circuits = read_diagrams(test_circuits_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2da3a7c-6a93-44e9-9640-7e9ead005cb2",
   "metadata": {},
   "source": [
    "## Read training, validation and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "774e9f52-69c9-4e1c-8a70-76e1198d12f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data, test_data, validation_data = None, None, None\n",
    "data_path = this_folder + \"//data//\" + workload + \"//\"\n",
    "\n",
    "with open(data_path + \"training_data.json\", \"r\") as inputfile:\n",
    "    training_data = json.load(inputfile)['training_data']\n",
    "with open(data_path + \"test_data.json\", \"r\") as inputfile:\n",
    "    test_data = json.load(inputfile)['test_data']\n",
    "with open(data_path + \"validation_data.json\", \"r\") as inputfile:\n",
    "    validation_data = json.load(inputfile)['validation_data']\n",
    "\n",
    "training_data_labels = create_labeled_classes(training_data, classification)\n",
    "test_data_labels = create_labeled_classes(test_data, classification)\n",
    "validation_data_labels = create_labeled_classes(validation_data, classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6cad830-e6c3-4c29-9ce6-0d6bec2794bc",
   "metadata": {},
   "source": [
    "## Prepare circuits for the Lambeq optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce559dbf-2b4b-4853-82ed-58832aa11e61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test circuits need to share training circuits' parameters. The parameters that are not covered (should be empty set, set()):  set()\n",
      "Validation circuits need to share training circuits' parameters. The parameters that are not covered (should be empty set, set()):  set()\n",
      "Total number of circuits:  29\n",
      "Total number of variables:  91\n"
     ]
    }
   ],
   "source": [
    "#all_circuits = list(training_circuits.values()) + list(test_circuits.values())\n",
    "\n",
    "training_circuits_l = []\n",
    "test_circuits_l = []\n",
    "validation_circuits_l = []\n",
    "\n",
    "training_data_labels_l = []\n",
    "test_data_labels_l = []\n",
    "validation_data_labels_l = []\n",
    "\n",
    "# Organize circuits and labels in correct order into two lists which will be input for training the model\n",
    "for key in training_data_labels:\n",
    "    training_circuits_l.append(training_circuits[key])\n",
    "    training_data_labels_l.append(training_data_labels[key])\n",
    "\n",
    "for key in test_data_labels:\n",
    "    test_circuits_l.append(test_circuits[key])\n",
    "    test_data_labels_l.append(test_data_labels[key])\n",
    "    \n",
    "for key in validation_data_labels:\n",
    "    validation_circuits_l.append(validation_circuits[key])\n",
    "    validation_data_labels_l.append(validation_data_labels[key])\n",
    "\n",
    "all_circuits = training_circuits_l + test_circuits_l + validation_circuits_l\n",
    "\n",
    "train_syms = set([sym for circuit in training_circuits.values() for sym in circuit.free_symbols])\n",
    "test_syms = set([sym for circuit in test_circuits.values() for sym in circuit.free_symbols])\n",
    "val_syms = set([sym for circuit in validation_circuits.values() for sym in circuit.free_symbols])\n",
    "\n",
    "print(\"Test circuits need to share training circuits' parameters. The parameters that are not covered (should be empty set, set()): \", test_syms.difference(train_syms))\n",
    "print(\"Validation circuits need to share training circuits' parameters. The parameters that are not covered (should be empty set, set()): \", val_syms.difference(train_syms))\n",
    "\n",
    "print(\"Total number of circuits: \", len(all_circuits))\n",
    "print(\"Total number of variables: \", len(train_syms))\n",
    "\n",
    "backend = AerBackend()\n",
    "backend_config = {\n",
    "    'backend': backend,\n",
    "    'compilation': backend.default_compilation_pass(2),\n",
    "    'shots': 3200\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "572abfc1-cc81-4fdb-b8bb-6813fe658dd6",
   "metadata": {},
   "source": [
    "## Select the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "550e15cc-550a-4c30-8aa5-05f46678ab5f",
   "metadata": {},
   "source": [
    "Select the used model between `TketModel` or `NumpyModel`. `NumpyModel` can use JAX which speeds up the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "04c65634-fa13-47b3-915c-83361d0e1baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = TketModel.from_diagrams(training_circuits_l, backend_config=backend_config)\n",
    "model = NumpyModel.from_diagrams(all_circuits, use_jit=True)\n",
    "model.initialise_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "868cf7e7-fcbf-4bad-b8bc-4ff0e6b29294",
   "metadata": {},
   "source": [
    "## Define loss function and evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7cde594c-ad61-4dd6-ac79-85496f2cfed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_metrics = {\"acc\": acc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c458d727-069f-47d2-b3dc-7797d587c06a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -- Learning rate: a / ((A + n) ^ alpha) with a = 16.09168294326651, A = 100.0, alpha = 0.602\n",
      " -- Perturbation: c / (n ^ gamma) with c = 0.2, gamma = 0.101\n"
     ]
    }
   ],
   "source": [
    "a, c = calibrate(loss, np.array(model.weights), A = 0.01*EPOCHS)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "58215988-ec14-4ac9-a6f0-9a26f6e8161d",
   "metadata": {},
   "source": [
    "# Code to debug why Hadamard transform was positioned wrong\n",
    "\n",
    "#print(training_data_labels_l)\n",
    "#for c in training_circuits_l:\n",
    "#    c.draw(figsize=(10, 20))\n",
    "\n",
    "from discopy.quantum import Circuit\n",
    "import numpy\n",
    "import copy\n",
    "SEED = 10\n",
    "rng = numpy.random.default_rng(SEED)\n",
    "c = training_circuits_l[0].dagger()\n",
    "c.draw(figsize=(10, 20))\n",
    "parameter_n = len(c.free_symbols)\n",
    "params = list(c.free_symbols)\n",
    "c = c.lambdify(*params)\n",
    "x00 = -np.array(rng.random(parameter_n))\n",
    "numpy.random.seed(SEED)\n",
    "#for x in x00: print(x)\n",
    "\n",
    "#for i in range(len(params)):\n",
    "#    print(i, params[i])\n",
    "\n",
    "def normalise(predictions):\n",
    "    # apply smoothing to predictions\n",
    "    predictions = np.abs(predictions) + 1e-9\n",
    "    return predictions / predictions.sum()\n",
    "\n",
    "outputss = []\n",
    "\n",
    "#for i in range(31):\n",
    "#c.draw(figsize=(10, 20))\n",
    "x0 = copy.deepcopy(x00)\n",
    "#print(x0)\n",
    "#x0[i] = x0[i] + 0.7\n",
    "#print(x0)\n",
    "outputs = Circuit.eval(c(*x0))\n",
    "#print(list(normalise(outputs.array)), params[i])\n",
    "print(outputs)\n",
    "#outputss.append(list(outputs.array))\n",
    "\n",
    "print(acc(outputs[0], [0,0,1,0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3bb6805-facb-4ec9-9c38-8d1df42022b2",
   "metadata": {},
   "source": [
    "## Initialize the trainer and the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "47dbc0e6-4261-498f-92fc-f71e28a8aab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = QuantumTrainer(\n",
    "    model,\n",
    "    loss_function=loss,\n",
    "    epochs=EPOCHS,\n",
    "    optimizer=SPSAOptimizer,\n",
    "    optim_hyperparams={'a': 1.0, 'c': 1.0, 'A':0.01*EPOCHS},\n",
    "    evaluate_functions=eval_metrics,\n",
    "    evaluate_on_train=True,\n",
    "    verbose = 'text',\n",
    "    seed=SEED\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c9ee9919-b926-4b12-9e3a-8eef9330bddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Dataset(training_circuits_l, training_data_labels_l)\n",
    "val_dataset = Dataset(validation_circuits_l, validation_data_labels_l, shuffle=False)\n",
    "test_dataset = Dataset(test_circuits_l, test_data_labels_l, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd52574-ab2e-4918-a108-f18409d1b25b",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17fc3f1d-cf86-4b9a-918e-f95ae6bd3a01",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:      train/loss: 9.1131   valid/loss: 1.7401   train/acc: 0.3158   valid/acc: 0.4000\n",
      "Epoch 100:    train/loss: 7.2721   valid/loss: 1.8683   train/acc: 0.1053   valid/acc: 0.4000\n",
      "Epoch 200:    train/loss: 6.8331   valid/loss: 2.0618   train/acc: 0.2632   valid/acc: 0.2000\n",
      "Epoch 300:    train/loss: 6.7172   valid/loss: 2.0741   train/acc: 0.4211   valid/acc: 0.2000\n",
      "Epoch 400:    train/loss: 7.6977   valid/loss: 2.5623   train/acc: 0.2632   valid/acc: 0.0000\n",
      "Epoch 500:    train/loss: 7.6336   valid/loss: 1.6407   train/acc: 0.1053   valid/acc: 0.2000\n",
      "Epoch 600:    train/loss: 7.3624   valid/loss: 1.9875   train/acc: 0.2632   valid/acc: 0.4000\n",
      "Epoch 700:    train/loss: 7.0538   valid/loss: 1.6423   train/acc: 0.3158   valid/acc: 0.6000\n",
      "Epoch 800:    train/loss: 6.9702   valid/loss: 1.7262   train/acc: 0.3684   valid/acc: 0.4000\n",
      "Epoch 900:    train/loss: 7.2157   valid/loss: 1.2527   train/acc: 0.2632   valid/acc: 0.8000\n",
      "Epoch 1000:   train/loss: 7.3324   valid/loss: 1.6228   train/acc: 0.3684   valid/acc: 0.2000\n",
      "Epoch 1100:   train/loss: 6.7634   valid/loss: 1.7623   train/acc: 0.2632   valid/acc: 0.0000\n",
      "Epoch 1200:   train/loss: 7.1665   valid/loss: 2.0546   train/acc: 0.1579   valid/acc: 0.2000\n",
      "Epoch 1300:   train/loss: 7.8223   valid/loss: 2.0006   train/acc: 0.3158   valid/acc: 0.4000\n",
      "Epoch 1400:   train/loss: 6.7047   valid/loss: 2.2225   train/acc: 0.2105   valid/acc: 0.2000\n",
      "Epoch 1500:   train/loss: 7.9692   valid/loss: 1.6446   train/acc: 0.2632   valid/acc: 0.0000\n",
      "Epoch 1600:   train/loss: 6.7981   valid/loss: 1.9731   train/acc: 0.2105   valid/acc: 0.2000\n",
      "Epoch 1700:   train/loss: 7.3409   valid/loss: 3.2417   train/acc: 0.1579   valid/acc: 0.2000\n",
      "Epoch 1800:   train/loss: 7.2522   valid/loss: 2.2190   train/acc: 0.1579   valid/acc: 0.2000\n",
      "Epoch 1900:   train/loss: 7.8752   valid/loss: 2.5314   train/acc: 0.2105   valid/acc: 0.4000\n",
      "Epoch 2000:   train/loss: 6.8125   valid/loss: 2.7507   train/acc: 0.3158   valid/acc: 0.4000\n",
      "Epoch 2100:   train/loss: 7.1553   valid/loss: 1.8076   train/acc: 0.1579   valid/acc: 0.4000\n",
      "Epoch 2200:   train/loss: 9.8435   valid/loss: 1.2990   train/acc: 0.2632   valid/acc: 0.4000\n",
      "Epoch 2300:   train/loss: 9.1241   valid/loss: 1.9824   train/acc: 0.3158   valid/acc: 0.6000\n",
      "Epoch 2400:   train/loss: 9.6604   valid/loss: 1.7209   train/acc: 0.2632   valid/acc: 0.2000\n",
      "Epoch 2500:   train/loss: 10.2297   valid/loss: 2.4764   train/acc: 0.3158   valid/acc: 0.2000\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(train_dataset, val_dataset, evaluation_step=1, logging_step=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd474ba-917f-4f2a-9c33-2bacaa9c9715",
   "metadata": {},
   "source": [
    "## Visualize the training process and results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c46057-738a-4088-a9b4-d8e6a458f954",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ((ax_tl, ax_tr), (ax_bl, ax_br)) = plt.subplots(2, 2, sharex=True, sharey='row', figsize=(10, 6))\n",
    "ax_tl.set_title('Training set')\n",
    "ax_tr.set_title('Development set')\n",
    "ax_bl.set_xlabel('Iterations')\n",
    "ax_br.set_xlabel('Iterations')\n",
    "ax_bl.set_ylabel('Accuracy')\n",
    "ax_tl.set_ylabel('Loss')\n",
    "\n",
    "colours = iter(plt.rcParams['axes.prop_cycle'].by_key()['color'])\n",
    "ax_tl.plot(trainer.train_epoch_costs[::10], color=next(colours))\n",
    "ax_bl.plot(trainer.train_results['acc'][::10], color=next(colours))\n",
    "ax_tr.plot(trainer.val_costs[::10], color=next(colours))\n",
    "ax_br.plot(trainer.val_results['acc'][::10], color=next(colours))\n",
    "\n",
    "for e in model(test_circuits_l):\n",
    "    print(e)\n",
    "for e in test_data_labels_l:\n",
    "    print(e)\n",
    "\n",
    "# print test accuracy\n",
    "test_acc = acc(model(test_circuits_l), test_data_labels_l)\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e4e7e6c-e747-45a9-addd-78cda9a96cb3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
