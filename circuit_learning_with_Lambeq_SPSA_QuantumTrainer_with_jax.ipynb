{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b09952d6-99a3-41a5-865f-2170e9ee0247",
   "metadata": {},
   "source": [
    "# Circuit learning module: Lambeq's QuantumTrainer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb811fe4-d729-4a44-838d-9c02db4a644d",
   "metadata": {},
   "source": [
    "This module performs the optimization with Lambeq's native optimizer. Because the circuits are constructed with Lambeq and DisCoPy, this optimizer is the natural choice. The code is based on the workflow presented in https://github.com/CQCL/lambeq/blob/main/docs/examples/quantum_pipeline.ipynb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9a5783f-901a-4bfe-a622-4003b345fb1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import json\n",
    "import os\n",
    "import glob\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pickle\n",
    "import math\n",
    "\n",
    "from discopy.utils import loads\n",
    "from pytket.extensions.qiskit import AerBackend\n",
    "from lambeq import TketModel, NumpyModel\n",
    "from lambeq import QuantumTrainer, SPSAOptimizer\n",
    "from lambeq import Dataset\n",
    "\n",
    "from calibrate import calibrate\n",
    "from utils import read_diagrams, create_labeled_classes, loss, acc\n",
    "\n",
    "this_folder = os.path.abspath(os.getcwd())\n",
    "os.environ['TOKENIZERS_PARALLELISM'] = 'true'\n",
    "\n",
    "# Uncomment if you do not want to access GPU\n",
    "#os.environ[\"JAX_PLATFORMS\"] = \"cpu\"\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 8000\n",
    "SEED = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41db742d-857e-4c75-99f7-aa37a34cc077",
   "metadata": {},
   "source": [
    "## Select workload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98139440-66a4-473d-9353-3eaa5387a032",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select workload\n",
    "#workload = \"small\"\n",
    "workload = \"medium\"\n",
    "#workload = \"large\"\n",
    "\n",
    "# Select if we perform binary classification or multi-class classification\n",
    "# Give number of qubits to create classes:\n",
    "# 1 -> 2^1 = 2 classes i.e. binary classification\n",
    "# 2 -> 2^2 = 4 classes\n",
    "# ...\n",
    "# 5 -> 2^5 = 32 classes, etc.\n",
    "\n",
    "classification = 2\n",
    "\n",
    "# Access the selected circuits\n",
    "path_name = this_folder + \"//simplified-JOB-diagrams//\" + workload + \"//circuits//\" + str(classification) + \"//\"\n",
    "\n",
    "training_circuits_paths = glob.glob(path_name + \"training//[0-9]*.p\")\n",
    "validation_circuits_paths = glob.glob(path_name + \"validation//[0-9]*.p\")\n",
    "test_circuits_paths = glob.glob(path_name + \"test//[0-9]*.p\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238fca40-5d8d-4ace-a65f-693885a8caf8",
   "metadata": {},
   "source": [
    "## Read circuits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f6f00d7-b573-4c5d-a0d6-d5eafc54745e",
   "metadata": {},
   "source": [
    "We read the circuits from the pickled files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ff0a551-444c-40a7-bf66-8e929bc49a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_circuits = read_diagrams(training_circuits_paths)\n",
    "validation_circuits = read_diagrams(validation_circuits_paths)\n",
    "test_circuits = read_diagrams(test_circuits_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2da3a7c-6a93-44e9-9640-7e9ead005cb2",
   "metadata": {},
   "source": [
    "## Read training, validation and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "774e9f52-69c9-4e1c-8a70-76e1198d12f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data, test_data, validation_data = None, None, None\n",
    "data_path = this_folder + \"//data//\" + workload + \"//\"\n",
    "\n",
    "with open(data_path + \"training_data.json\", \"r\") as inputfile:\n",
    "    training_data = json.load(inputfile)['training_data']\n",
    "with open(data_path + \"test_data.json\", \"r\") as inputfile:\n",
    "    test_data = json.load(inputfile)['test_data']\n",
    "with open(data_path + \"validation_data.json\", \"r\") as inputfile:\n",
    "    validation_data = json.load(inputfile)['validation_data']\n",
    "\n",
    "training_data_labels = create_labeled_classes(training_data, classification)\n",
    "test_data_labels = create_labeled_classes(test_data, classification)\n",
    "validation_data_labels = create_labeled_classes(validation_data, classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6cad830-e6c3-4c29-9ce6-0d6bec2794bc",
   "metadata": {},
   "source": [
    "## Prepare circuits for the Lambeq optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce559dbf-2b4b-4853-82ed-58832aa11e61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test circuits need to share training circuits' parameters. The parameters that are not covered (should be empty set, set()):  set()\n",
      "Validation circuits need to share training circuits' parameters. The parameters that are not covered (should be empty set, set()):  set()\n",
      "Total number of circuits:  121\n",
      "Total number of variables:  77\n"
     ]
    }
   ],
   "source": [
    "#all_circuits = list(training_circuits.values()) + list(test_circuits.values())\n",
    "\n",
    "training_circuits_l = []\n",
    "test_circuits_l = []\n",
    "validation_circuits_l = []\n",
    "\n",
    "training_data_labels_l = []\n",
    "test_data_labels_l = []\n",
    "validation_data_labels_l = []\n",
    "\n",
    "# Organize circuits and labels in correct order into two lists which will be input for training the model\n",
    "for key in training_data_labels:\n",
    "    training_circuits_l.append(training_circuits[key])\n",
    "    training_data_labels_l.append(training_data_labels[key])\n",
    "\n",
    "for key in test_data_labels:\n",
    "    test_circuits_l.append(test_circuits[key])\n",
    "    test_data_labels_l.append(test_data_labels[key])\n",
    "    \n",
    "for key in validation_data_labels:\n",
    "    validation_circuits_l.append(validation_circuits[key])\n",
    "    validation_data_labels_l.append(validation_data_labels[key])\n",
    "\n",
    "all_circuits = training_circuits_l + test_circuits_l + validation_circuits_l\n",
    "\n",
    "train_syms = set([sym for circuit in training_circuits.values() for sym in circuit.free_symbols])\n",
    "test_syms = set([sym for circuit in test_circuits.values() for sym in circuit.free_symbols])\n",
    "val_syms = set([sym for circuit in validation_circuits.values() for sym in circuit.free_symbols])\n",
    "\n",
    "print(\"Test circuits need to share training circuits' parameters. The parameters that are not covered (should be empty set, set()): \", test_syms.difference(train_syms))\n",
    "print(\"Validation circuits need to share training circuits' parameters. The parameters that are not covered (should be empty set, set()): \", val_syms.difference(train_syms))\n",
    "\n",
    "print(\"Total number of circuits: \", len(all_circuits))\n",
    "print(\"Total number of variables: \", len(train_syms))\n",
    "\n",
    "backend = AerBackend()\n",
    "backend_config = {\n",
    "    'backend': backend,\n",
    "    'compilation': backend.default_compilation_pass(2),\n",
    "    'shots': 3200\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "572abfc1-cc81-4fdb-b8bb-6813fe658dd6",
   "metadata": {},
   "source": [
    "## Select the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "550e15cc-550a-4c30-8aa5-05f46678ab5f",
   "metadata": {},
   "source": [
    "Select the used model between `TketModel` or `NumpyModel`. `NumpyModel` can use JAX which speeds up the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "04c65634-fa13-47b3-915c-83361d0e1baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = TketModel.from_diagrams(training_circuits_l, backend_config=backend_config)\n",
    "model = NumpyModel.from_diagrams(all_circuits, use_jit=True)\n",
    "model.initialise_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "868cf7e7-fcbf-4bad-b8bc-4ff0e6b29294",
   "metadata": {},
   "source": [
    "## Define loss function and evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7cde594c-ad61-4dd6-ac79-85496f2cfed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_metrics = {\"acc\": acc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c458d727-069f-47d2-b3dc-7797d587c06a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -- Learning rate: a / ((A + n) ^ alpha) with a = 14.089902289038072, A = 80.0, alpha = 0.602\n",
      " -- Perturbation: c / (n ^ gamma) with c = 0.2, gamma = 0.101\n"
     ]
    }
   ],
   "source": [
    "a, c = calibrate(loss, np.array(model.weights), A = 0.01*EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3bb6805-facb-4ec9-9c38-8d1df42022b2",
   "metadata": {},
   "source": [
    "## Initialize the trainer and the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "47dbc0e6-4261-498f-92fc-f71e28a8aab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = QuantumTrainer(\n",
    "    model,\n",
    "    loss_function=loss,\n",
    "    epochs=EPOCHS,\n",
    "    optimizer=SPSAOptimizer,\n",
    "    optim_hyperparams={'a': 10, 'c': c, 'A':0.01*EPOCHS},\n",
    "    evaluate_functions=eval_metrics,\n",
    "    evaluate_on_train=True,\n",
    "    verbose = 'text',\n",
    "    seed=SEED\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c9ee9919-b926-4b12-9e3a-8eef9330bddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Dataset(training_circuits_l, training_data_labels_l)\n",
    "val_dataset = Dataset(validation_circuits_l, validation_data_labels_l, shuffle=False)\n",
    "test_dataset = Dataset(test_circuits_l, test_data_labels_l, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd52574-ab2e-4918-a108-f18409d1b25b",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17fc3f1d-cf86-4b9a-918e-f95ae6bd3a01",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:     train/loss: 0.3555   valid/loss: 0.3580   train/acc: 0.3750   valid/acc: 0.3512\n",
      "Epoch 100:   train/loss: 0.4242   valid/loss: 0.3957   train/acc: 0.3688   valid/acc: 0.3690\n",
      "Epoch 200:   train/loss: 0.3702   valid/loss: 0.3377   train/acc: 0.3750   valid/acc: 0.3750\n",
      "Epoch 300:   train/loss: 0.3555   valid/loss: 0.3498   train/acc: 0.3750   valid/acc: 0.3750\n",
      "Epoch 400:   train/loss: 0.3676   valid/loss: 0.3609   train/acc: 0.3750   valid/acc: 0.3750\n",
      "Epoch 500:   train/loss: 0.3483   valid/loss: 0.3243   train/acc: 0.3750   valid/acc: 0.3750\n",
      "Epoch 600:   train/loss: 0.3519   valid/loss: 0.3431   train/acc: 0.3750   valid/acc: 0.3750\n",
      "Epoch 700:   train/loss: 0.3466   valid/loss: 0.3383   train/acc: 0.3750   valid/acc: 0.3750\n",
      "Epoch 800:   train/loss: 0.3459   valid/loss: 0.3317   train/acc: 0.3750   valid/acc: 0.3750\n",
      "Epoch 900:   train/loss: 0.3495   valid/loss: 0.3497   train/acc: 0.3750   valid/acc: 0.3750\n",
      "Epoch 1000:  train/loss: 0.3596   valid/loss: 0.3499   train/acc: 0.3750   valid/acc: 0.3750\n",
      "Epoch 1100:  train/loss: 0.3552   valid/loss: 0.3424   train/acc: 0.3750   valid/acc: 0.3750\n",
      "Epoch 1200:  train/loss: 0.3555   valid/loss: 0.3414   train/acc: 0.3750   valid/acc: 0.3750\n",
      "Epoch 1300:  train/loss: 0.3532   valid/loss: 0.3368   train/acc: 0.3750   valid/acc: 0.3750\n",
      "Epoch 1400:  train/loss: 0.3931   valid/loss: 0.3418   train/acc: 0.3750   valid/acc: 0.3750\n",
      "Epoch 1500:  train/loss: 0.3427   valid/loss: 0.3702   train/acc: 0.3750   valid/acc: 0.3750\n",
      "Epoch 1600:  train/loss: 0.3541   valid/loss: 0.3686   train/acc: 0.3750   valid/acc: 0.3750\n",
      "Epoch 1700:  train/loss: 0.3382   valid/loss: 0.3559   train/acc: 0.3750   valid/acc: 0.3750\n",
      "Epoch 1800:  train/loss: 0.3382   valid/loss: 0.3559   train/acc: 0.3750   valid/acc: 0.3750\n",
      "Epoch 1900:  train/loss: 0.3352   valid/loss: 0.3527   train/acc: 0.3750   valid/acc: 0.3750\n",
      "Epoch 2000:  train/loss: 0.3517   valid/loss: 0.3628   train/acc: 0.3750   valid/acc: 0.3750\n",
      "Epoch 2100:  train/loss: 0.3420   valid/loss: 0.3518   train/acc: 0.3734   valid/acc: 0.3750\n",
      "Epoch 2200:  train/loss: 0.3382   valid/loss: 0.3663   train/acc: 0.3750   valid/acc: 0.3750\n",
      "Epoch 2300:  train/loss: 0.3391   valid/loss: 0.3867   train/acc: 0.3750   valid/acc: 0.3750\n",
      "Epoch 2400:  train/loss: 0.3543   valid/loss: 0.3322   train/acc: 0.3750   valid/acc: 0.3750\n",
      "Epoch 2500:  train/loss: 0.3406   valid/loss: 0.3542   train/acc: 0.3750   valid/acc: 0.3750\n",
      "Epoch 2600:  train/loss: 0.3256   valid/loss: 0.3288   train/acc: 0.3750   valid/acc: 0.3750\n",
      "Epoch 2700:  train/loss: 0.3325   valid/loss: 0.3412   train/acc: 0.3750   valid/acc: 0.3750\n",
      "Epoch 2800:  train/loss: 0.3535   valid/loss: 0.3785   train/acc: 0.3750   valid/acc: 0.3750\n",
      "Epoch 2900:  train/loss: 0.3472   valid/loss: 0.3261   train/acc: 0.3750   valid/acc: 0.3929\n",
      "Epoch 3000:  train/loss: 0.3564   valid/loss: 0.3354   train/acc: 0.3750   valid/acc: 0.3690\n",
      "Epoch 3100:  train/loss: 0.3398   valid/loss: 0.3186   train/acc: 0.3750   valid/acc: 0.3929\n",
      "Epoch 3200:  train/loss: 0.3315   valid/loss: 0.3053   train/acc: 0.3750   valid/acc: 0.3690\n",
      "Epoch 3300:  train/loss: 0.3197   valid/loss: 0.3141   train/acc: 0.3734   valid/acc: 0.3750\n",
      "Epoch 3400:  train/loss: 0.3292   valid/loss: 0.3315   train/acc: 0.3734   valid/acc: 0.3631\n",
      "Epoch 3500:  train/loss: 0.3335   valid/loss: 0.3302   train/acc: 0.3750   valid/acc: 0.3750\n",
      "Epoch 3600:  train/loss: 0.3283   valid/loss: 0.3196   train/acc: 0.3750   valid/acc: 0.3750\n",
      "Epoch 3700:  train/loss: 0.3208   valid/loss: 0.3345   train/acc: 0.3750   valid/acc: 0.3750\n",
      "Epoch 3800:  train/loss: 0.3087   valid/loss: 0.3257   train/acc: 0.3750   valid/acc: 0.3750\n",
      "Epoch 3900:  train/loss: 0.3383   valid/loss: 0.3281   train/acc: 0.3750   valid/acc: 0.3750\n",
      "Epoch 4000:  train/loss: 0.3248   valid/loss: 0.3264   train/acc: 0.3750   valid/acc: 0.3750\n",
      "Epoch 4100:  train/loss: 0.3098   valid/loss: 0.3261   train/acc: 0.3766   valid/acc: 0.3690\n",
      "Epoch 4200:  train/loss: 0.3505   valid/loss: 0.3312   train/acc: 0.3766   valid/acc: 0.3750\n",
      "Epoch 4300:  train/loss: 0.3346   valid/loss: 0.3351   train/acc: 0.3750   valid/acc: 0.3750\n",
      "Epoch 4400:  train/loss: 0.3257   valid/loss: 0.3303   train/acc: 0.3719   valid/acc: 0.3869\n",
      "Epoch 4500:  train/loss: 0.3313   valid/loss: 0.3258   train/acc: 0.3750   valid/acc: 0.3810\n",
      "Epoch 4600:  train/loss: 0.3226   valid/loss: 0.3218   train/acc: 0.3734   valid/acc: 0.3750\n",
      "Epoch 4700:  train/loss: 0.3430   valid/loss: 0.3247   train/acc: 0.3750   valid/acc: 0.3690\n",
      "Epoch 4800:  train/loss: 0.3309   valid/loss: 0.3271   train/acc: 0.3719   valid/acc: 0.3810\n",
      "Epoch 4900:  train/loss: 0.3333   valid/loss: 0.3363   train/acc: 0.3750   valid/acc: 0.3810\n",
      "Epoch 5000:  train/loss: 0.3391   valid/loss: 0.3243   train/acc: 0.3656   valid/acc: 0.3810\n",
      "Epoch 5100:  train/loss: 0.3190   valid/loss: 0.3292   train/acc: 0.3750   valid/acc: 0.3750\n",
      "Epoch 5200:  train/loss: 0.3475   valid/loss: 0.3371   train/acc: 0.3750   valid/acc: 0.3750\n",
      "Epoch 5300:  train/loss: 0.3455   valid/loss: 0.3383   train/acc: 0.3750   valid/acc: 0.3750\n",
      "Epoch 5400:  train/loss: 0.3248   valid/loss: 0.3335   train/acc: 0.3750   valid/acc: 0.3750\n",
      "Epoch 5500:  train/loss: 0.3454   valid/loss: 0.3549   train/acc: 0.3750   valid/acc: 0.3750\n",
      "Epoch 5600:  train/loss: 0.3242   valid/loss: 0.3473   train/acc: 0.3750   valid/acc: 0.3750\n",
      "Epoch 5700:  train/loss: 0.3490   valid/loss: 0.3360   train/acc: 0.3750   valid/acc: 0.3810\n",
      "Epoch 5800:  train/loss: 0.3304   valid/loss: 0.3559   train/acc: 0.3750   valid/acc: 0.3750\n",
      "Epoch 5900:  train/loss: 0.3248   valid/loss: 0.3510   train/acc: 0.3750   valid/acc: 0.3810\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(train_dataset, val_dataset, evaluation_step=1, logging_step=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd474ba-917f-4f2a-9c33-2bacaa9c9715",
   "metadata": {},
   "source": [
    "## Visualize the training process and results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c46057-738a-4088-a9b4-d8e6a458f954",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ((ax_tl, ax_tr), (ax_bl, ax_br)) = plt.subplots(2, 2, sharex=True, sharey='row', figsize=(10, 6))\n",
    "ax_tl.set_title('Training set')\n",
    "ax_tr.set_title('Development set')\n",
    "ax_bl.set_xlabel('Iterations')\n",
    "ax_br.set_xlabel('Iterations')\n",
    "ax_bl.set_ylabel('Accuracy')\n",
    "ax_tl.set_ylabel('Loss')\n",
    "\n",
    "colours = iter(plt.rcParams['axes.prop_cycle'].by_key()['color'])\n",
    "ax_tl.plot(trainer.train_epoch_costs[::10], color=next(colours))\n",
    "ax_bl.plot(trainer.train_results['acc'][::10], color=next(colours))\n",
    "ax_tr.plot(trainer.val_costs[::10], color=next(colours))\n",
    "ax_br.plot(trainer.val_results['acc'][::10], color=next(colours))\n",
    "\n",
    "for e in model(test_circuits_l):\n",
    "    print(e)\n",
    "for e in test_data_labels_l:\n",
    "    print(e)\n",
    "\n",
    "# print test accuracy\n",
    "test_acc = acc(model(test_circuits_l), test_data_labels_l)\n",
    "print('Test accuracy:', test_acc.item())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
