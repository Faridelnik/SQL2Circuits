{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b09952d6-99a3-41a5-865f-2170e9ee0247",
   "metadata": {},
   "source": [
    "# Circuit learning module: Lambeq's QuantumTrainer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb811fe4-d729-4a44-838d-9c02db4a644d",
   "metadata": {},
   "source": [
    "This module performs the optimization with Lambeq's native optimizer. Because the circuits are constructed with Lambeq and DisCoPy, this optimizer is the natural choice. The code is based on the workflow presented in https://github.com/CQCL/lambeq/blob/main/docs/examples/quantum_pipeline.ipynb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9a5783f-901a-4bfe-a622-4003b345fb1b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'jaxlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mglob\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpathlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mjax\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m numpy \u001b[38;5;28;01mas\u001b[39;00m np\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m#import numpy as np\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpickle\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\jax\\__init__.py:21\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m _os\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# flake8: noqa: F401\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m config\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     23\u001b[0m   ad,  \u001b[38;5;66;03m# TODO(phawkins): update users to avoid this.\u001b[39;00m\n\u001b[0;32m     24\u001b[0m   argnums_partial,  \u001b[38;5;66;03m# TODO(phawkins): update Haiku to not use this.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     87\u001b[0m   xla_computation,\n\u001b[0;32m     88\u001b[0m )\n\u001b[0;32m     89\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmaps\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m soft_pmap\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\jax\\config.py:19\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mthreading\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Optional\n\u001b[1;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mjax\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m lib\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbool_env\u001b[39m(varname: \u001b[38;5;28mstr\u001b[39m, default: \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[0;32m     22\u001b[0m   \u001b[38;5;124;03m\"\"\"Read an environment variable and interpret it as a boolean.\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \n\u001b[0;32m     24\u001b[0m \u001b[38;5;124;03m  True values are (case insensitive): 'y', 'yes', 't', 'true', 'on', and '1';\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;124;03m  Raises: ValueError if the environment variable is anything else.\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\jax\\lib\\__init__.py:23\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2018 Google LLC\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# This module is largely a wrapper around `jaxlib` that performs version\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# checking on import.\u001b[39;00m\n\u001b[0;32m     18\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     19\u001b[0m   \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda_prng\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcusolver\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrocsolver\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjaxlib\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlapack\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     20\u001b[0m   \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpocketfft\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpytree\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtpu_client\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mversion\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mxla_client\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     21\u001b[0m ]\n\u001b[1;32m---> 23\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjaxlib\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# Must be kept in sync with the jaxlib version in build/test-requirements.txt\u001b[39;00m\n\u001b[0;32m     26\u001b[0m _minimum_jaxlib_version \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m60\u001b[39m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'jaxlib'"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import json\n",
    "import os\n",
    "import glob\n",
    "from pathlib import Path\n",
    "from jax import numpy as np\n",
    "#import numpy as np\n",
    "import pickle\n",
    "import math\n",
    "\n",
    "from discopy.utils import loads\n",
    "from pytket.extensions.qiskit import AerBackend\n",
    "from lambeq import TketModel, NumpyModel\n",
    "from lambeq import QuantumTrainer, SPSAOptimizer\n",
    "from lambeq import Dataset\n",
    "\n",
    "from calibrate import calibrate\n",
    "from utils import read_diagrams, create_labeled_classes, bin_class_loss, multi_class_loss, bin_class_acc, multi_class_acc, visualize_results\n",
    "\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "\n",
    "this_folder = os.path.abspath(os.getcwd())\n",
    "os.environ['TOKENIZERS_PARALLELISM'] = 'true'\n",
    "\n",
    "# Uncomment if you do not want to access GPU\n",
    "#os.environ[\"JAX_PLATFORMS\"] = \"cpu\"\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 3000\n",
    "SEED = 0\n",
    "\n",
    "backend = AerBackend()\n",
    "backend_config = {\n",
    "    'backend': backend,\n",
    "    'compilation': backend.default_compilation_pass(2),\n",
    "    'shots': 3200\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41db742d-857e-4c75-99f7-aa37a34cc077",
   "metadata": {},
   "source": [
    "## Select workload and read the circuits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dfb445f-b9e4-4778-9698-b803126bc352",
   "metadata": {},
   "source": [
    "Select if we perform binary classification or multi-class classification. Give number of qubits to create classes:\n",
    "- 1 qubits -> 2^1 = 2 classes i.e. binary classification\n",
    "- 2 qubits -> 2^2 = 4 classes\n",
    "- ...\n",
    "- 5 qubits -> 2^5 = 32 classes, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98139440-66a4-473d-9353-3eaa5387a032",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select workload\n",
    "workload = \"execution_time\"\n",
    "#workload = \"cardinality\"\n",
    "\n",
    "# Select workload size\n",
    "#workload_size = \"small\"\n",
    "#workload_size = \"medium\"\n",
    "#workload_size = \"large\"\n",
    "workload_size = \"main\"\n",
    "\n",
    "classification = 1\n",
    "layers = 1\n",
    "single_qubit_params = 3\n",
    "n_wire_count = 1\n",
    "loss = multi_class_loss\n",
    "acc = multi_class_acc\n",
    "\n",
    "if classification == 1:\n",
    "    loss = bin_class_loss\n",
    "    acc = bin_class_acc\n",
    "\n",
    "# Access the selected circuits\n",
    "path_name = this_folder + \"//simplified-JOB-diagrams//\" + workload_size + \"//circuits//\" + str(classification) + \"//\" + str(layers) + \"_layer//\" + str(single_qubit_params) + \"_single_qubit_params//\" + str(n_wire_count) + \"_n_wire_count//\"\n",
    "\n",
    "training_circuits_paths = glob.glob(path_name + \"training//[0-9]*.p\")\n",
    "validation_circuits_paths = glob.glob(path_name + \"validation//[0-9]*.p\")\n",
    "test_circuits_paths = glob.glob(path_name + \"test//[0-9]*.p\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f6f00d7-b573-4c5d-a0d6-d5eafc54745e",
   "metadata": {},
   "source": [
    "We read the circuits from the pickled files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff0a551-444c-40a7-bf66-8e929bc49a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_circuits = read_diagrams(training_circuits_paths)\n",
    "validation_circuits = read_diagrams(validation_circuits_paths)\n",
    "test_circuits = read_diagrams(test_circuits_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2da3a7c-6a93-44e9-9640-7e9ead005cb2",
   "metadata": {},
   "source": [
    "## Read training, validation and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774e9f52-69c9-4e1c-8a70-76e1198d12f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data, test_data, validation_data = None, None, None\n",
    "data_path = this_folder + \"//data//\" + workload + \"//\" + workload_size + \"//\"\n",
    "\n",
    "with open(data_path + \"training_data.json\", \"r\") as inputfile:\n",
    "    training_data = json.load(inputfile)['training_data']\n",
    "with open(data_path + \"test_data.json\", \"r\") as inputfile:\n",
    "    test_data = json.load(inputfile)['test_data']\n",
    "with open(data_path + \"validation_data.json\", \"r\") as inputfile:\n",
    "    validation_data = json.load(inputfile)['validation_data']\n",
    "\n",
    "training_data_labels = create_labeled_classes(training_data, classification)\n",
    "test_data_labels = create_labeled_classes(test_data, classification)\n",
    "validation_data_labels = create_labeled_classes(validation_data, classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6cad830-e6c3-4c29-9ce6-0d6bec2794bc",
   "metadata": {},
   "source": [
    "## Prepare circuits for the Lambeq optimizer"
   ]
  },
  {
   "cell_type": "raw",
   "id": "37707d3b-eab2-4787-9f3e-f17589b800cf",
   "metadata": {},
   "source": [
    "#all_circuits = list(training_circuits.values()) + list(test_circuits.values())\n",
    "\n",
    "training_circuits_l = []\n",
    "test_circuits_l = []\n",
    "validation_circuits_l = []\n",
    "\n",
    "training_data_labels_l = []\n",
    "test_data_labels_l = []\n",
    "validation_data_labels_l = []\n",
    "\n",
    "# Organize circuits and labels in correct order into two lists which will be input for training the model\n",
    "for key in training_data_labels:\n",
    "    training_circuits_l.append(training_circuits[key])\n",
    "    training_data_labels_l.append(training_data_labels[key])\n",
    "\n",
    "for key in test_data_labels:\n",
    "    test_circuits_l.append(test_circuits[key])\n",
    "    test_data_labels_l.append(test_data_labels[key])\n",
    "    \n",
    "for key in validation_data_labels:\n",
    "    validation_circuits_l.append(validation_circuits[key])\n",
    "    validation_data_labels_l.append(validation_data_labels[key])\n",
    "\n",
    "all_circuits = training_circuits_l + test_circuits_l + validation_circuits_l\n",
    "\n",
    "#for c in training_circuits_l:\n",
    "#    c.draw(figsize =(20,20))\n",
    "\n",
    "train_syms = set([sym for circuit in training_circuits.values() for sym in circuit.free_symbols])\n",
    "#test_syms = set([sym for circuit in test_circuits.values() for sym in circuit.free_symbols])\n",
    "#val_syms = set([sym for circuit in validation_circuits.values() for sym in circuit.free_symbols])\n",
    "\n",
    "#print(\"Test circuits need to share training circuits' parameters. The parameters that are not covered (should be empty set, set()): \", test_syms.difference(train_syms))\n",
    "#print(\"Validation circuits need to share training circuits' parameters. The parameters that are not covered (should be empty set, set()): \", val_syms.difference(train_syms))\n",
    "\n",
    "print(\"Total number of circuits: \", len(all_circuits))\n",
    "print(\"Total number of variables: \", len(train_syms))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6226b5f5-7ef1-4815-aa5b-3c7bd1d391f9",
   "metadata": {},
   "source": [
    "## Continuously optimize parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80598a13-d79a-4d62-95aa-d15306d88f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_symbols(circs):\n",
    "    return set([sym for circuit in circs.values() for sym in circuit.free_symbols])\n",
    "\n",
    "\n",
    "def construct_data_and_labels(circuits, labels):\n",
    "    circuits_l = []\n",
    "    data_labels_l = []\n",
    "    for key in circuits:\n",
    "        circuits_l.append(circuits[key])\n",
    "        data_labels_l.append(labels[key])\n",
    "    return circuits_l, data_labels_l\n",
    "\n",
    "\n",
    "def select_circuits(base_circuits, selected_circuits):\n",
    "    res = {}\n",
    "    syms = get_symbols(base_circuits)\n",
    "    for c in selected_circuits:\n",
    "        s_syms = set(selected_circuits[c].free_symbols)\n",
    "        if s_syms.difference(syms) == set():\n",
    "            res[c] = selected_circuits[c]\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166e929a-f3e2-48e1-9b25-c7d310c80855",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_metrics = {\"acc\": acc}\n",
    "syms = {}\n",
    "\n",
    "all_training_keys = list(training_circuits.keys())\n",
    "initial_circuit_keys = all_training_keys[:1]\n",
    "\n",
    "current_training_circuits = {}\n",
    "for k in initial_circuit_keys:\n",
    "    current_training_circuits[k] = training_circuits[k]\n",
    "\n",
    "for run, key in enumerate(all_training_keys[1:]):\n",
    "    print(\"Progress: \", round(run/len(all_training_keys), 2))\n",
    "    current_training_circuits[key] = training_circuits[key]\n",
    "    \n",
    "    if run == 0:\n",
    "        syms = get_symbols(current_training_circuits)\n",
    "    else:\n",
    "        if len(syms) == len(get_symbols(current_training_circuits)):\n",
    "            continue\n",
    "    \n",
    "    # Select those circuits from test and validation circuits which share the parameters with the current training circuits\n",
    "    current_validation_circuits = select_circuits(current_training_circuits, validation_circuits)\n",
    "    current_test_circuits = select_circuits(current_training_circuits, test_circuits)\n",
    "    \n",
    "    # Create lists with circuits and their corresponding label\n",
    "    training_circuits_l, training_data_labels_l = construct_data_and_labels(current_training_circuits, training_data_labels)\n",
    "    validation_circuits_l, validation_data_labels_l = construct_data_and_labels(current_validation_circuits, validation_data_labels)\n",
    "    test_circuits_l, test_data_labels_l = construct_data_and_labels(current_test_circuits, test_data_labels)\n",
    "    \n",
    "    print(f\"Number of training circuits: {len(training_circuits_l)}   \",\n",
    "          f\"Number of validation circuits: {len(validation_circuits_l)}   \",\n",
    "          f\"Number of test circuits: {len(test_circuits_l)}   \",\n",
    "          f\"Number of parameters in model: {len(set([sym for circuit in training_circuits_l for sym in circuit.free_symbols]))}\")\n",
    "    \n",
    "    # Select model\n",
    "    #model = TketModel.from_diagrams(training_circuits_l, backend_config = backend_config)\n",
    "    model = NumpyModel.from_diagrams(training_circuits_l, use_jit=True)\n",
    "    \n",
    "    # Initialize the weights from the possible previous training checkpoint\n",
    "    if run > 0:\n",
    "        model.from_checkpoint(this_folder + \"//training_checkpoints//\" + workload + \"//checkpoint_\" + str(run - 1) + \".chk\")\n",
    "    else:\n",
    "        model.initialise_weights()\n",
    "    \n",
    "    trainer = QuantumTrainer(\n",
    "        model,\n",
    "        loss_function=loss,\n",
    "        epochs=EPOCHS,\n",
    "        optimizer=SPSAOptimizer,\n",
    "        optim_hyperparams={'a': 0.0053, 'c': 0.0185, 'A':0.01*EPOCHS},\n",
    "        evaluate_functions=eval_metrics,\n",
    "        evaluate_on_train=True,\n",
    "        verbose = 'text',\n",
    "        seed=SEED\n",
    "        )\n",
    "    \n",
    "    train_dataset = Dataset(training_circuits_l, training_data_labels_l)\n",
    "    val_dataset = Dataset(validation_circuits_l, validation_data_labels_l, shuffle=False)\n",
    "    trainer.fit(train_dataset, val_dataset, evaluation_step=1, logging_step=100)\n",
    "    checkpoint_path = this_folder + \"//training_checkpoints//\" + workload + \"//checkpoint_\" + str(run) + \".chk\"\n",
    "    model.make_checkpoint(checkpoint_path)\n",
    "    visualize_results(model, trainer, test_circuits_l, test_data_labels_l, acc)\n",
    "    syms = get_symbols(current_training_circuits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "572abfc1-cc81-4fdb-b8bb-6813fe658dd6",
   "metadata": {},
   "source": [
    "## Select the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "550e15cc-550a-4c30-8aa5-05f46678ab5f",
   "metadata": {},
   "source": [
    "Select the used model between `TketModel` or `NumpyModel`. `NumpyModel` can use JAX which speeds up the training."
   ]
  },
  {
   "cell_type": "raw",
   "id": "c33975c5-df1a-4979-a374-3ada1a750410",
   "metadata": {},
   "source": [
    "model = TketModel.from_diagrams(training_circuits_l, backend_config=backend_config)\n",
    "#model = NumpyModel.from_diagrams(all_circuits, use_jit=True)\n",
    "model.initialise_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "868cf7e7-fcbf-4bad-b8bc-4ff0e6b29294",
   "metadata": {},
   "source": [
    "## Define loss function and evaluation metrics"
   ]
  },
  {
   "cell_type": "raw",
   "id": "916c6076-3055-434e-b360-f00326f2a92e",
   "metadata": {},
   "source": [
    "eval_metrics = {\"acc\": acc}\n",
    "a, c = calibrate(loss, np.array(model.weights), A = 0.01*EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3bb6805-facb-4ec9-9c38-8d1df42022b2",
   "metadata": {},
   "source": [
    "## Initialize the trainer and the datasets"
   ]
  },
  {
   "cell_type": "raw",
   "id": "13e5627e-7618-4a59-a414-a84eade428cd",
   "metadata": {},
   "source": [
    "trainer = QuantumTrainer(\n",
    "    model,\n",
    "    loss_function=loss,\n",
    "    epochs=EPOCHS,\n",
    "    optimizer=SPSAOptimizer,\n",
    "    optim_hyperparams={'a': 1.0, 'c': 1.0, 'A':0.01*EPOCHS},\n",
    "    evaluate_functions=eval_metrics,\n",
    "    evaluate_on_train=True,\n",
    "    verbose = 'text',\n",
    "    seed=SEED\n",
    ")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6d228cb7-80db-4e35-8276-42cf721b4c2e",
   "metadata": {},
   "source": [
    "train_dataset = Dataset(training_circuits_l, training_data_labels_l)\n",
    "val_dataset = Dataset(validation_circuits_l, validation_data_labels_l, shuffle=False)\n",
    "test_dataset = Dataset(test_circuits_l, test_data_labels_l, shuffle=False)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6da69195-565d-42a2-91bd-794d2728b098",
   "metadata": {},
   "source": [
    "from discopy.quantum import Circuit\n",
    "import numpy\n",
    "import copy\n",
    "SEED = 10\n",
    "rng = numpy.random.default_rng(SEED)\n",
    "c = training_circuits_l[0].dagger()\n",
    "c.draw(figsize=(10, 20))\n",
    "parameter_n = len(c.free_symbols)\n",
    "params = list(c.free_symbols)\n",
    "c = c.lambdify(*params)\n",
    "x00 = -np.array(rng.random(parameter_n))\n",
    "numpy.random.seed(SEED)\n",
    "#for x in x00: print(x)\n",
    "\n",
    "#for i in range(len(params)):\n",
    "#    print(i, params[i])\n",
    "\n",
    "def normalise(predictions):\n",
    "    # apply smoothing to predictions\n",
    "    predictions = np.abs(predictions) + 1e-9\n",
    "    return predictions / predictions.sum()\n",
    "\n",
    "for i in range(31):\n",
    "    #c.draw(figsize=(10, 20))\n",
    "    x0 = copy.deepcopy(x00)\n",
    "    #print(x0)\n",
    "    x0[i] = x0[i] + 0.7\n",
    "    #print(x0)\n",
    "    outputs = Circuit.eval(c(*x0))\n",
    "    print(list(normalise(outputs.array)), params[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd52574-ab2e-4918-a108-f18409d1b25b",
   "metadata": {},
   "source": [
    "## Train the model and visualize"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d110fcc6-80a3-4728-a1be-e53a13f4a8f4",
   "metadata": {},
   "source": [
    "trainer.fit(train_dataset, val_dataset, evaluation_step=1, logging_step=100)\n",
    "visualize_results(model, trainer, test_circuits_l, test_data_labels_l, acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
