{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b09952d6-99a3-41a5-865f-2170e9ee0247",
   "metadata": {},
   "source": [
    "# Circuit learning module: Lambeq manually with SPSA and JAX"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb811fe4-d729-4a44-838d-9c02db4a644d",
   "metadata": {},
   "source": [
    "This module performs the optimization of the parametrized circuit manually compared to Lambeq's automatic QuantumTrainer class. I created this because I wanted to have more control over the optimization process and debug it better. The code is based on the workflow presented in https://github.com/CQCL/Quanthoven."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9a5783f-901a-4bfe-a622-4003b345fb1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import json\n",
    "import os\n",
    "import glob\n",
    "from pathlib import Path\n",
    "from jax import numpy as np\n",
    "from sympy import default_sort_key\n",
    "#import numpy as np\n",
    "import numpy\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from discopy.utils import loads\n",
    "from pytket.extensions.qiskit import AerBackend\n",
    "from pytket.extensions.qulacs import QulacsBackend\n",
    "from pytket.extensions.cirq import CirqStateSampleBackend\n",
    "\n",
    "backend = None\n",
    "\n",
    "from discopy.quantum import Circuit\n",
    "from discopy.tensor import Tensor\n",
    "\n",
    "from utils import read_diagrams, create_labeled_classes, bin_class_loss, multi_class_loss, bin_class_acc, multi_class_acc\n",
    "\n",
    "import jax\n",
    "from jax import jit\n",
    "from noisyopt import minimizeSPSA\n",
    "\n",
    "this_folder = os.path.abspath(os.getcwd())\n",
    "os.environ['TOKENIZERS_PARALLELISM'] = 'true'\n",
    "#os.environ[\"JAX_PLATFORMS\"] = \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238fca40-5d8d-4ace-a65f-693885a8caf8",
   "metadata": {},
   "source": [
    "## Read circuit data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f6f00d7-b573-4c5d-a0d6-d5eafc54745e",
   "metadata": {},
   "source": [
    "We read the circuits from the pickled files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01bac1f9-3bc0-4a25-8f4f-baa2b9c581e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select workload\n",
    "workload = \"small\"\n",
    "#workload = \"medium\"\n",
    "#workload = \"large\"\n",
    "\n",
    "# Select if we perform binary classification or multi-class classification\n",
    "# Give number of qubits to create classes:\n",
    "# 1 -> 2^1 = 2 classes i.e. binary classification\n",
    "# 2 -> 2^2 = 4 classes\n",
    "# ...\n",
    "# 5 -> 2^5 = 32 classes, etc.\n",
    "\n",
    "classification = 2\n",
    "acc = None\n",
    "loss = None\n",
    "\n",
    "if classification == 1:\n",
    "    loss = bin_class_loss\n",
    "    acc = bin_class_acc\n",
    "else:\n",
    "    loss = multi_class_loss\n",
    "    acc = multi_class_acc\n",
    "\n",
    "# Access the selected circuits\n",
    "path_name = this_folder + \"//simplified-JOB-diagrams//\" + workload + \"//circuits//\" + str(classification) + \"//\"\n",
    "\n",
    "training_circuits_paths = glob.glob(path_name + \"training//[0-9]*.p\")\n",
    "validation_circuits_paths = glob.glob(path_name + \"validation//[0-9]*.p\")\n",
    "test_circuits_paths = glob.glob(path_name + \"test//[0-9]*.p\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ff0a551-444c-40a7-bf66-8e929bc49a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_circuits = read_diagrams(training_circuits_paths)\n",
    "validation_circuits = read_diagrams(validation_circuits_paths)\n",
    "test_circuits = read_diagrams(test_circuits_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2da3a7c-6a93-44e9-9640-7e9ead005cb2",
   "metadata": {},
   "source": [
    "## Read training and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "774e9f52-69c9-4e1c-8a70-76e1198d12f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data, test_data, validation_data = None, None, None\n",
    "data_path = this_folder + \"//data//\" + workload + \"//\"\n",
    "\n",
    "with open(data_path + \"training_data.json\", \"r\") as inputfile:\n",
    "    training_data = json.load(inputfile)['training_data']\n",
    "with open(data_path + \"test_data.json\", \"r\") as inputfile:\n",
    "    test_data = json.load(inputfile)['test_data']\n",
    "with open(data_path + \"validation_data.json\", \"r\") as inputfile:\n",
    "    validation_data = json.load(inputfile)['validation_data']\n",
    "\n",
    "training_data_labels = create_labeled_classes(training_data, classification)\n",
    "test_data_labels = create_labeled_classes(test_data, classification)\n",
    "validation_data_labels = create_labeled_classes(validation_data, classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6cad830-e6c3-4c29-9ce6-0d6bec2794bc",
   "metadata": {},
   "source": [
    "## Lambeq optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce559dbf-2b4b-4853-82ed-58832aa11e61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test circuits need to share training circuits' parameters. The parameters that are not covered (should be empty set, set()):  set()\n",
      "Validation circuits need to share training circuits' parameters. The parameters that are not covered (should be empty set, set()):  set()\n",
      "Total number of circuits:  29\n",
      "Total number of variables:  91\n"
     ]
    }
   ],
   "source": [
    "#all_circuits = list(training_circuits.values()) + list(test_circuits.values())\n",
    "\n",
    "training_circuits_l = []\n",
    "test_circuits_l = []\n",
    "validation_circuits_l = []\n",
    "\n",
    "training_data_labels_l = []\n",
    "test_data_labels_l = []\n",
    "validation_data_labels_l = []\n",
    "\n",
    "# Organize circuits and labels in correct order into two lists which will be input for training the model\n",
    "for key in training_data_labels:\n",
    "    training_circuits_l.append(training_circuits[key])\n",
    "    training_data_labels_l.append(training_data_labels[key])\n",
    "\n",
    "for key in test_data_labels:\n",
    "    test_circuits_l.append(test_circuits[key])\n",
    "    test_data_labels_l.append(test_data_labels[key])\n",
    "    \n",
    "for key in validation_data_labels:\n",
    "    validation_circuits_l.append(validation_circuits[key])\n",
    "    validation_data_labels_l.append(validation_data_labels[key])\n",
    "\n",
    "all_circuits = training_circuits_l + test_circuits_l + validation_circuits_l\n",
    "\n",
    "train_syms = set([sym for circuit in training_circuits.values() for sym in circuit.free_symbols])\n",
    "test_syms = set([sym for circuit in test_circuits.values() for sym in circuit.free_symbols])\n",
    "val_syms = set([sym for circuit in validation_circuits.values() for sym in circuit.free_symbols])\n",
    "\n",
    "print(\"Test circuits need to share training circuits' parameters. The parameters that are not covered (should be empty set, set()): \", test_syms.difference(train_syms))\n",
    "print(\"Validation circuits need to share training circuits' parameters. The parameters that are not covered (should be empty set, set()): \", val_syms.difference(train_syms))\n",
    "\n",
    "print(\"Total number of circuits: \", len(all_circuits))\n",
    "print(\"Total number of variables: \", len(train_syms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c84f333-8670-492f-b85f-20467a2f7d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_labels_l = np.array(training_data_labels_l)\n",
    "test_data_labels_l = np.array(test_data_labels_l)\n",
    "validation_data_labels_l = np.array(validation_data_labels_l)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "572abfc1-cc81-4fdb-b8bb-6813fe658dd6",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e772e8c8-b747-4c19-8eef-7cc038194d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = sorted(\n",
    "    train_syms,\n",
    "    key=default_sort_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "04c65634-fa13-47b3-915c-83361d0e1baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_pred_fn(circuits):\n",
    "    if backend:\n",
    "        compiled_circuits1 = backend.get_compiled_circuits([c.to_tk() for c in circuits])\n",
    "        circuits = [Circuit.from_tk(c) for c in compiled_circuits1]\n",
    "        \n",
    "    circuit_fns = [c.lambdify(*parameters) for c in circuits]\n",
    "    \n",
    "    def predict(params):\n",
    "        outputs = Circuit.eval(*(c(*params) for c in circuit_fns), backend = backend)\n",
    "        res = []\n",
    "        \n",
    "        for output in outputs:\n",
    "            predictions = np.abs(output.array) + 1e-9\n",
    "            ratio = predictions / predictions.sum()\n",
    "            res.append(ratio)\n",
    "            \n",
    "        return np.array(res)\n",
    "    return predict\n",
    "\n",
    "train_pred_fn = jit(make_pred_fn(training_circuits_l))\n",
    "dev_pred_fn = jit(make_pred_fn(validation_circuits_l))\n",
    "test_pred_fn = make_pred_fn(test_circuits_l)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "868cf7e7-fcbf-4bad-b8bc-4ff0e6b29294",
   "metadata": {},
   "source": [
    "## Loss function and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f376b4aa-0ec6-4037-80eb-935aa75a2f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_cost_fn(pred_fn, labels):\n",
    "    def cost_fn(params, **kwargs):\n",
    "        predictions = pred_fn(params)\n",
    "\n",
    "        cost = loss(predictions, labels) #-np.sum(labels * np.log(predictions)) / len(labels)  # binary cross-entropy loss\n",
    "        costs.append(cost)\n",
    "\n",
    "        accuracy = acc(predictions, labels) #np.sum(np.round(predictions) == labels) / len(labels) / 2  # half due to double-counting\n",
    "        accuracies.append(accuracy)\n",
    "\n",
    "        return cost\n",
    "\n",
    "    costs, accuracies = [], []\n",
    "    return cost_fn, costs, accuracies"
   ]
  },
  {
   "cell_type": "raw",
   "id": "eb0b4d9d-ee5a-4204-b4a5-9ad14ae46979",
   "metadata": {},
   "source": [
    "# Code to debug why Hadamard transform was positioned wrong\n",
    "\n",
    "#print(training_data_labels_l)\n",
    "#for c in training_circuits_l:\n",
    "#    c.draw(figsize=(10, 20))\n",
    "\n",
    "from discopy.quantum import Circuit\n",
    "import numpy\n",
    "import copy\n",
    "SEED = 10\n",
    "rng = numpy.random.default_rng(SEED)\n",
    "c = training_circuits_l[0].dagger()\n",
    "c.draw(figsize=(10, 20))\n",
    "parameter_n = len(c.free_symbols)\n",
    "params = list(c.free_symbols)\n",
    "c = c.lambdify(*params)\n",
    "x00 = -np.array(rng.random(parameter_n))\n",
    "numpy.random.seed(SEED)\n",
    "#for x in x00: print(x)\n",
    "\n",
    "#for i in range(len(params)):\n",
    "#    print(i, params[i])\n",
    "\n",
    "def normalise(predictions):\n",
    "    # apply smoothing to predictions\n",
    "    predictions = np.abs(predictions) + 1e-9\n",
    "    return predictions / predictions.sum()\n",
    "\n",
    "outputss = []\n",
    "\n",
    "#for i in range(31):\n",
    "#c.draw(figsize=(10, 20))\n",
    "x0 = copy.deepcopy(x00)\n",
    "#print(x0)\n",
    "#x0[i] = x0[i] + 0.7\n",
    "#print(x0)\n",
    "outputs = Circuit.eval(c(*x0))\n",
    "#print(list(normalise(outputs.array)), params[i])\n",
    "#print(list(outputs.array), params[i])\n",
    "outputss.append(list(outputs.array))\n",
    "\n",
    "for o in outputss:\n",
    "    print(acc(o, [0,0,1,0]))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "66b315a1-2b74-4955-835f-09788aacdeeb",
   "metadata": {},
   "source": [
    "def normalise(predictions):\n",
    "    # apply smoothing to predictions\n",
    "    predictions = np.abs(predictions) + 1e-9\n",
    "    return predictions / predictions.sum()\n",
    "\n",
    "y_hat = normalise(np.array(outputss[0]).flatten())\n",
    "y = np.array([0,0,1,0]).flatten()\n",
    "\n",
    "print(y_hat, y)\n",
    "print(np.round(y_hat))\n",
    "print(np.sum(np.round(y_hat) == y))\n",
    "print((np.sum(np.round(y_hat) == y) / len(y)) / 2)\n",
    "\n",
    "max_index = number_list.index(max(y_hat))\n",
    "res_vector = [0]*len(y)\n",
    "res_vector[max_index] = 1\n",
    "\n",
    "\n",
    "#print(loss(outputss[0], [0,0,1,0]))\n",
    "#print(acc(outputss[0], [0,0,1,0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3bb6805-facb-4ec9-9c38-8d1df42022b2",
   "metadata": {},
   "source": [
    "## Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "575f6418-781f-4d16-bf0f-7dc9dacdf0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 20000\n",
    "SEED = 0\n",
    "\n",
    "# This avoids TracerArrayConversionError from jax\n",
    "Tensor.np = np\n",
    "\n",
    "import numpy\n",
    "\n",
    "rng = numpy.random.default_rng(SEED)\n",
    "init_params_spsa = np.array(rng.random(len(parameters)))\n",
    "numpy.random.seed(SEED)\n",
    "\n",
    "#print(jax.make_jaxpr(train_pred_fn)(init_params_spsa))\n",
    "\n",
    "train_cost_fn, train_costs, train_accs = make_cost_fn(train_pred_fn, training_data_labels_l)\n",
    "dev_cost_fn, dev_costs, dev_accs = make_cost_fn(dev_pred_fn, validation_data_labels_l)\n",
    "\n",
    "def callback_fn(xk):\n",
    "    valid_loss = dev_cost_fn(xk)\n",
    "    train_loss = round(train_costs[-1], 4)\n",
    "    train_acc = round(train_accs[-1], 4)\n",
    "    valid_acc = round(dev_accs[-1], 4)\n",
    "    iters = int(len(train_accs)/2)\n",
    "    if iters % 100 == 0:\n",
    "        print(\n",
    "                #f\"Params = {xk}, \"\n",
    "                f\"Epoch: {iters}   \",\n",
    "                f\"train/loss: {train_loss}   \",\n",
    "                f\"valid/loss: {round(valid_loss, 4)}   \",\n",
    "                f\"train/acc: {train_acc}   \",\n",
    "                f\"valid/acc: {valid_acc}\"\n",
    "            )\n",
    "    return valid_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95052c87-ffb7-4c4f-952f-e63d9c54b2ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 100    train/loss: 6.24429988861084    valid/loss: 2.416800022125244    train/acc: 0.4211    valid/acc: 0.2\n",
      "Epoch: 200    train/loss: 7.261999607086182    valid/loss: 1.9825999736785889    train/acc: 0.1579    valid/acc: 0.2\n",
      "Epoch: 300    train/loss: 6.104599952697754    valid/loss: 1.7734999656677246    train/acc: 0.5789    valid/acc: 0.2\n",
      "Epoch: 400    train/loss: 6.012499809265137    valid/loss: 2.0212998390197754    train/acc: 0.2632    valid/acc: 0.0\n",
      "Epoch: 500    train/loss: 6.299999713897705    valid/loss: 2.0515999794006348    train/acc: 0.3158    valid/acc: 0.0\n",
      "Epoch: 600    train/loss: 6.141900062561035    valid/loss: 1.9670000076293945    train/acc: 0.4211    valid/acc: 0.0\n",
      "Epoch: 700    train/loss: 5.921599864959717    valid/loss: 2.5423998832702637    train/acc: 0.4211    valid/acc: 0.2\n",
      "Epoch: 800    train/loss: 6.29449987411499    valid/loss: 2.4701998233795166    train/acc: 0.3684    valid/acc: 0.2\n",
      "Epoch: 900    train/loss: 6.480099678039551    valid/loss: 2.36299991607666    train/acc: 0.4211    valid/acc: 0.2\n",
      "Epoch: 1000    train/loss: 6.968699932098389    valid/loss: 2.086199998855591    train/acc: 0.3158    valid/acc: 0.2\n",
      "Epoch: 1100    train/loss: 6.252799987792969    valid/loss: 2.098599910736084    train/acc: 0.4211    valid/acc: 0.2\n",
      "Epoch: 1200    train/loss: 6.492099761962891    valid/loss: 2.0597000122070312    train/acc: 0.3158    valid/acc: 0.2\n",
      "Epoch: 1300    train/loss: 6.999799728393555    valid/loss: 2.1594998836517334    train/acc: 0.4737    valid/acc: 0.2\n",
      "Epoch: 1400    train/loss: 6.405699729919434    valid/loss: 2.089099884033203    train/acc: 0.2632    valid/acc: 0.2\n",
      "Epoch: 1500    train/loss: 6.470399856567383    valid/loss: 2.148900032043457    train/acc: 0.4211    valid/acc: 0.2\n",
      "Epoch: 1600    train/loss: 6.170199871063232    valid/loss: 2.2152998447418213    train/acc: 0.4737    valid/acc: 0.2\n",
      "Epoch: 1700    train/loss: 6.404399871826172    valid/loss: 2.3252999782562256    train/acc: 0.2632    valid/acc: 0.2\n",
      "Epoch: 1800    train/loss: 6.023599624633789    valid/loss: 2.1877999305725098    train/acc: 0.4211    valid/acc: 0.2\n",
      "Epoch: 1900    train/loss: 6.2428998947143555    valid/loss: 2.1385998725891113    train/acc: 0.3158    valid/acc: 0.2\n",
      "Epoch: 2000    train/loss: 6.399199962615967    valid/loss: 2.0976998805999756    train/acc: 0.4211    valid/acc: 0.2\n",
      "Epoch: 2100    train/loss: 5.291599750518799    valid/loss: 2.063699960708618    train/acc: 0.4211    valid/acc: 0.2\n",
      "Epoch: 2200    train/loss: 6.330100059509277    valid/loss: 1.8194999694824219    train/acc: 0.4211    valid/acc: 0.2\n",
      "Epoch: 2300    train/loss: 6.548599720001221    valid/loss: 1.956299901008606    train/acc: 0.3158    valid/acc: 0.2\n",
      "Epoch: 2400    train/loss: 6.696699619293213    valid/loss: 2.1412999629974365    train/acc: 0.2632    valid/acc: 0.2\n",
      "Epoch: 2500    train/loss: 5.6468000411987305    valid/loss: 1.8488999605178833    train/acc: 0.4211    valid/acc: 0.2\n",
      "Epoch: 2600    train/loss: 6.1066999435424805    valid/loss: 1.8125998973846436    train/acc: 0.4211    valid/acc: 0.2\n",
      "Epoch: 2700    train/loss: 5.9653000831604    valid/loss: 1.7323999404907227    train/acc: 0.4737    valid/acc: 0.4\n",
      "Epoch: 2800    train/loss: 6.5320000648498535    valid/loss: 1.674799919128418    train/acc: 0.4211    valid/acc: 0.4\n",
      "Epoch: 2900    train/loss: 7.230999946594238    valid/loss: 1.7089999914169312    train/acc: 0.4211    valid/acc: 0.4\n",
      "Epoch: 3000    train/loss: 6.191299915313721    valid/loss: 1.6881999969482422    train/acc: 0.4211    valid/acc: 0.4\n",
      "Epoch: 3100    train/loss: 5.228399753570557    valid/loss: 1.6414999961853027    train/acc: 0.5789    valid/acc: 0.4\n",
      "Epoch: 3200    train/loss: 5.208399772644043    valid/loss: 1.6416999101638794    train/acc: 0.5263    valid/acc: 0.4\n",
      "Epoch: 3300    train/loss: 5.8907999992370605    valid/loss: 1.6204999685287476    train/acc: 0.5789    valid/acc: 0.4\n",
      "Epoch: 3400    train/loss: 5.932499885559082    valid/loss: 1.6273999214172363    train/acc: 0.4211    valid/acc: 0.4\n",
      "Epoch: 3500    train/loss: 5.824599742889404    valid/loss: 1.7339999675750732    train/acc: 0.4737    valid/acc: 0.4\n",
      "Epoch: 3600    train/loss: 5.843499660491943    valid/loss: 1.6761999130249023    train/acc: 0.4211    valid/acc: 0.4\n",
      "Epoch: 3700    train/loss: 5.735699653625488    valid/loss: 1.7268999814987183    train/acc: 0.4737    valid/acc: 0.4\n",
      "Epoch: 3800    train/loss: 5.763400077819824    valid/loss: 1.6689999103546143    train/acc: 0.4211    valid/acc: 0.4\n",
      "Epoch: 3900    train/loss: 5.751899719238281    valid/loss: 1.6617000102996826    train/acc: 0.4211    valid/acc: 0.4\n",
      "Epoch: 4000    train/loss: 5.878499984741211    valid/loss: 1.5898000001907349    train/acc: 0.4211    valid/acc: 0.4\n",
      "Epoch: 4100    train/loss: 5.490299701690674    valid/loss: 1.6469999551773071    train/acc: 0.4211    valid/acc: 0.4\n",
      "Epoch: 4200    train/loss: 5.399099826812744    valid/loss: 1.7086999416351318    train/acc: 0.4737    valid/acc: 0.4\n",
      "Epoch: 4300    train/loss: 5.878200054168701    valid/loss: 1.7168999910354614    train/acc: 0.4737    valid/acc: 0.4\n",
      "Epoch: 4400    train/loss: 5.86899995803833    valid/loss: 1.6822999715805054    train/acc: 0.3684    valid/acc: 0.4\n",
      "Epoch: 4500    train/loss: 6.077600002288818    valid/loss: 1.654599905014038    train/acc: 0.2632    valid/acc: 0.4\n",
      "Epoch: 4600    train/loss: 5.65939998626709    valid/loss: 1.6272999048233032    train/acc: 0.3684    valid/acc: 0.4\n",
      "Epoch: 4700    train/loss: 6.171799659729004    valid/loss: 1.5938999652862549    train/acc: 0.5263    valid/acc: 0.4\n",
      "Epoch: 4800    train/loss: 5.644799709320068    valid/loss: 1.6304999589920044    train/acc: 0.5263    valid/acc: 0.4\n",
      "Epoch: 4900    train/loss: 6.7581000328063965    valid/loss: 1.555400013923645    train/acc: 0.3684    valid/acc: 0.4\n",
      "Epoch: 5000    train/loss: 5.993299961090088    valid/loss: 1.5281000137329102    train/acc: 0.5263    valid/acc: 0.4\n",
      "Epoch: 5100    train/loss: 5.729499816894531    valid/loss: 1.5405999422073364    train/acc: 0.3684    valid/acc: 0.4\n",
      "Epoch: 5200    train/loss: 6.111199855804443    valid/loss: 1.517799973487854    train/acc: 0.5789    valid/acc: 0.4\n",
      "Epoch: 5300    train/loss: 5.223700046539307    valid/loss: 1.5203999280929565    train/acc: 0.5789    valid/acc: 0.4\n",
      "Epoch: 5400    train/loss: 5.736700057983398    valid/loss: 1.5513999462127686    train/acc: 0.5263    valid/acc: 0.4\n",
      "Epoch: 5500    train/loss: 6.042799949645996    valid/loss: 1.558899998664856    train/acc: 0.5263    valid/acc: 0.4\n",
      "Epoch: 5600    train/loss: 6.468400001525879    valid/loss: 1.559499979019165    train/acc: 0.4211    valid/acc: 0.4\n",
      "Epoch: 5700    train/loss: 5.82480001449585    valid/loss: 1.5723999738693237    train/acc: 0.3684    valid/acc: 0.4\n",
      "Epoch: 5800    train/loss: 6.1331000328063965    valid/loss: 1.5795999765396118    train/acc: 0.5263    valid/acc: 0.4\n",
      "Epoch: 5900    train/loss: 5.8815999031066895    valid/loss: 1.545799970626831    train/acc: 0.2632    valid/acc: 0.4\n",
      "Epoch: 6000    train/loss: 6.0269999504089355    valid/loss: 1.5318999290466309    train/acc: 0.3684    valid/acc: 0.4\n",
      "Epoch: 6100    train/loss: 5.549699783325195    valid/loss: 1.5209999084472656    train/acc: 0.5263    valid/acc: 0.4\n",
      "Epoch: 6200    train/loss: 5.853699684143066    valid/loss: 1.5501999855041504    train/acc: 0.4737    valid/acc: 0.4\n",
      "Epoch: 6300    train/loss: 5.883699893951416    valid/loss: 1.5411999225616455    train/acc: 0.4211    valid/acc: 0.4\n",
      "Epoch: 6400    train/loss: 5.662499904632568    valid/loss: 1.5895999670028687    train/acc: 0.4211    valid/acc: 0.4\n",
      "Epoch: 6500    train/loss: 5.703099727630615    valid/loss: 1.552799940109253    train/acc: 0.4737    valid/acc: 0.4\n",
      "Epoch: 6600    train/loss: 5.467499732971191    valid/loss: 1.5865999460220337    train/acc: 0.5789    valid/acc: 0.4\n",
      "Epoch: 6700    train/loss: 6.128999710083008    valid/loss: 1.5882999897003174    train/acc: 0.4737    valid/acc: 0.4\n",
      "Epoch: 6800    train/loss: 5.503900051116943    valid/loss: 1.5885999202728271    train/acc: 0.5263    valid/acc: 0.4\n",
      "Epoch: 6900    train/loss: 5.868899822235107    valid/loss: 1.565999984741211    train/acc: 0.5263    valid/acc: 0.4\n",
      "Epoch: 7000    train/loss: 5.496999740600586    valid/loss: 1.5618000030517578    train/acc: 0.5263    valid/acc: 0.4\n",
      "Epoch: 7100    train/loss: 5.3892998695373535    valid/loss: 1.5762999057769775    train/acc: 0.5789    valid/acc: 0.4\n",
      "Epoch: 7200    train/loss: 5.040899753570557    valid/loss: 1.5478999614715576    train/acc: 0.5789    valid/acc: 0.4\n",
      "Epoch: 7300    train/loss: 5.738499641418457    valid/loss: 1.5433999300003052    train/acc: 0.4737    valid/acc: 0.4\n",
      "Epoch: 7400    train/loss: 6.047399997711182    valid/loss: 1.5777000188827515    train/acc: 0.5263    valid/acc: 0.4\n",
      "Epoch: 7500    train/loss: 5.486499786376953    valid/loss: 1.5520999431610107    train/acc: 0.5789    valid/acc: 0.4\n",
      "Epoch: 7600    train/loss: 5.076299667358398    valid/loss: 1.5342999696731567    train/acc: 0.6316    valid/acc: 0.4\n",
      "Epoch: 7700    train/loss: 5.124599933624268    valid/loss: 1.517300009727478    train/acc: 0.5789    valid/acc: 0.4\n",
      "Epoch: 7800    train/loss: 5.344399929046631    valid/loss: 1.5161999464035034    train/acc: 0.4211    valid/acc: 0.4\n"
     ]
    }
   ],
   "source": [
    "#j = 1\n",
    "#for i in np.linspace(0,20,201):\n",
    "#new_a = np.round(i, 1)\n",
    "#print(new_a)\n",
    "\n",
    "result = minimizeSPSA(train_cost_fn, x0=init_params_spsa, a = 0.05, c = 0.2, niter=EPOCHS, callback=callback_fn)\n",
    "print(result)\n",
    "\n",
    "# print test accuracy\n",
    "test_cost_fn, _, test_accs = make_cost_fn(test_pred_fn, test_data_labels_l)\n",
    "test_cost_fn(result.x)\n",
    "print('Test accuracy:', test_accs[0])\n",
    "train_cost_fn(result.x)\n",
    "print('Training accuracy:', train_accs[0])\n",
    "\n",
    "#with open(this_folder + \"//results//result_2_\" + str(j) + \".p\", \"wb\") as f:\n",
    "#    pickle.dump(result, f)\n",
    "#with open(this_folder + \"//results//result_stats_2_\" + str(j) + \".p\", \"wb\") as f:\n",
    "#    stats = {\"train_costs\":train_costs,\"train_accs\":train_accs,\"dev_costs\":dev_costs,\"dev_accs\":dev_accs, \"a\" : new_a}\n",
    "#    pickle.dump(stats, f)\n",
    "#j+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4db293b-aa47-4a8d-a2ec-ee60b644fd18",
   "metadata": {},
   "outputs": [],
   "source": [
    "#result = minimizeSPSA(train_cost_fn, x0=init_params_spsa, a = 1.0, c = 0.2, niter=EPOCHS, callback=dev_cost_fn, disp=False)\n",
    "#print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537aa180-ea99-48b1-90a3-097e4a9ecc6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ((ax_tl, ax_tr), (ax_bl, ax_br)) = plt.subplots(2, 2, sharex=True, sharey='row', figsize=(10, 6))\n",
    "ax_tl.set_title('Training set')\n",
    "ax_tr.set_title('Development set')\n",
    "ax_bl.set_xlabel('Iterations')\n",
    "ax_br.set_xlabel('Iterations')\n",
    "ax_bl.set_ylabel('Accuracy')\n",
    "ax_tl.set_ylabel('Loss')\n",
    "\n",
    "colours = iter(plt.rcParams['axes.prop_cycle'].by_key()['color'])\n",
    "ax_tl.plot(train_costs[1::2], color=next(colours))  # training evaluates twice per iteration\n",
    "ax_bl.plot(train_accs[1::2], color=next(colours))   # so take every other entry\n",
    "ax_tr.plot(dev_costs, color=next(colours))\n",
    "ax_br.plot(dev_accs, color=next(colours))\n",
    "\n",
    "# print test accuracy\n",
    "test_cost_fn, _, test_accs = make_cost_fn(test_pred_fn, test_data_labels_l)\n",
    "test_cost_fn(result.x)\n",
    "print('Test accuracy:', test_accs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ecdc65-e90a-45dc-973c-074f6c7415e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
