{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b09952d6-99a3-41a5-865f-2170e9ee0247",
   "metadata": {},
   "source": [
    "# Circuit learning module: Lambeq manually with SPSA and JAX"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb811fe4-d729-4a44-838d-9c02db4a644d",
   "metadata": {},
   "source": [
    "This module performs the optimization of the parametrized circuit manually compared to Lambeq's automatic QuantumTrainer class. I created this because I wanted to have more control over the optimization process and debug it better. The code is based on the workflow presented in https://github.com/CQCL/Quanthoven."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9a5783f-901a-4bfe-a622-4003b345fb1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "from math import ceil\n",
    "from pathlib import Path\n",
    "from jax import numpy as np\n",
    "from sympy import default_sort_key\n",
    "import numpy\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import jax\n",
    "from jax import jit\n",
    "from noisyopt import minimizeSPSA, minimizeCompass\n",
    "\n",
    "from discopy.quantum import Circuit\n",
    "from discopy.tensor import Tensor\n",
    "from discopy.utils import loads\n",
    "#from pytket.extensions.qiskit import AerBackend\n",
    "#from pytket.extensions.qulacs import QulacsBackend\n",
    "#from pytket.extensions.cirq import CirqStateSampleBackend\n",
    "backend = None\n",
    "\n",
    "from utils import get_symbols, construct_data_and_labels, select_circuits, read_diagrams, create_labeled_classes, bin_class_loss, multi_class_loss, bin_class_acc, multi_class_acc, visualize_result_noisyopt\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "this_folder = os.path.abspath(os.getcwd())\n",
    "os.environ['TOKENIZERS_PARALLELISM'] = 'true'\n",
    "#os.environ[\"JAX_PLATFORMS\"] = \"cpu\"\n",
    "\n",
    "EPOCHS = 500\n",
    "SEED = 0\n",
    "\n",
    "# This avoids TracerArrayConversionError from jax\n",
    "Tensor.np = np\n",
    "\n",
    "rng = numpy.random.default_rng(SEED)\n",
    "numpy.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238fca40-5d8d-4ace-a65f-693885a8caf8",
   "metadata": {},
   "source": [
    "## Read circuit data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f6f00d7-b573-4c5d-a0d6-d5eafc54745e",
   "metadata": {},
   "source": [
    "We read the circuits from the pickled files. Select if we perform binary classification or multi-class classification. Give number of qubits to create classes:\n",
    "- 1 qubits -> 2^1 = 2 classes i.e. binary classification\n",
    "- 2 qubits -> 2^2 = 4 classes\n",
    "- ...\n",
    "- 5 qubits -> 2^5 = 32 classes, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01bac1f9-3bc0-4a25-8f4f-baa2b9c581e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select workload\n",
    "workload = \"execution_time\"\n",
    "#workload = \"cardinality\"\n",
    "\n",
    "# Select workload size\n",
    "#workload_size = \"small\"\n",
    "#workload_size = \"medium\"\n",
    "#workload_size = \"large\"\n",
    "workload_size = \"main\"\n",
    "\n",
    "classification = 2\n",
    "layers = 1\n",
    "single_qubit_params = 3\n",
    "n_wire_count = 1\n",
    "\n",
    "loss = multi_class_loss\n",
    "acc = multi_class_acc\n",
    "\n",
    "if classification == 1:\n",
    "    loss = bin_class_loss\n",
    "    acc = bin_class_acc\n",
    "\n",
    "# Access the selected circuits\n",
    "path_name = this_folder + \"//simplified-JOB-diagrams//\" + workload + \"//\" + workload_size + \"//circuits//\" + str(classification) + \"//\" + str(layers) + \"_layer//\" + str(single_qubit_params) + \"_single_qubit_params//\" + str(n_wire_count) + \"_n_wire_count//\"\n",
    "\n",
    "training_circuits_paths = glob.glob(path_name + \"training//[0-9]*.p\")\n",
    "validation_circuits_paths = glob.glob(path_name + \"validation//[0-9]*.p\")\n",
    "test_circuits_paths = glob.glob(path_name + \"test//[0-9]*.p\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ff0a551-444c-40a7-bf66-8e929bc49a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_circuits = read_diagrams(training_circuits_paths)\n",
    "validation_circuits = read_diagrams(validation_circuits_paths)\n",
    "test_circuits = read_diagrams(test_circuits_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2da3a7c-6a93-44e9-9640-7e9ead005cb2",
   "metadata": {},
   "source": [
    "## Read training and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "774e9f52-69c9-4e1c-8a70-76e1198d12f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data, test_data, validation_data = None, None, None\n",
    "data_path = this_folder + \"//data//\" + workload + \"//\" + workload_size + \"//\"\n",
    "\n",
    "with open(data_path + \"training_data.json\", \"r\") as inputfile:\n",
    "    training_data = json.load(inputfile)['training_data']\n",
    "with open(data_path + \"test_data.json\", \"r\") as inputfile:\n",
    "    test_data = json.load(inputfile)['test_data']\n",
    "with open(data_path + \"validation_data.json\", \"r\") as inputfile:\n",
    "    validation_data = json.load(inputfile)['validation_data']\n",
    "\n",
    "training_data_labels = create_labeled_classes(training_data, classification)\n",
    "test_data_labels = create_labeled_classes(test_data, classification)\n",
    "validation_data_labels = create_labeled_classes(validation_data, classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6cad830-e6c3-4c29-9ce6-0d6bec2794bc",
   "metadata": {},
   "source": [
    "## Lambeq optimizer"
   ]
  },
  {
   "cell_type": "raw",
   "id": "be555e95-e7aa-4f1b-bf4d-29acd66056b0",
   "metadata": {},
   "source": [
    "#all_circuits = list(training_circuits.values()) + list(test_circuits.values())\n",
    "\n",
    "training_circuits_l = []\n",
    "test_circuits_l = []\n",
    "validation_circuits_l = []\n",
    "\n",
    "training_data_labels_l = []\n",
    "test_data_labels_l = []\n",
    "validation_data_labels_l = []\n",
    "\n",
    "# Organize circuits and labels in correct order into two lists which will be input for training the model\n",
    "for key in training_data_labels:\n",
    "    training_circuits_l.append(training_circuits[key])\n",
    "    training_data_labels_l.append(training_data_labels[key])\n",
    "\n",
    "for key in test_data_labels:\n",
    "    test_circuits_l.append(test_circuits[key])\n",
    "    test_data_labels_l.append(test_data_labels[key])\n",
    "    \n",
    "for key in validation_data_labels:\n",
    "    validation_circuits_l.append(validation_circuits[key])\n",
    "    validation_data_labels_l.append(validation_data_labels[key])\n",
    "\n",
    "all_circuits = training_circuits_l + test_circuits_l + validation_circuits_l\n",
    "\n",
    "train_syms = set([sym for circuit in training_circuits.values() for sym in circuit.free_symbols])\n",
    "test_syms = set([sym for circuit in test_circuits.values() for sym in circuit.free_symbols])\n",
    "val_syms = set([sym for circuit in validation_circuits.values() for sym in circuit.free_symbols])\n",
    "\n",
    "print(\"Test circuits need to share training circuits' parameters. The parameters that are not covered (should be empty set, set()): \", test_syms.difference(train_syms))\n",
    "print(\"Validation circuits need to share training circuits' parameters. The parameters that are not covered (should be empty set, set()): \", val_syms.difference(train_syms))\n",
    "\n",
    "print(\"Total number of circuits: \", len(all_circuits))\n",
    "print(\"Total number of variables: \", len(train_syms))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ecd5daca-fdba-44fe-961d-5b9b9c3c68cb",
   "metadata": {},
   "source": [
    "training_data_labels_l = np.array(training_data_labels_l)\n",
    "test_data_labels_l = np.array(test_data_labels_l)\n",
    "validation_data_labels_l = np.array(validation_data_labels_l)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "572abfc1-cc81-4fdb-b8bb-6813fe658dd6",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "raw",
   "id": "75f97a9a-c5fc-4d9b-920f-9eb0795ca018",
   "metadata": {},
   "source": [
    "parameters = sorted(\n",
    "    train_syms,\n",
    "    key=default_sort_key)\n",
    "\n",
    "rng = numpy.random.default_rng(SEED)\n",
    "init_params_spsa = np.array(rng.random(len(parameters)))\n",
    "numpy.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04c65634-fa13-47b3-915c-83361d0e1baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_pred_fn(circuits):\n",
    "    # In the case we want to use other backends. \n",
    "    # Currently does not work properly.\n",
    "    if backend:\n",
    "        compiled_circuits1 = backend.get_compiled_circuits([c.to_tk() for c in circuits])\n",
    "        circuits = [Circuit.from_tk(c) for c in compiled_circuits1]\n",
    "        \n",
    "    circuit_fns = [c.lambdify(*parameters) for c in circuits]\n",
    "    \n",
    "    def predict(params):\n",
    "        outputs = Circuit.eval(*(c(*params) for c in circuit_fns), backend = backend)\n",
    "        res = []\n",
    "        \n",
    "        for output in outputs:\n",
    "            predictions = np.abs(output.array) + 1e-9\n",
    "            ratio = predictions / predictions.sum()\n",
    "            res.append(ratio)\n",
    "            \n",
    "        return np.array(res)\n",
    "    return predict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "868cf7e7-fcbf-4bad-b8bc-4ff0e6b29294",
   "metadata": {},
   "source": [
    "## Loss function and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f376b4aa-0ec6-4037-80eb-935aa75a2f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_cost_fn(pred_fn, labels):\n",
    "    def cost_fn(params, **kwargs):\n",
    "        predictions = pred_fn(params)\n",
    "\n",
    "        cost = loss(predictions, labels) #-np.sum(labels * np.log(predictions)) / len(labels)  # binary cross-entropy loss\n",
    "        costs.append(cost)\n",
    "\n",
    "        accuracy = acc(predictions, labels) #np.sum(np.round(predictions) == labels) / len(labels) / 2  # half due to double-counting\n",
    "        accuracies.append(accuracy)\n",
    "\n",
    "        return cost\n",
    "\n",
    "    costs, accuracies = [], []\n",
    "    return cost_fn, costs, accuracies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3bb6805-facb-4ec9-9c38-8d1df42022b2",
   "metadata": {},
   "source": [
    "## Minimization with noisyopt"
   ]
  },
  {
   "cell_type": "raw",
   "id": "53bc5cb8-8960-46d9-a64e-02b96fb97acc",
   "metadata": {},
   "source": [
    "EPOCHS = 1000\n",
    "SEED = 0\n",
    "\n",
    "# This avoids TracerArrayConversionError from jax\n",
    "Tensor.np = np\n",
    "\n",
    "rng = numpy.random.default_rng(SEED)\n",
    "init_params_spsa = np.array(rng.random(len(parameters)))\n",
    "numpy.random.seed(SEED)\n",
    "\n",
    "train_cost_fn, train_costs, train_accs = make_cost_fn(train_pred_fn, training_data_labels_l)\n",
    "dev_cost_fn, dev_costs, dev_accs = make_cost_fn(dev_pred_fn, validation_data_labels_l)\n",
    "\n",
    "def callback_fn(xk):\n",
    "    valid_loss = dev_cost_fn(xk)\n",
    "    train_loss = round(train_costs[-1], 4)\n",
    "    train_acc = round(train_accs[-1], 4)\n",
    "    valid_acc = round(dev_accs[-1], 4)\n",
    "    iters = int(len(train_accs)/2)\n",
    "    if iters % 100 == 0:\n",
    "        print(\n",
    "                #f\"Params = {xk}, \"\n",
    "                f\"Epoch: {iters}   \",\n",
    "                f\"train/loss: {train_loss}   \",\n",
    "                f\"valid/loss: {round(valid_loss, 4)}   \",\n",
    "                f\"train/acc: {train_acc}   \",\n",
    "                f\"valid/acc: {valid_acc}\"\n",
    "            )\n",
    "    return valid_loss"
   ]
  },
  {
   "cell_type": "raw",
   "id": "cc202031-11f7-4307-96de-8c642d65ce4d",
   "metadata": {},
   "source": [
    "#a_values = [100.0, 10.0, 1.0, 0.1, 0.01, 0.001, 0.0001, 0.00001, 0.000001]\n",
    "#c_values = [100.0, 10.0, 1.0, 0.1, 0.01, 0.001, 0.0001, 0.00001, 0.000001]\n",
    "\n",
    "#a_values = [0.001, 0.005, 0.01, 0.015, 0.02, 0.025, 0.03]\n",
    "#c_values = [0.001, 0.005, 0.01, 0.015, 0.02, 0.025, 0.03]\n",
    "\n",
    "run = 6\n",
    "#a_values = [0.0055, 0.0054, 0.0052, 0.005, 0.0048, 0.0045, 0.004]\n",
    "#c_values = [0.012, 0.016, 0.018, 0.02, 0.022, 0.025, 0.03]\n",
    "\n",
    "#a_values = [0.0053, 0.0054, 0.0055, 0.0056, 0.0057]\n",
    "#c_values = [0.017, 0.0175, 0.018, 0.0185, 0.019]\n",
    "\n",
    "a_values = [0.0052, 0.00525, 0.0053, 0.00535, 0.0054]\n",
    "c_values = [0.0183, 0.0184, 0.0185, 0.0186, 0.0187] \n",
    "\n",
    "for i, a_value in enumerate(a_values):\n",
    "    for j, c_value in enumerate(c_values):\n",
    "        train_cost_fn, train_costs, train_accs = make_cost_fn(train_pred_fn, training_data_labels_l)\n",
    "        dev_cost_fn, dev_costs, dev_accs = make_cost_fn(dev_pred_fn, validation_data_labels_l)\n",
    "        \n",
    "        result = minimizeSPSA(train_cost_fn, x0=init_params_spsa, a = a_value, c = c_value, niter=EPOCHS, callback=callback_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "85b70bae-fe88-4852-a423-658641380e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters(old_params, old_values, new_params):\n",
    "    new_values = list(numpy.array(rng.random(len(new_params))))\n",
    "    old_param_dict = {}\n",
    "    for p, v in zip(old_params, old_values):\n",
    "        old_param_dict[p] = v\n",
    "        \n",
    "    parameters = sorted(set(old_params + new_params), key=default_sort_key)\n",
    "    values = []\n",
    "    for p in parameters:\n",
    "        if p in old_param_dict:\n",
    "            values.append(old_param_dict[p])\n",
    "        else:\n",
    "            values.append(new_values.pop())\n",
    "            \n",
    "    return parameters, np.array(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "20299a15-ac61-46f8-8b10-1e8277a4ee54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search():\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d19610-d096-4de1-b1b9-63aef886e632",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress:  0.022\n",
      "Number of training circuits: 5    Number of validation circuits: 5    Number of test circuits: 8    Number of parameters in model: 103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Params = [0.6369617  0.26978672 0.04097353 ... 0.47998792 0.23237292 0.8018806 ],  Epoch: 3090    train/loss: 1.4855    valid/loss: 1.6128    train/acc: 0.6    valid/acc: 0.4\n",
      "Params = [0.6369617  0.26978672 0.04097353 ... 0.47998792 0.23237292 0.8018806 ],  Epoch: 6045    train/loss: 1.4855    valid/loss: 1.6128    train/acc: 0.6    valid/acc: 0.4\n",
      "Params = [ 1.1369617  -0.23021328  0.04097353 ...  0.47998792  0.23237292\n",
      "  0.8018806 ],  Epoch: 9105    train/loss: 1.1664    valid/loss: 1.6737    train/acc: 0.8    valid/acc: 0.4\n",
      "Params = [ 1.1369617  -0.23021328  0.04097353 ...  0.47998792  0.23237292\n",
      "  0.8018806 ],  Epoch: 12090    train/loss: 1.1565    valid/loss: 1.6769    train/acc: 0.8    valid/acc: 0.4\n",
      "Params = [ 1.1369617  -0.23021328  0.04097353 ...  0.47998792  0.23237292\n",
      "  0.8018806 ],  Epoch: 14190    train/loss: 1.2926    valid/loss: 1.6769    train/acc: 0.6    valid/acc: 0.4\n",
      "Params = [ 1.1369617  -0.48021328  0.04097353 ...  0.47998792 -0.01762708\n",
      "  0.8018806 ],  Epoch: 17265    train/loss: 1.124    valid/loss: 1.8767    train/acc: 0.8    valid/acc: 0.2\n",
      "Params = [ 1.1369617  -0.48021328  0.04097353 ...  0.47998792 -0.01762708\n",
      "  0.8018806 ],  Epoch: 20325    train/loss: 0.8026    valid/loss: 1.81    train/acc: 0.8    valid/acc: 0.4\n",
      "Params = [ 1.1369617  -0.48021328  0.04097353 ...  0.47998792 -0.01762708\n",
      "  0.8018806 ],  Epoch: 23250    train/loss: 1.0501    valid/loss: 1.8012    train/acc: 0.8    valid/acc: 0.4\n",
      "Params = [ 1.1369617  -0.48021328  0.04097353 ...  0.47998792 -0.01762708\n",
      "  0.8018806 ],  Epoch: 25755    train/loss: 0.782    valid/loss: 1.8012    train/acc: 0.8    valid/acc: 0.4\n",
      "Params = [ 1.1369617  -0.48021328  0.04097353 ...  0.47998792 -0.01762708\n",
      "  0.8018806 ],  Epoch: 27660    train/loss: 0.7337    valid/loss: 1.8012    train/acc: 0.8    valid/acc: 0.4\n",
      "Params = [ 1.1369617  -0.48021328  0.04097353 ...  0.47998792 -0.01762708\n",
      "  0.8018806 ],  Epoch: 30735    train/loss: 0.6992    valid/loss: 2.4406    train/acc: 1.0    valid/acc: 0.4\n",
      "Params = [ 1.1369617  -0.48021328  0.04097353 ...  0.47998792 -0.01762708\n",
      "  0.8018806 ],  Epoch: 33810    train/loss: 0.4563    valid/loss: 2.442    train/acc: 0.8    valid/acc: 0.4\n",
      "Params = [ 1.1369617  -0.48021328  0.04097353 ...  0.47998792 -0.01762708\n",
      "  0.8018806 ],  Epoch: 36840    train/loss: 0.648    valid/loss: 2.4396    train/acc: 1.0    valid/acc: 0.4\n",
      "Params = [ 1.1369617  -0.48021328  0.04097353 ...  0.47998792 -0.01762708\n",
      "  0.8018806 ],  Epoch: 39810    train/loss: 0.499    valid/loss: 2.4396    train/acc: 0.8    valid/acc: 0.4\n",
      "Params = [ 1.1369617  -0.48021328  0.04097353 ...  0.47998792 -0.01762708\n",
      "  0.8018806 ],  Epoch: 42885    train/loss: 0.3662    valid/loss: 2.4148    train/acc: 0.8    valid/acc: 0.4\n",
      "Params = [ 1.1369617  -0.48021328  0.04097353 ...  0.47998792 -0.01762708\n",
      "  0.8018806 ],  Epoch: 45915    train/loss: 0.3318    valid/loss: 2.416    train/acc: 0.8    valid/acc: 0.4\n",
      "Params = [ 1.1369617  -0.48021328  0.04097353 ...  0.47998792 -0.01762708\n",
      "  0.8018806 ],  Epoch: 48090    train/loss: 0.4325    valid/loss: 2.416    train/acc: 0.8    valid/acc: 0.4\n",
      "Params = [ 1.1369617  -0.48021328  0.04097353 ...  0.47998792 -0.04887708\n",
      "  0.8018806 ],  Epoch: 51180    train/loss: 0.304    valid/loss: 2.5353    train/acc: 0.8    valid/acc: 0.4\n",
      "Params = [ 1.1369617  -0.51146328  0.04097353 ...  0.47998792 -0.04887708\n",
      "  0.8018806 ],  Epoch: 53730    train/loss: 0.3097    valid/loss: 2.6215    train/acc: 0.8    valid/acc: 0.4\n",
      "Params = [ 1.1369617  -0.51146328  0.04097353 ...  0.47998792 -0.04887708\n",
      "  0.8018806 ],  Epoch: 56235    train/loss: 0.3193    valid/loss: 2.6215    train/acc: 0.8    valid/acc: 0.4\n",
      "Params = [ 1.1369617  -0.51146328  0.04097353 ...  0.47998792 -0.04887708\n",
      "  0.8018806 ],  Epoch: 57495    train/loss: 0.3544    valid/loss: 2.6215    train/acc: 0.8    valid/acc: 0.4\n",
      "Params = [ 1.1369617  -0.49583828  0.04097353 ...  0.47998792 -0.03325208\n",
      "  0.8018806 ],  Epoch: 60585    train/loss: 0.1611    valid/loss: 2.9464    train/acc: 1.0    valid/acc: 0.4\n",
      "Params = [ 1.1369617  -0.49583828  0.04097353 ...  0.47998792 -0.03325208\n",
      "  0.8018806 ],  Epoch: 63480    train/loss: 0.1622    valid/loss: 2.9465    train/acc: 1.0    valid/acc: 0.4\n",
      "Params = [ 1.1369617  -0.49583828  0.04097353 ...  0.47998792 -0.03325208\n",
      "  0.8018806 ],  Epoch: 66045    train/loss: 0.1569    valid/loss: 2.9461    train/acc: 1.0    valid/acc: 0.4\n",
      "Params = [ 1.1369617  -0.49583828  0.04097353 ...  0.47998792 -0.03325208\n",
      "  0.8018806 ],  Epoch: 67755    train/loss: 0.1512    valid/loss: 2.9461    train/acc: 1.0    valid/acc: 0.4\n",
      "Params = [ 1.1369617  -0.49583828  0.04097353 ...  0.47998792 -0.04106458\n",
      "  0.8018806 ],  Epoch: 70845    train/loss: 0.1354    valid/loss: 3.1836    train/acc: 1.0    valid/acc: 0.4\n",
      "Params = [ 1.1369617  -0.50365078  0.04097353 ...  0.47998792 -0.04106458\n",
      "  0.8018806 ],  Epoch: 73845    train/loss: 0.1402    valid/loss: 3.2435    train/acc: 1.0    valid/acc: 0.4\n",
      "Params = [ 1.1369617  -0.50365078  0.04097353 ...  0.47998792 -0.04106458\n",
      "  0.8018806 ],  Epoch: 76455    train/loss: 0.1353    valid/loss: 3.2435    train/acc: 1.0    valid/acc: 0.4\n",
      "Params = [ 1.1369617  -0.50365078  0.04097353 ...  0.47998792 -0.04106458\n",
      "  0.8018806 ],  Epoch: 78795    train/loss: 0.1348    valid/loss: 3.2435    train/acc: 1.0    valid/acc: 0.4\n",
      "Params = [ 1.1369617  -0.49974453  0.04097353 ...  0.47998792 -0.03715833\n",
      "  0.8018806 ],  Epoch: 81885    train/loss: 0.0665    valid/loss: 4.1993    train/acc: 1.0    valid/acc: 0.4\n",
      "Params = [ 1.1369617  -0.49974453  0.04097353 ...  0.47998792 -0.03325208\n",
      "  0.8018806 ],  Epoch: 84975    train/loss: 0.0438    valid/loss: 4.1993    train/acc: 1.0    valid/acc: 0.4\n",
      "Params = [ 1.1369617  -0.49974453  0.04097353 ...  0.47998792 -0.03325208\n",
      "  0.8018806 ],  Epoch: 87270    train/loss: 0.0365    valid/loss: 4.1993    train/acc: 1.0    valid/acc: 0.4\n",
      "Params = [ 1.1369617  -0.49974453  0.04097353 ...  0.47998792 -0.03325208\n",
      "  0.8018806 ],  Epoch: 90345    train/loss: 0.009    valid/loss: 4.2863    train/acc: 1.0    valid/acc: 0.4\n",
      "Params = [ 1.1369617  -0.49974453  0.04097353 ...  0.47998792 -0.03325208\n",
      "  0.8018806 ],  Epoch: 93405    train/loss: 0.0481    valid/loss: 4.2855    train/acc: 1.0    valid/acc: 0.4\n",
      "Params = [ 1.1369617  -0.49974453  0.04097353 ...  0.47998792 -0.03325208\n",
      "  0.8018806 ],  Epoch: 96465    train/loss: 0.0123    valid/loss: 4.2855    train/acc: 1.0    valid/acc: 0.4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.25\n",
      "Progress:  0.025\n",
      "Number of training circuits: 6    Number of validation circuits: 18    Number of test circuits: 19    Number of parameters in model: 130\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Params = [2.1369617  0.50025547 0.04097353 ... 0.56047595 0.8097108  0.5540905 ],  Epoch: 3885    train/loss: 0.249    valid/loss: 7.6251    train/acc: 1.0    valid/acc: 0.5\n",
      "Params = [2.1369617  0.50025547 0.04097353 ... 0.56047595 0.8097108  0.5540905 ],  Epoch: 7725    train/loss: 0.2489    valid/loss: 7.6253    train/acc: 1.0    valid/acc: 0.5\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 3000\n",
    "syms = {}\n",
    "all_training_keys = list(training_circuits.keys())\n",
    "initial_circuit_keys = all_training_keys[:5]\n",
    "current_training_circuits = {}\n",
    "\n",
    "for k in initial_circuit_keys:\n",
    "    current_training_circuits[k] = training_circuits[k]\n",
    "    \n",
    "syms = get_symbols(current_training_circuits)\n",
    "parameters = sorted(syms, key=default_sort_key)\n",
    "init_params_spsa = np.array(rng.random(len(parameters)))\n",
    "\n",
    "run = 0\n",
    "for i, key in enumerate(all_training_keys[5:]):\n",
    "    print(\"Progress: \", round((i + 10)/len(all_training_keys), 3))\n",
    "    \n",
    "    # Skip cases when the number of parameters did not grow when new circuits were added\n",
    "    if len(syms) == len(get_symbols(current_training_circuits)) and i > 0:\n",
    "        if i != len(all_training_keys[10:]):\n",
    "            current_training_circuits[key] = training_circuits[key]\n",
    "            new_parameters = sorted(get_symbols({key: training_circuits[key]}), key=default_sort_key)\n",
    "            parameters, init_params_spsa = initialize_parameters(parameters, result.x, new_parameters)\n",
    "            continue\n",
    "    else:\n",
    "        run += 1\n",
    "    \n",
    "    # Select those circuits from test and validation circuits which share the parameters with the current training circuits\n",
    "    current_validation_circuits = select_circuits(current_training_circuits, validation_circuits)\n",
    "    current_test_circuits = select_circuits(current_training_circuits, test_circuits)\n",
    "    \n",
    "    if len(current_validation_circuits) == 0 or len(current_test_circuits) == 0:\n",
    "        continue\n",
    "    \n",
    "    # Create lists with circuits and their corresponding label\n",
    "    training_circuits_l, training_data_labels_l = construct_data_and_labels(current_training_circuits, training_data_labels)\n",
    "    validation_circuits_l, validation_data_labels_l = construct_data_and_labels(current_validation_circuits, validation_data_labels)\n",
    "    test_circuits_l, test_data_labels_l = construct_data_and_labels(current_test_circuits, test_data_labels)\n",
    "    \n",
    "    # Limit the number of validation and test circuits to 20% of number of the training circuits\n",
    "    #val_test_circ_size = ceil(len(current_training_circuits))\n",
    "    #if len(current_validation_circuits) > val_test_circ_size:\n",
    "    #    validation_circuits_l = validation_circuits_l[:val_test_circ_size]\n",
    "    #    validation_data_labels_l = validation_data_labels_l[:val_test_circ_size]\n",
    "    #if len(current_test_circuits) > val_test_circ_size:\n",
    "    #    test_circuits_l = test_circuits_l[:val_test_circ_size]\n",
    "    #    test_data_labels_l = test_data_labels_l[:val_test_circ_size]\n",
    "    \n",
    "    print(f\"Number of training circuits: {len(training_circuits_l)}   \",\n",
    "          f\"Number of validation circuits: {len(validation_circuits_l)}   \",\n",
    "          f\"Number of test circuits: {len(test_circuits_l)}   \",\n",
    "          f\"Number of parameters in model: {len(set([sym for circuit in training_circuits_l for sym in circuit.free_symbols]))}\")\n",
    "    \n",
    "    train_pred_fn = jit(make_pred_fn(training_circuits_l))\n",
    "    dev_pred_fn = jit(make_pred_fn(validation_circuits_l))\n",
    "    test_pred_fn = make_pred_fn(test_circuits_l)\n",
    "    \n",
    "    train_cost_fn, train_costs, train_accs = make_cost_fn(train_pred_fn, training_data_labels_l)\n",
    "    dev_cost_fn, dev_costs, dev_accs = make_cost_fn(dev_pred_fn, validation_data_labels_l)\n",
    "    \n",
    "    def callback_fn(xk):\n",
    "        #print(xk)\n",
    "        valid_loss = dev_cost_fn(xk)\n",
    "        train_loss = numpy.around(min(float(train_costs[-1]), float(train_costs[-2])), 4)\n",
    "        train_acc = numpy.around(min(float(train_accs[-1]), float(train_accs[-2])), 4)\n",
    "        valid_acc = numpy.around(float(dev_accs[-1]), 4)\n",
    "        iters = int(len(train_accs)/2)\n",
    "        #if iters % 100 == 0:\n",
    "        print(\n",
    "                #f\"Params = {xk}, \",\n",
    "                f\"Epoch: {iters}   \",\n",
    "                f\"train/loss: {train_loss}   \",\n",
    "                f\"valid/loss: {numpy.around(float(valid_loss), 4)}   \",\n",
    "                f\"train/acc: {train_acc}   \",\n",
    "                f\"valid/acc: {valid_acc}\", file=sys.stderr\n",
    "            )\n",
    "        return valid_loss\n",
    "    \n",
    "    a_value = 0.07 #0.0053 #0.0053\n",
    "    c_value = 0.01 #0.00017 #0.0185\n",
    "    #a_values = [0.005, 0.0051, 0.0052, 0.0053, 0.0054, 0.0055]\n",
    "    #c_values = [0.00017, 0.000175, 0.00018, 0.000185, 0.00019, 0.000195]\n",
    "    #a_values = [0.045, 0.05, 0.07, 0.1, 0.15]\n",
    "    #c_values = [0.0045, 0.005, 0.007, 0.01, 0.013, 0.015]\n",
    "    #for i, a_value in enumerate(a_values):\n",
    "    #    for c_value in c_values:\n",
    "    \n",
    "    #for a_value in a_values:\n",
    "    #    for c_value in c_values:\n",
    "            #print(\"a: \", a_value)\n",
    "            #print(\"c: \", c_value)\n",
    "            #train_cost_fn, train_costs, train_accs = make_cost_fn(train_pred_fn, training_data_labels_l)\n",
    "            #dev_cost_fn, dev_costs, dev_accs = make_cost_fn(dev_pred_fn, validation_data_labels_l)\n",
    "            \n",
    "    #result = minimizeSPSA(train_cost_fn, x0=init_params_spsa, a = a_value, c = c_value, niter=EPOCHS, callback=callback_fn)\n",
    "    result = minimizeCompass(train_cost_fn, x0=init_params_spsa, redfactor=2.0, deltainit=1.0, deltatol=0.001, feps=1e-15, errorcontrol=True, funcNinit=30, funcmultfactor=2.0, paired=True, alpha=0.05, callback=callback_fn)\n",
    "\n",
    "    figure_path = this_folder + \"//results//\" + workload_size + \"_noisyopt_compass_\" + str(classification) + \"_\" + str(layers) + \"_\" + str(single_qubit_params) + \"_\" + str(run) + \".png\"\n",
    "    visualize_result_noisyopt(result, make_cost_fn, test_pred_fn, test_data_labels_l, train_costs, train_accs, dev_costs, dev_accs, figure_path)\n",
    "    \n",
    "    run += 1\n",
    "    EPOCHS += 100\n",
    "    syms = get_symbols(current_training_circuits)\n",
    "    \n",
    "    # Extend for the next optimization round\n",
    "    current_training_circuits[key] = training_circuits[key]\n",
    "    new_parameters = sorted(get_symbols({key: training_circuits[key]}), key=default_sort_key)\n",
    "    parameters, init_params_spsa = initialize_parameters(parameters, result.x, new_parameters)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
