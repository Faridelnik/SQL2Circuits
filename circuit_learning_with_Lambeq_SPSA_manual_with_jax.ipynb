{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b09952d6-99a3-41a5-865f-2170e9ee0247",
   "metadata": {},
   "source": [
    "# Circuit learning module: Lambeq manually with SPSA and JAX"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb811fe4-d729-4a44-838d-9c02db4a644d",
   "metadata": {},
   "source": [
    "This module performs the optimization of the parametrized circuit manually compared to Lambeq's automatic QuantumTrainer class. I created this because I wanted to have more control over the optimization process and debug it better. The code is based on the workflow presented in https://github.com/CQCL/Quanthoven."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9a5783f-901a-4bfe-a622-4003b345fb1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import json\n",
    "import os\n",
    "import glob\n",
    "from pathlib import Path\n",
    "from jax import numpy as np\n",
    "from sympy import default_sort_key\n",
    "#import numpy as np\n",
    "import numpy\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from discopy.utils import loads\n",
    "from pytket.extensions.qiskit import AerBackend\n",
    "from pytket.extensions.qulacs import QulacsBackend\n",
    "from pytket.extensions.cirq import CirqStateSampleBackend\n",
    "\n",
    "backend = None\n",
    "\n",
    "from discopy.quantum import Circuit\n",
    "from discopy.tensor import Tensor\n",
    "\n",
    "from utils import read_diagrams, create_labeled_classes, bin_class_loss, multi_class_loss, bin_class_acc, multi_class_acc\n",
    "\n",
    "import jax\n",
    "from jax import jit\n",
    "from noisyopt import minimizeSPSA\n",
    "\n",
    "this_folder = os.path.abspath(os.getcwd())\n",
    "os.environ['TOKENIZERS_PARALLELISM'] = 'true'\n",
    "#os.environ[\"JAX_PLATFORMS\"] = \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238fca40-5d8d-4ace-a65f-693885a8caf8",
   "metadata": {},
   "source": [
    "## Read circuit data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f6f00d7-b573-4c5d-a0d6-d5eafc54745e",
   "metadata": {},
   "source": [
    "We read the circuits from the pickled files. Select if we perform binary classification or multi-class classification. Give number of qubits to create classes:\n",
    "- 1 qubits -> 2^1 = 2 classes i.e. binary classification\n",
    "- 2 qubits -> 2^2 = 4 classes\n",
    "- ...\n",
    "- 5 qubits -> 2^5 = 32 classes, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01bac1f9-3bc0-4a25-8f4f-baa2b9c581e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select workload\n",
    "#workload = \"small\"\n",
    "workload = \"medium\"\n",
    "#workload = \"large\"\n",
    "\n",
    "classification = 2\n",
    "layers = 1\n",
    "single_qubit_params = 9\n",
    "loss = multi_class_loss\n",
    "acc = multi_class_acc\n",
    "\n",
    "if classification == 1:\n",
    "    loss = bin_class_loss\n",
    "    acc = bin_class_acc\n",
    "\n",
    "# Access the selected circuits\n",
    "path_name = this_folder + \"//simplified-JOB-diagrams//\" + workload + \"//circuits//\" + str(classification) + \"//\" + str(layers) + \"_layer//\" + str(single_qubit_params) + \"_single_qubit_params//\"\n",
    "\n",
    "training_circuits_paths = glob.glob(path_name + \"training//[0-9]*.p\")\n",
    "validation_circuits_paths = glob.glob(path_name + \"validation//[0-9]*.p\")\n",
    "test_circuits_paths = glob.glob(path_name + \"test//[0-9]*.p\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ff0a551-444c-40a7-bf66-8e929bc49a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_circuits = read_diagrams(training_circuits_paths)\n",
    "validation_circuits = read_diagrams(validation_circuits_paths)\n",
    "test_circuits = read_diagrams(test_circuits_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2da3a7c-6a93-44e9-9640-7e9ead005cb2",
   "metadata": {},
   "source": [
    "## Read training and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "774e9f52-69c9-4e1c-8a70-76e1198d12f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data, test_data, validation_data = None, None, None\n",
    "data_path = this_folder + \"//data//\" + workload + \"//\"\n",
    "\n",
    "with open(data_path + \"training_data.json\", \"r\") as inputfile:\n",
    "    training_data = json.load(inputfile)['training_data']\n",
    "with open(data_path + \"test_data.json\", \"r\") as inputfile:\n",
    "    test_data = json.load(inputfile)['test_data']\n",
    "with open(data_path + \"validation_data.json\", \"r\") as inputfile:\n",
    "    validation_data = json.load(inputfile)['validation_data']\n",
    "\n",
    "training_data_labels = create_labeled_classes(training_data, classification)\n",
    "test_data_labels = create_labeled_classes(test_data, classification)\n",
    "validation_data_labels = create_labeled_classes(validation_data, classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6cad830-e6c3-4c29-9ce6-0d6bec2794bc",
   "metadata": {},
   "source": [
    "## Lambeq optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce559dbf-2b4b-4853-82ed-58832aa11e61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test circuits need to share training circuits' parameters. The parameters that are not covered (should be empty set, set()):  set()\n",
      "Validation circuits need to share training circuits' parameters. The parameters that are not covered (should be empty set, set()):  set()\n",
      "Total number of circuits:  121\n",
      "Total number of variables:  203\n"
     ]
    }
   ],
   "source": [
    "#all_circuits = list(training_circuits.values()) + list(test_circuits.values())\n",
    "\n",
    "training_circuits_l = []\n",
    "test_circuits_l = []\n",
    "validation_circuits_l = []\n",
    "\n",
    "training_data_labels_l = []\n",
    "test_data_labels_l = []\n",
    "validation_data_labels_l = []\n",
    "\n",
    "# Organize circuits and labels in correct order into two lists which will be input for training the model\n",
    "for key in training_data_labels:\n",
    "    training_circuits_l.append(training_circuits[key])\n",
    "    training_data_labels_l.append(training_data_labels[key])\n",
    "\n",
    "for key in test_data_labels:\n",
    "    test_circuits_l.append(test_circuits[key])\n",
    "    test_data_labels_l.append(test_data_labels[key])\n",
    "    \n",
    "for key in validation_data_labels:\n",
    "    validation_circuits_l.append(validation_circuits[key])\n",
    "    validation_data_labels_l.append(validation_data_labels[key])\n",
    "\n",
    "all_circuits = training_circuits_l + test_circuits_l + validation_circuits_l\n",
    "\n",
    "train_syms = set([sym for circuit in training_circuits.values() for sym in circuit.free_symbols])\n",
    "test_syms = set([sym for circuit in test_circuits.values() for sym in circuit.free_symbols])\n",
    "val_syms = set([sym for circuit in validation_circuits.values() for sym in circuit.free_symbols])\n",
    "\n",
    "print(\"Test circuits need to share training circuits' parameters. The parameters that are not covered (should be empty set, set()): \", test_syms.difference(train_syms))\n",
    "print(\"Validation circuits need to share training circuits' parameters. The parameters that are not covered (should be empty set, set()): \", val_syms.difference(train_syms))\n",
    "\n",
    "print(\"Total number of circuits: \", len(all_circuits))\n",
    "print(\"Total number of variables: \", len(train_syms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c84f333-8670-492f-b85f-20467a2f7d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_labels_l = np.array(training_data_labels_l)\n",
    "test_data_labels_l = np.array(test_data_labels_l)\n",
    "validation_data_labels_l = np.array(validation_data_labels_l)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "572abfc1-cc81-4fdb-b8bb-6813fe658dd6",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e772e8c8-b747-4c19-8eef-7cc038194d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = sorted(\n",
    "    train_syms,\n",
    "    key=default_sort_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "04c65634-fa13-47b3-915c-83361d0e1baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_pred_fn(circuits):\n",
    "    # In the case we want to use other backends. \n",
    "    # Currently does not work properly.\n",
    "    if backend:\n",
    "        compiled_circuits1 = backend.get_compiled_circuits([c.to_tk() for c in circuits])\n",
    "        circuits = [Circuit.from_tk(c) for c in compiled_circuits1]\n",
    "        \n",
    "    circuit_fns = [c.lambdify(*parameters) for c in circuits]\n",
    "    \n",
    "    def predict(params):\n",
    "        outputs = Circuit.eval(*(c(*params) for c in circuit_fns), backend = backend)\n",
    "        res = []\n",
    "        \n",
    "        for output in outputs:\n",
    "            predictions = np.abs(output.array) + 1e-9\n",
    "            ratio = predictions / predictions.sum()\n",
    "            res.append(ratio)\n",
    "            \n",
    "        return np.array(res)\n",
    "    return predict\n",
    "\n",
    "train_pred_fn = jit(make_pred_fn(training_circuits_l))\n",
    "dev_pred_fn = jit(make_pred_fn(validation_circuits_l))\n",
    "test_pred_fn = make_pred_fn(test_circuits_l)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "868cf7e7-fcbf-4bad-b8bc-4ff0e6b29294",
   "metadata": {},
   "source": [
    "## Loss function and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f376b4aa-0ec6-4037-80eb-935aa75a2f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_cost_fn(pred_fn, labels):\n",
    "    def cost_fn(params, **kwargs):\n",
    "        predictions = pred_fn(params)\n",
    "\n",
    "        cost = loss(predictions, labels) #-np.sum(labels * np.log(predictions)) / len(labels)  # binary cross-entropy loss\n",
    "        costs.append(cost)\n",
    "\n",
    "        accuracy = acc(predictions, labels) #np.sum(np.round(predictions) == labels) / len(labels) / 2  # half due to double-counting\n",
    "        accuracies.append(accuracy)\n",
    "\n",
    "        return cost\n",
    "\n",
    "    costs, accuracies = [], []\n",
    "    return cost_fn, costs, accuracies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3bb6805-facb-4ec9-9c38-8d1df42022b2",
   "metadata": {},
   "source": [
    "## Minimization with noisyopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "575f6418-781f-4d16-bf0f-7dc9dacdf0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 10000\n",
    "SEED = 0\n",
    "\n",
    "# This avoids TracerArrayConversionError from jax\n",
    "Tensor.np = np\n",
    "\n",
    "rng = numpy.random.default_rng(SEED)\n",
    "init_params_spsa = np.array(rng.random(len(parameters)))\n",
    "numpy.random.seed(SEED)\n",
    "\n",
    "train_cost_fn, train_costs, train_accs = make_cost_fn(train_pred_fn, training_data_labels_l)\n",
    "dev_cost_fn, dev_costs, dev_accs = make_cost_fn(dev_pred_fn, validation_data_labels_l)\n",
    "\n",
    "def callback_fn(xk):\n",
    "    valid_loss = dev_cost_fn(xk)\n",
    "    train_loss = round(train_costs[-1], 4)\n",
    "    train_acc = round(train_accs[-1], 4)\n",
    "    valid_acc = round(dev_accs[-1], 4)\n",
    "    iters = int(len(train_accs)/2)\n",
    "    if iters % 100 == 0:\n",
    "        print(\n",
    "                #f\"Params = {xk}, \"\n",
    "                f\"Epoch: {iters}   \",\n",
    "                f\"train/loss: {train_loss}   \",\n",
    "                f\"valid/loss: {round(valid_loss, 4)}   \",\n",
    "                f\"train/acc: {train_acc}   \",\n",
    "                f\"valid/acc: {valid_acc}\"\n",
    "            )\n",
    "    return valid_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95052c87-ffb7-4c4f-952f-e63d9c54b2ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 100    train/loss: 25.971599578857422    valid/loss: 7.048599720001221    train/acc: 0.35    valid/acc: 0.3333\n",
      "Epoch: 200    train/loss: 25.43470001220703    valid/loss: 6.720799922943115    train/acc: 0.375    valid/acc: 0.4762\n",
      "Epoch: 300    train/loss: 24.86319923400879    valid/loss: 6.512099742889404    train/acc: 0.375    valid/acc: 0.4762\n",
      "Epoch: 400    train/loss: 23.960298538208008    valid/loss: 6.227099895477295    train/acc: 0.375    valid/acc: 0.4762\n",
      "Epoch: 500    train/loss: 23.58479881286621    valid/loss: 5.967199802398682    train/acc: 0.45    valid/acc: 0.381\n",
      "Epoch: 600    train/loss: 23.621599197387695    valid/loss: 5.683199882507324    train/acc: 0.4125    valid/acc: 0.5238\n",
      "Epoch: 700    train/loss: 23.07969856262207    valid/loss: 5.996999740600586    train/acc: 0.4625    valid/acc: 0.381\n",
      "Epoch: 800    train/loss: 23.425199508666992    valid/loss: 5.843999862670898    train/acc: 0.4625    valid/acc: 0.4286\n",
      "Epoch: 900    train/loss: 23.27069854736328    valid/loss: 5.971499919891357    train/acc: 0.4875    valid/acc: 0.5238\n",
      "Epoch: 1000    train/loss: 22.458799362182617    valid/loss: 5.5304999351501465    train/acc: 0.4875    valid/acc: 0.5238\n",
      "Epoch: 1100    train/loss: 23.675800323486328    valid/loss: 5.722799777984619    train/acc: 0.4625    valid/acc: 0.4286\n",
      "Epoch: 1200    train/loss: 22.49519920349121    valid/loss: 5.712800025939941    train/acc: 0.5375    valid/acc: 0.619\n",
      "Epoch: 1300    train/loss: 24.232099533081055    valid/loss: 6.482999801635742    train/acc: 0.4875    valid/acc: 0.619\n",
      "Epoch: 1400    train/loss: 21.80430030822754    valid/loss: 5.628999710083008    train/acc: 0.4875    valid/acc: 0.619\n",
      "Epoch: 1500    train/loss: 21.938098907470703    valid/loss: 5.367599964141846    train/acc: 0.5125    valid/acc: 0.5238\n",
      "Epoch: 1600    train/loss: 20.918699264526367    valid/loss: 5.345999717712402    train/acc: 0.5125    valid/acc: 0.5714\n",
      "Epoch: 1700    train/loss: 20.359399795532227    valid/loss: 4.837100028991699    train/acc: 0.55    valid/acc: 0.619\n",
      "Epoch: 1800    train/loss: 19.702299118041992    valid/loss: 5.25629997253418    train/acc: 0.55    valid/acc: 0.619\n",
      "Epoch: 1900    train/loss: 19.98979949951172    valid/loss: 5.125199794769287    train/acc: 0.6    valid/acc: 0.6667\n",
      "Epoch: 2000    train/loss: 19.68709945678711    valid/loss: 4.783499717712402    train/acc: 0.6    valid/acc: 0.619\n",
      "Epoch: 2100    train/loss: 19.71619987487793    valid/loss: 4.702699661254883    train/acc: 0.5875    valid/acc: 0.7143\n",
      "Epoch: 2200    train/loss: 20.330398559570312    valid/loss: 4.81719970703125    train/acc: 0.5625    valid/acc: 0.7619\n",
      "Epoch: 2300    train/loss: 20.024799346923828    valid/loss: 4.979300022125244    train/acc: 0.6125    valid/acc: 0.7619\n",
      "Epoch: 2400    train/loss: 19.866100311279297    valid/loss: 4.951999664306641    train/acc: 0.5625    valid/acc: 0.7143\n",
      "Epoch: 2500    train/loss: 19.529699325561523    valid/loss: 5.286599636077881    train/acc: 0.575    valid/acc: 0.7619\n",
      "Epoch: 2600    train/loss: 19.38640022277832    valid/loss: 5.16379976272583    train/acc: 0.55    valid/acc: 0.7619\n",
      "Epoch: 2700    train/loss: 21.164798736572266    valid/loss: 4.911399841308594    train/acc: 0.55    valid/acc: 0.6667\n",
      "Epoch: 2800    train/loss: 20.03839874267578    valid/loss: 5.564499855041504    train/acc: 0.625    valid/acc: 0.7619\n",
      "Epoch: 2900    train/loss: 19.33989906311035    valid/loss: 5.532700061798096    train/acc: 0.575    valid/acc: 0.7143\n",
      "Epoch: 3000    train/loss: 19.347200393676758    valid/loss: 5.327600002288818    train/acc: 0.55    valid/acc: 0.7143\n",
      "Epoch: 3100    train/loss: 18.977100372314453    valid/loss: 5.359899997711182    train/acc: 0.6125    valid/acc: 0.619\n",
      "Epoch: 3200    train/loss: 18.93389892578125    valid/loss: 5.596999645233154    train/acc: 0.5625    valid/acc: 0.619\n",
      "Epoch: 3300    train/loss: 19.721698760986328    valid/loss: 5.633599758148193    train/acc: 0.5875    valid/acc: 0.5714\n"
     ]
    }
   ],
   "source": [
    "result = minimizeSPSA(train_cost_fn, x0=init_params_spsa, a = 0.0045, c = 0.006, niter=EPOCHS, callback=callback_fn)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537aa180-ea99-48b1-90a3-097e4a9ecc6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ((ax_tl, ax_tr), (ax_bl, ax_br)) = plt.subplots(2, 2, sharex=True, sharey='row', figsize=(10, 6))\n",
    "ax_tl.set_title('Training set')\n",
    "ax_tr.set_title('Development set')\n",
    "ax_bl.set_xlabel('Iterations')\n",
    "ax_br.set_xlabel('Iterations')\n",
    "ax_bl.set_ylabel('Accuracy')\n",
    "ax_tl.set_ylabel('Loss')\n",
    "\n",
    "colours = iter(plt.rcParams['axes.prop_cycle'].by_key()['color'])\n",
    "ax_tl.plot(train_costs[1::2], color=next(colours))  # training evaluates twice per iteration\n",
    "ax_bl.plot(train_accs[1::2], color=next(colours))   # so take every other entry\n",
    "ax_tr.plot(dev_costs, color=next(colours))\n",
    "ax_br.plot(dev_accs, color=next(colours))\n",
    "\n",
    "# print test accuracy\n",
    "test_cost_fn, _, test_accs = make_cost_fn(test_pred_fn, test_data_labels_l)\n",
    "test_cost_fn(result.x)\n",
    "print('Test accuracy:', test_accs[0])\n",
    "\n",
    "plt.savefig(this_folder + \"//results//\" + workload + \"_\" + str(classification) + \"_\" + str(layers) + \"_\" + str(single_qubit_params) + \".png\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa369834-070c-4a84-9678-37625e5ea4a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
