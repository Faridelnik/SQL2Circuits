{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b09952d6-99a3-41a5-865f-2170e9ee0247",
   "metadata": {},
   "source": [
    "# Circuit learning module: Lambeq manually with SPSA and JAX"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb811fe4-d729-4a44-838d-9c02db4a644d",
   "metadata": {},
   "source": [
    "This module performs the optimization of the parametrized circuit manually compared to Lambeq's automatic QuantumTrainer class. I created this because I wanted to have more control over the optimization process and debug it better. The code is based on the workflow presented in https://github.com/CQCL/Quanthoven."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9a5783f-901a-4bfe-a622-4003b345fb1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import json\n",
    "import os\n",
    "import glob\n",
    "from pathlib import Path\n",
    "#from jax import numpy as np\n",
    "import numpy as np\n",
    "import numpy\n",
    "import pickle\n",
    "\n",
    "from discopy.utils import loads\n",
    "from pytket.extensions.qiskit import AerBackend\n",
    "from pytket.extensions.qulacs import QulacsBackend\n",
    "from pytket.extensions.cirq import CirqStateSampleBackend\n",
    "\n",
    "backend = QulacsBackend()\n",
    "\n",
    "from discopy.quantum import Circuit\n",
    "from discopy.tensor import Tensor\n",
    "\n",
    "import jax\n",
    "from jax import jit\n",
    "from noisyopt import minimizeSPSA\n",
    "\n",
    "this_folder = os.path.abspath(os.getcwd())\n",
    "os.environ['TOKENIZERS_PARALLELISM'] = 'true'\n",
    "#os.environ[\"JAX_PLATFORMS\"] = \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238fca40-5d8d-4ace-a65f-693885a8caf8",
   "metadata": {},
   "source": [
    "## Read circuit data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f6f00d7-b573-4c5d-a0d6-d5eafc54745e",
   "metadata": {},
   "source": [
    "We read the circuits from the pickled files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ff0a551-444c-40a7-bf66-8e929bc49a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_circuits_paths = glob.glob(this_folder + \"//simplified-JOB-diagrams//circuits//binary_classification//training//[0-9]*.p\")\n",
    "#validation_circuits_paths = glob.glob(this_folder + \"//simplified-JOB-diagrams//circuits//binary_classification//validation//[0-9]*.p\")\n",
    "test_circuits_paths = glob.glob(this_folder + \"//simplified-JOB-diagrams//circuits//binary_classification//test//[0-9]*.p\")\n",
    "\n",
    "def read_diagrams(circuit_paths):\n",
    "    circuits = {}\n",
    "    for serialized_diagram in circuit_paths:\n",
    "        base_name = Path(serialized_diagram).stem\n",
    "        f = open(serialized_diagram, \"rb\")\n",
    "        diagram = pickle.load(f)\n",
    "        circuits[base_name] = diagram\n",
    "    return circuits\n",
    "\n",
    "\n",
    "training_circuits = read_diagrams(training_circuits_paths[:2])\n",
    "#for key in training_circuits:\n",
    "#    print(\"training query: \", key)\n",
    "test_circuits = read_diagrams(test_circuits_paths) #+ [test_circuits_paths[2]] + test_circuits_paths[8:])\n",
    "#test_circuits = read_diagrams([test_circuits_paths[2]])\n",
    "#for key in test_circuits:\n",
    "#    print(\"test query: \", key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2da3a7c-6a93-44e9-9640-7e9ead005cb2",
   "metadata": {},
   "source": [
    "## Read training and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "774e9f52-69c9-4e1c-8a70-76e1198d12f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data, test_data = None, None\n",
    "with open(this_folder + \"//data//training_data.json\", \"r\") as inputfile:\n",
    "    training_data = json.load(inputfile)['training_data']\n",
    "with open(this_folder + \"//data//test_data.json\", \"r\") as inputfile:\n",
    "    test_data = json.load(inputfile)['test_data']\n",
    "    \n",
    "\n",
    "def time_to_states(data, circuits):\n",
    "    labeled_data = {}\n",
    "    for elem in data:\n",
    "        if elem[\"name\"] in circuits.keys():\n",
    "            if elem[\"time\"] < 5000:\n",
    "                labeled_data[elem[\"name\"]] = [1,0] # corresponds to |0>\n",
    "            else:\n",
    "                labeled_data[elem[\"name\"]] = [0,1] # corresponds to |1>\n",
    "    return labeled_data\n",
    "\n",
    "\n",
    "training_data_labels = time_to_states(training_data, training_circuits)\n",
    "test_data_labels = time_to_states(test_data, test_circuits)\n",
    "\n",
    "#for key in training_data_labels:\n",
    "#    print(\"training: \", key)\n",
    "#for key in test_data_labels:\n",
    "#    print(\"test \", key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6cad830-e6c3-4c29-9ce6-0d6bec2794bc",
   "metadata": {},
   "source": [
    "## Lambeq optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce559dbf-2b4b-4853-82ed-58832aa11e61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test circuits need to share training circuits' parameters. The parameters that are not covered:  {'bottom 10 rank'__n.l_0, link__n.l_1, cast_info__n.l_2, 'Sweden'__n.l_0, '%(presents)%'__n.l_1, <_n.l@n.l_n.l_0, aka_title__n.l_0, aka_title__n.l_1, production_year__n.l_1, movie_info__n.l_1, kind__n.l_1, '[us]'__n.l_1, info_type_id__n.l_2, linked_movie_id__n.l_1, FROM_n@n.l@n.l_n_0, NULL__n.l_1, 'USA'__n.l_1, info__n.l_0, 'German'__n.l_2, 'B%'__n.l_0, NOT_n.l_n.l_0, aka_name__n.l_2, 'features'__n.l_2, 'top 250 rank'__n.l_0, keyword__n.l_1, 'movie'__n.l_0, complete_cast__n.l_1, link__n.l_2, kind_id__n.l_2, link_type_id__n.l_0, person_info__n.l_2, set_n.l@n.l@n.l_n.l_0, role_id__n.l_2, 2011__n.l_1, kind_type__n.l_1, info_type_id__n.l_0, role_id__n.l_0, 'production companies'__n.l_2, '%(as Metro-Goldwyn-Mayer Pictures)%'__n.l_1, char_name__n.l_0, person_role_id__n.l_0, '%sequel%'__n.l_2, NOT_n.l_n.l_2, 'Queen'__n.l_2, '(voice: English version)'__n.l_0, 'top 250 rank'__n.l_2, keyword_id__n.l_0, 'movie'__n.l_1, role_type__n.l_2, person_id__n.l_1, name__n.l_0, keyword__n.l_2, set_n.l@n.l_n.l_0, 'Volker Boehm'__n.l_1, 'Volker Boehm'__n.l_2, 'features'__n.l_1, 'mini biography'__n.l_2, country_code__n.l_2, linked_movie_id__n.l_0, 'German'__n.l_1, 'Volker Boehm'__n.l_0, kind_id__n.l_0, '%Film%'__n.l_2, company_id__n.l_0, cast_info__n.l_0, 2004__n.l_1, link_type_id__n.l_1, 'Sweden'__n.l_1, '[us]'__n.l_2, aka_title__n.l_2, gender__n.l_2, production_year__n.l_2, gender__n.l_1, 2004__n.l_2, 'character-name-in-title'__n.l_2, '%sequel%'__n.l_0, 'German'__n.l_0, 'top 250 rank'__n.l_1, link_type__n.l_1, 'mini biography'__n.l_1, person_role_id__n.l_2, aka_name__n.l_0, '%a%'__n.l_2, country_code__n.l_1, '%(France)%'__n.l_0, '(voice: English version)'__n.l_2, company_name__n.l_2, name__n.l_2, movie_info__n.l_2, 'features'__n.l_0, link_type_id__n.l_2, info_type__n.l_2, company_id__n.l_1, 'superhero'__n.l_0, role_type__n.l_0, 2011__n.l_2, '%(as Metro-Goldwyn-Mayer Pictures)%'__n.l_2, company_name__n.l_1, NULL__n.l_2, person_role_id__n.l_1, '[us]'__n.l_0, char_name__n.l_2, 'superhero'__n.l_2, '%sequel%'__n.l_1, NOT_LIKE_n.l@n.l_n.l_0, 'B%'__n.l_2, linked_movie_id__n.l_2, kind_id__n.l_1, IS_n.l@n.l_n.l_0, char_name__n.l_1, role_type__n.l_1, info__n.l_2, '%(presents)%'__n.l_2, 'm'__n.l_1, 'bottom 10 rank'__n.l_1, 'production companies'__n.l_1, 'Queen'__n.l_0, keyword_id__n.l_2, '%(France)%'__n.l_2, kind_type__n.l_2, gender__n.l_0, 'production companies'__n.l_0, '%(France)%'__n.l_1, role_id__n.l_1, link_type__n.l_2, >_n.l@n.l_n.l_0, kind_type__n.l_0, '%Film%'__n.l_0, production_year__n.l_0, person_id__n.l_0, company_name__n.l_0, IN_n.l@n.l_n.l_0, company_id__n.l_2, FROM_n@n.l@n.l_n_1, '%a%'__n.l_1, kind__n.l_2, kind__n.l_0, 'sequel'__n.l_2, info_type__n.l_0, '%(as Metro-Goldwyn-Mayer Pictures)%'__n.l_0, cast_info__n.l_1, 'Queen'__n.l_1, info__n.l_1, 2011__n.l_0, info_type__n.l_1, person_info__n.l_0, person_id__n.l_2, '%a%'__n.l_0, 'sequel'__n.l_1, aka_name__n.l_1, 'mini biography'__n.l_0, country_code__n.l_0, 'm'__n.l_0, 'movie'__n.l_2, 'sequel'__n.l_0, '%(presents)%'__n.l_0, name__n.l_1, 2004__n.l_0, 'bottom 10 rank'__n.l_2, 'character-name-in-title'__n.l_1, set_n.l@n.l@n.l_n.l_1, NULL__n.l_0, NOT_n.l_n.l_1, 'USA'__n.l_2, person_info__n.l_1, 'USA'__n.l_0, 'Sweden'__n.l_2, 'B%'__n.l_1, info_type_id__n.l_1, complete_cast__n.l_0, 'character-name-in-title'__n.l_0, link__n.l_0, '(voice: English version)'__n.l_1, link_type__n.l_0, movie_info__n.l_0, keyword__n.l_0, complete_cast__n.l_2, 'superhero'__n.l_1, keyword_id__n.l_1, 'm'__n.l_2, '%Film%'__n.l_1}\n",
      "Total number of circuits:  200\n",
      "Total number of variables:  41\n"
     ]
    }
   ],
   "source": [
    "#all_circuits = list(training_circuits.values()) + list(test_circuits.values())\n",
    "\n",
    "training_circuits_l = []\n",
    "test_circuits_l = []\n",
    "training_data_labels_l = []\n",
    "test_data_labels_l = []\n",
    "\n",
    "# Organize circuits and labels in correct order into two lists which will be input for training the model\n",
    "for key in training_data_labels:\n",
    "    training_circuits_l.append(training_circuits[key])\n",
    "    training_data_labels_l.append(training_data_labels[key])\n",
    "\n",
    "for key in test_data_labels:\n",
    "    test_circuits_l.append(test_circuits[key])\n",
    "    test_data_labels_l.append(test_data_labels[key])\n",
    "    \n",
    "all_circuits = training_circuits_l + test_circuits_l\n",
    "\n",
    "train_syms = set([sym for circuit in training_circuits.values() for sym in circuit.free_symbols])\n",
    "test_syms = set([sym for circuit in test_circuits.values() for sym in circuit.free_symbols])\n",
    "\n",
    "print(\"Test circuits need to share training circuits' parameters. The parameters that are not covered: \", test_syms.difference(train_syms))\n",
    "\n",
    "print(\"Total number of circuits: \", len(all_circuits))\n",
    "print(\"Total number of variables: \", len(train_syms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c84f333-8670-492f-b85f-20467a2f7d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_labels_l = np.array(training_data_labels_l)\n",
    "test_data_labels_l = np.array(test_data_labels_l)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "572abfc1-cc81-4fdb-b8bb-6813fe658dd6",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e772e8c8-b747-4c19-8eef-7cc038194d9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sympy import default_sort_key\n",
    "\n",
    "parameters = sorted(\n",
    "    train_syms,\n",
    "    key=default_sort_key)\n",
    "\n",
    "len(parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "04c65634-fa13-47b3-915c-83361d0e1baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_pred_fn(circuits):\n",
    "    if backend:\n",
    "        compiled_circuits1 = backend.get_compiled_circuits([c.to_tk() for c in circuits])\n",
    "        circuits = [Circuit.from_tk(c) for c in compiled_circuits1]\n",
    "        \n",
    "    circuit_fns = [c.lambdify(*parameters) for c in circuits]\n",
    "    \n",
    "    def predict(params):\n",
    "        outputs = Circuit.eval(*(c(*params) for c in circuit_fns), backend = backend)\n",
    "        res = []\n",
    "        \n",
    "        for output in outputs:\n",
    "            predictions = np.abs(output.array) + 1e-9\n",
    "            ratio = predictions / predictions.sum()\n",
    "            res.append(ratio)\n",
    "            \n",
    "        return np.array(res)\n",
    "    return predict\n",
    "\n",
    "train_pred_fn = make_pred_fn(training_circuits_l)\n",
    "#dev_pred_fn = jit(make_pred_fn(dev_circuits))\n",
    "test_pred_fn = make_pred_fn(test_circuits_l)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "868cf7e7-fcbf-4bad-b8bc-4ff0e6b29294",
   "metadata": {},
   "source": [
    "## Loss function and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f376b4aa-0ec6-4037-80eb-935aa75a2f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_cost_fn(pred_fn, labels):\n",
    "    def cost_fn(params, **kwargs):\n",
    "        predictions = pred_fn(params)\n",
    "        #print(labels)\n",
    "        #print(predictions)\n",
    "\n",
    "        cost = -np.sum(labels * np.log(predictions)) / len(labels)  # binary cross-entropy loss\n",
    "        costs.append(cost)\n",
    "\n",
    "        acc = np.sum(np.round(predictions) == labels) / len(labels) / 2  # half due to double-counting\n",
    "        accuracies.append(acc)\n",
    "\n",
    "        return cost\n",
    "\n",
    "    costs, accuracies = [], []\n",
    "    return cost_fn, costs, accuracies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3bb6805-facb-4ec9-9c38-8d1df42022b2",
   "metadata": {},
   "source": [
    "## Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "575f6418-781f-4d16-bf0f-7dc9dacdf0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 1000\n",
    "SEED = 0\n",
    "\n",
    "# This avoids TracerArrayConversionError from jax\n",
    "Tensor.np = np\n",
    "\n",
    "import numpy\n",
    "\n",
    "rng = numpy.random.default_rng(SEED)\n",
    "init_params_spsa = np.array(rng.random(len(parameters)))\n",
    "numpy.random.seed(SEED)\n",
    "\n",
    "#print(jax.make_jaxpr(train_pred_fn)(init_params_spsa))\n",
    "\n",
    "train_cost_fn, train_costs, train_accs = make_cost_fn(train_pred_fn, training_data_labels_l)\n",
    "#dev_cost_fn, dev_costs, dev_accs = make_cost_fn(dev_pred_fn, dev_labels)\n",
    "\n",
    "def callback_fn(xk):\n",
    "    #cost_val = train_cost_fn(xk, costs = cost_store_spsa, accuracies = acc_store_spsa)\n",
    "    cost_val = train_costs[-1]\n",
    "    acc_val = train_accs[-1]\n",
    "    iters = len(train_accs)/2\n",
    "    print(\n",
    "            #f\"Params = {xk}, \"\n",
    "            f\"Iteration = {iters}, \"\n",
    "            f\"Cost = {cost_val}\",\n",
    "            f\"Accuracy on training data = {acc_val}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "47dbc0e6-4261-498f-92fc-f71e28a8aab4",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'replace'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [10]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mminimizeSPSA\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_cost_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx0\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit_params_spsa\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.12\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mniter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mEPOCHS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback_fn\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/noisyopt/main.py:320\u001b[0m, in \u001b[0;36mminimizeSPSA\u001b[0;34m(func, x0, args, bounds, niter, paired, a, c, disp, callback)\u001b[0m\n\u001b[1;32m    318\u001b[0m     fkwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mseed\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m0\u001b[39m, np\u001b[38;5;241m.\u001b[39miinfo(np\u001b[38;5;241m.\u001b[39muint32)\u001b[38;5;241m.\u001b[39mmax)\n\u001b[1;32m    319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m bounds \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m     grad \u001b[38;5;241m=\u001b[39m (\u001b[43mfuncf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mck\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdelta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfkwargs\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m-\u001b[39m funcf(x \u001b[38;5;241m-\u001b[39m ck\u001b[38;5;241m*\u001b[39mdelta, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfkwargs)) \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39mck\u001b[38;5;241m*\u001b[39mdelta)\n\u001b[1;32m    321\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;66;03m# ensure evaluation points are feasible\u001b[39;00m\n\u001b[1;32m    323\u001b[0m     xplus \u001b[38;5;241m=\u001b[39m project(x \u001b[38;5;241m+\u001b[39m ck\u001b[38;5;241m*\u001b[39mdelta)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/noisyopt/main.py:308\u001b[0m, in \u001b[0;36mminimizeSPSA.<locals>.funcf\u001b[0;34m(x, **kwargs)\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfuncf\u001b[39m(x, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 308\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [8]\u001b[0m, in \u001b[0;36mmake_cost_fn.<locals>.cost_fn\u001b[0;34m(params, **kwargs)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcost_fn\u001b[39m(params, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m----> 3\u001b[0m     predictions \u001b[38;5;241m=\u001b[39m \u001b[43mpred_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;66;03m#print(labels)\u001b[39;00m\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;66;03m#print(predictions)\u001b[39;00m\n\u001b[1;32m      7\u001b[0m     cost \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39mnp\u001b[38;5;241m.\u001b[39msum(labels \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39mlog(predictions)) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(labels)  \u001b[38;5;66;03m# binary cross-entropy loss\u001b[39;00m\n",
      "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36mmake_pred_fn.<locals>.predict\u001b[0;34m(params)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(params):\n\u001b[0;32m----> 9\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mCircuit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mc\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcircuit_fns\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbackend\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbackend\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m     res \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m output \u001b[38;5;129;01min\u001b[39;00m outputs:\n",
      "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(params):\n\u001b[0;32m----> 9\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m Circuit\u001b[38;5;241m.\u001b[39meval(\u001b[38;5;241m*\u001b[39m(\u001b[43mc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m circuit_fns), backend \u001b[38;5;241m=\u001b[39m backend)\n\u001b[1;32m     10\u001b[0m     res \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m output \u001b[38;5;129;01min\u001b[39;00m outputs:\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/discopy/monoidal.py:509\u001b[0m, in \u001b[0;36mDiagram.lambdify.<locals>.<lambda>\u001b[0;34m(*xs)\u001b[0m\n\u001b[1;32m    508\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlambdify\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39msymbols, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mlambda\u001b[39;00m \u001b[38;5;241m*\u001b[39mxs: \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdom\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mthen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    510\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mid\u001b[49m\u001b[43m(\u001b[49m\u001b[43mleft\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbox\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlambdify\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msymbols\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mxs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    511\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mid\u001b[49m\u001b[43m(\u001b[49m\u001b[43mright\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mleft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbox\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mright\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayers\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/discopy/monoidal.py:510\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    508\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlambdify\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39msymbols, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mlambda\u001b[39;00m \u001b[38;5;241m*\u001b[39mxs: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mid(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdom)\u001b[38;5;241m.\u001b[39mthen(\u001b[38;5;241m*\u001b[39m(\n\u001b[0;32m--> 510\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mid(left) \u001b[38;5;241m@\u001b[39m \u001b[43mbox\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlambdify\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msymbols\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m(\u001b[38;5;241m*\u001b[39mxs)\n\u001b[1;32m    511\u001b[0m         \u001b[38;5;241m@\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mid(right) \u001b[38;5;28;01mfor\u001b[39;00m left, box, right \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers))\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/discopy/quantum/gates.py:126\u001b[0m, in \u001b[0;36mClassicalGate.lambdify\u001b[0;34m(self, *symbols, **kwargs)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlambdify\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39msymbols, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msympy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m lambdify\n\u001b[0;32m--> 126\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mlambdify\u001b[49m\u001b[43m(\u001b[49m\u001b[43msymbols\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodules\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mTensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mlambda\u001b[39;00m \u001b[38;5;241m*\u001b[39mxs: ClassicalGate(\n\u001b[1;32m    128\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdom, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcod, data(\u001b[38;5;241m*\u001b[39mxs))\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/sympy/utilities/lambdify.py:875\u001b[0m, in \u001b[0;36mlambdify\u001b[0;34m(args, expr, modules, printer, use_imps, dummify, cse)\u001b[0m\n\u001b[1;32m    873\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    874\u001b[0m     cses, _expr \u001b[38;5;241m=\u001b[39m (), expr\n\u001b[0;32m--> 875\u001b[0m funcstr \u001b[38;5;241m=\u001b[39m \u001b[43mfuncprinter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdoprint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfuncname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterable_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_expr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcses\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcses\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# Collect the module imports from the code printers.\u001b[39;00m\n\u001b[1;32m    878\u001b[0m imp_mod_lines \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/sympy/utilities/lambdify.py:1152\u001b[0m, in \u001b[0;36m_EvaluatorPrinter.doprint\u001b[0;34m(self, funcname, args, expr, cses)\u001b[0m\n\u001b[1;32m   1149\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1150\u001b[0m         funcbody\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m = \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(s, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exprrepr(e)))\n\u001b[0;32m-> 1152\u001b[0m str_expr \u001b[38;5;241m=\u001b[39m \u001b[43m_recursive_to_string\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_exprrepr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexpr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1155\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m str_expr:\n\u001b[1;32m   1156\u001b[0m     str_expr \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(str_expr)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/sympy/utilities/lambdify.py:968\u001b[0m, in \u001b[0;36m_recursive_to_string\u001b[0;34m(doprint, arg)\u001b[0m\n\u001b[1;32m    966\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arg\n\u001b[1;32m    967\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 968\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdoprint\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/sympy/printing/codeprinter.py:143\u001b[0m, in \u001b[0;36mCodePrinter.doprint\u001b[0;34m(self, expr, assign_to)\u001b[0m\n\u001b[1;32m    140\u001b[0m expr \u001b[38;5;241m=\u001b[39m _handle_assign_to(expr, assign_to)\n\u001b[1;32m    142\u001b[0m \u001b[38;5;66;03m# Remove re(...) nodes due to UnevaluatedExpr.is_real always is None:\u001b[39;00m\n\u001b[0;32m--> 143\u001b[0m expr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle_UnevaluatedExpr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexpr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;66;03m# keep a set of expressions that are not strictly translatable to Code\u001b[39;00m\n\u001b[1;32m    146\u001b[0m \u001b[38;5;66;03m# and number constants that must be declared and initialized\u001b[39;00m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_not_supported \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/sympy/printing/codeprinter.py:103\u001b[0m, in \u001b[0;36mCodePrinter._handle_UnevaluatedExpr\u001b[0;34m(self, expr)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_handle_UnevaluatedExpr\u001b[39m(\u001b[38;5;28mself\u001b[39m, expr):\n\u001b[0;32m--> 103\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mexpr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreplace\u001b[49m(re, \u001b[38;5;28;01mlambda\u001b[39;00m arg: arg \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[1;32m    104\u001b[0m         arg, UnevaluatedExpr) \u001b[38;5;129;01mand\u001b[39;00m arg\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mis_real \u001b[38;5;28;01melse\u001b[39;00m re(arg))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'replace'"
     ]
    }
   ],
   "source": [
    "result = minimizeSPSA(train_cost_fn, x0=init_params_spsa, a=1, c=0.12, niter=EPOCHS, callback=callback_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537aa180-ea99-48b1-90a3-097e4a9ecc6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ((ax_tl, ax_tr), (ax_bl, ax_br)) = plt.subplots(2, 2, sharex=True, sharey='row', figsize=(10, 6))\n",
    "ax_tl.set_title('Training set')\n",
    "ax_tr.set_title('Development set')\n",
    "ax_bl.set_xlabel('Iterations')\n",
    "ax_br.set_xlabel('Iterations')\n",
    "ax_bl.set_ylabel('Accuracy')\n",
    "ax_tl.set_ylabel('Loss')\n",
    "\n",
    "colours = iter(plt.rcParams['axes.prop_cycle'].by_key()['color'])\n",
    "ax_tl.plot(train_costs[1::2], color=next(colours))  # training evaluates twice per iteration\n",
    "ax_bl.plot(train_accs[1::2], color=next(colours))   # so take every other entry\n",
    "#ax_tr.plot(dev_costs, color=next(colours))\n",
    "#ax_br.plot(dev_accs, color=next(colours))\n",
    "\n",
    "# print test accuracy\n",
    "test_cost_fn, _, test_accs = make_cost_fn(test_pred_fn, test_data_labels_l)\n",
    "test_cost_fn(result.x)\n",
    "print('Test accuracy:', test_accs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ecdc65-e90a-45dc-973c-074f6c7415e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
