{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b09952d6-99a3-41a5-865f-2170e9ee0247",
   "metadata": {},
   "source": [
    "# Circuit learning module: Lambeq manually with SPSA and JAX"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb811fe4-d729-4a44-838d-9c02db4a644d",
   "metadata": {},
   "source": [
    "This module performs the optimization of the parametrized circuit manually compared to Lambeq's automatic QuantumTrainer class. I created this because I wanted to have more control over the optimization process and debug it better. The code is based on the workflow presented in https://github.com/CQCL/Quanthoven."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9a5783f-901a-4bfe-a622-4003b345fb1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import json\n",
    "import os\n",
    "import glob\n",
    "from pathlib import Path\n",
    "from jax import numpy as np\n",
    "from sympy import default_sort_key\n",
    "import numpy\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import jax\n",
    "from jax import jit\n",
    "from noisyopt import minimizeSPSA\n",
    "\n",
    "from discopy.quantum import Circuit\n",
    "from discopy.tensor import Tensor\n",
    "from discopy.utils import loads\n",
    "#from pytket.extensions.qiskit import AerBackend\n",
    "#from pytket.extensions.qulacs import QulacsBackend\n",
    "#from pytket.extensions.cirq import CirqStateSampleBackend\n",
    "backend = None\n",
    "\n",
    "from utils import read_diagrams, create_labeled_classes, bin_class_loss, multi_class_loss, bin_class_acc, multi_class_acc\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "this_folder = os.path.abspath(os.getcwd())\n",
    "os.environ['TOKENIZERS_PARALLELISM'] = 'true'\n",
    "#os.environ[\"JAX_PLATFORMS\"] = \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238fca40-5d8d-4ace-a65f-693885a8caf8",
   "metadata": {},
   "source": [
    "## Read circuit data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f6f00d7-b573-4c5d-a0d6-d5eafc54745e",
   "metadata": {},
   "source": [
    "We read the circuits from the pickled files. Select if we perform binary classification or multi-class classification. Give number of qubits to create classes:\n",
    "- 1 qubits -> 2^1 = 2 classes i.e. binary classification\n",
    "- 2 qubits -> 2^2 = 4 classes\n",
    "- ...\n",
    "- 5 qubits -> 2^5 = 32 classes, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01bac1f9-3bc0-4a25-8f4f-baa2b9c581e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select workload\n",
    "workload = \"small\"\n",
    "#workload = \"medium\"\n",
    "#workload = \"large\"\n",
    "\n",
    "classification = 2\n",
    "layers = 1\n",
    "single_qubit_params = 3\n",
    "n_wire_count = 2\n",
    "\n",
    "loss = multi_class_loss\n",
    "acc = multi_class_acc\n",
    "\n",
    "if classification == 1:\n",
    "    loss = bin_class_loss\n",
    "    acc = bin_class_acc\n",
    "\n",
    "# Access the selected circuits\n",
    "path_name = this_folder + \"//simplified-JOB-diagrams//\" + workload + \"//circuits//\" + str(classification) + \"//\" + str(layers) + \"_layer//\" + str(single_qubit_params) + \"_single_qubit_params//\" + str(n_wire_count) + \"_n_wire_count//\"\n",
    "\n",
    "training_circuits_paths = glob.glob(path_name + \"training//[0-9]*.p\")\n",
    "validation_circuits_paths = glob.glob(path_name + \"validation//[0-9]*.p\")\n",
    "test_circuits_paths = glob.glob(path_name + \"test//[0-9]*.p\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ff0a551-444c-40a7-bf66-8e929bc49a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_circuits = read_diagrams(training_circuits_paths)\n",
    "validation_circuits = read_diagrams(validation_circuits_paths)\n",
    "test_circuits = read_diagrams(test_circuits_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2da3a7c-6a93-44e9-9640-7e9ead005cb2",
   "metadata": {},
   "source": [
    "## Read training and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "774e9f52-69c9-4e1c-8a70-76e1198d12f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data, test_data, validation_data = None, None, None\n",
    "data_path = this_folder + \"//data//\" + workload + \"//\"\n",
    "\n",
    "with open(data_path + \"training_data.json\", \"r\") as inputfile:\n",
    "    training_data = json.load(inputfile)['training_data']\n",
    "with open(data_path + \"test_data.json\", \"r\") as inputfile:\n",
    "    test_data = json.load(inputfile)['test_data']\n",
    "with open(data_path + \"validation_data.json\", \"r\") as inputfile:\n",
    "    validation_data = json.load(inputfile)['validation_data']\n",
    "\n",
    "training_data_labels = create_labeled_classes(training_data, classification)\n",
    "test_data_labels = create_labeled_classes(test_data, classification)\n",
    "validation_data_labels = create_labeled_classes(validation_data, classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6cad830-e6c3-4c29-9ce6-0d6bec2794bc",
   "metadata": {},
   "source": [
    "## Lambeq optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce559dbf-2b4b-4853-82ed-58832aa11e61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test circuits need to share training circuits' parameters. The parameters that are not covered (should be empty set, set()):  set()\n",
      "Validation circuits need to share training circuits' parameters. The parameters that are not covered (should be empty set, set()):  set()\n",
      "Total number of circuits:  29\n",
      "Total number of variables:  58\n"
     ]
    }
   ],
   "source": [
    "#all_circuits = list(training_circuits.values()) + list(test_circuits.values())\n",
    "\n",
    "training_circuits_l = []\n",
    "test_circuits_l = []\n",
    "validation_circuits_l = []\n",
    "\n",
    "training_data_labels_l = []\n",
    "test_data_labels_l = []\n",
    "validation_data_labels_l = []\n",
    "\n",
    "# Organize circuits and labels in correct order into two lists which will be input for training the model\n",
    "for key in training_data_labels:\n",
    "    training_circuits_l.append(training_circuits[key])\n",
    "    training_data_labels_l.append(training_data_labels[key])\n",
    "\n",
    "for key in test_data_labels:\n",
    "    test_circuits_l.append(test_circuits[key])\n",
    "    test_data_labels_l.append(test_data_labels[key])\n",
    "    \n",
    "for key in validation_data_labels:\n",
    "    validation_circuits_l.append(validation_circuits[key])\n",
    "    validation_data_labels_l.append(validation_data_labels[key])\n",
    "\n",
    "all_circuits = training_circuits_l + test_circuits_l + validation_circuits_l\n",
    "\n",
    "train_syms = set([sym for circuit in training_circuits.values() for sym in circuit.free_symbols])\n",
    "test_syms = set([sym for circuit in test_circuits.values() for sym in circuit.free_symbols])\n",
    "val_syms = set([sym for circuit in validation_circuits.values() for sym in circuit.free_symbols])\n",
    "\n",
    "print(\"Test circuits need to share training circuits' parameters. The parameters that are not covered (should be empty set, set()): \", test_syms.difference(train_syms))\n",
    "print(\"Validation circuits need to share training circuits' parameters. The parameters that are not covered (should be empty set, set()): \", val_syms.difference(train_syms))\n",
    "\n",
    "print(\"Total number of circuits: \", len(all_circuits))\n",
    "print(\"Total number of variables: \", len(train_syms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c84f333-8670-492f-b85f-20467a2f7d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_labels_l = np.array(training_data_labels_l)\n",
    "test_data_labels_l = np.array(test_data_labels_l)\n",
    "validation_data_labels_l = np.array(validation_data_labels_l)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "572abfc1-cc81-4fdb-b8bb-6813fe658dd6",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e772e8c8-b747-4c19-8eef-7cc038194d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = sorted(\n",
    "    train_syms,\n",
    "    key=default_sort_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "04c65634-fa13-47b3-915c-83361d0e1baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_pred_fn(circuits):\n",
    "    # In the case we want to use other backends. \n",
    "    # Currently does not work properly.\n",
    "    if backend:\n",
    "        compiled_circuits1 = backend.get_compiled_circuits([c.to_tk() for c in circuits])\n",
    "        circuits = [Circuit.from_tk(c) for c in compiled_circuits1]\n",
    "        \n",
    "    circuit_fns = [c.lambdify(*parameters) for c in circuits]\n",
    "    \n",
    "    def predict(params):\n",
    "        outputs = Circuit.eval(*(c(*params) for c in circuit_fns), backend = backend)\n",
    "        res = []\n",
    "        \n",
    "        for output in outputs:\n",
    "            predictions = np.abs(output.array) + 1e-9\n",
    "            ratio = predictions / predictions.sum()\n",
    "            res.append(ratio)\n",
    "            \n",
    "        return np.array(res)\n",
    "    return predict\n",
    "\n",
    "train_pred_fn = jit(make_pred_fn(training_circuits_l))\n",
    "dev_pred_fn = jit(make_pred_fn(validation_circuits_l))\n",
    "test_pred_fn = make_pred_fn(test_circuits_l)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "868cf7e7-fcbf-4bad-b8bc-4ff0e6b29294",
   "metadata": {},
   "source": [
    "## Loss function and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f376b4aa-0ec6-4037-80eb-935aa75a2f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_cost_fn(pred_fn, labels):\n",
    "    def cost_fn(params, **kwargs):\n",
    "        predictions = pred_fn(params)\n",
    "\n",
    "        cost = loss(predictions, labels) #-np.sum(labels * np.log(predictions)) / len(labels)  # binary cross-entropy loss\n",
    "        costs.append(cost)\n",
    "\n",
    "        accuracy = acc(predictions, labels) #np.sum(np.round(predictions) == labels) / len(labels) / 2  # half due to double-counting\n",
    "        accuracies.append(accuracy)\n",
    "\n",
    "        return cost\n",
    "\n",
    "    costs, accuracies = [], []\n",
    "    return cost_fn, costs, accuracies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3bb6805-facb-4ec9-9c38-8d1df42022b2",
   "metadata": {},
   "source": [
    "## Minimization with noisyopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "575f6418-781f-4d16-bf0f-7dc9dacdf0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 10000\n",
    "SEED = 0\n",
    "\n",
    "# This avoids TracerArrayConversionError from jax\n",
    "Tensor.np = np\n",
    "\n",
    "rng = numpy.random.default_rng(SEED)\n",
    "init_params_spsa = np.array(rng.random(len(parameters)))\n",
    "numpy.random.seed(SEED)\n",
    "\n",
    "train_cost_fn, train_costs, train_accs = make_cost_fn(train_pred_fn, training_data_labels_l)\n",
    "dev_cost_fn, dev_costs, dev_accs = make_cost_fn(dev_pred_fn, validation_data_labels_l)\n",
    "\n",
    "def callback_fn(xk):\n",
    "    valid_loss = dev_cost_fn(xk)\n",
    "    train_loss = round(train_costs[-1], 4)\n",
    "    train_acc = round(train_accs[-1], 4)\n",
    "    valid_acc = round(dev_accs[-1], 4)\n",
    "    iters = int(len(train_accs)/2)\n",
    "    if iters % 100 == 0:\n",
    "        print(\n",
    "                #f\"Params = {xk}, \"\n",
    "                f\"Epoch: {iters}   \",\n",
    "                f\"train/loss: {train_loss}   \",\n",
    "                f\"valid/loss: {round(valid_loss, 4)}   \",\n",
    "                f\"train/acc: {train_acc}   \",\n",
    "                f\"valid/acc: {valid_acc}\"\n",
    "            )\n",
    "    return valid_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95052c87-ffb7-4c4f-952f-e63d9c54b2ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.12953465 0.30433276 0.09912094 0.46701157] [1 0 0 0]\n",
      "[0.12953465 0.30433276 0.09912094 0.46701157] [1 0 0 0]\n",
      "[0.12953465 0.30433276 0.09912094 0.46701157] [1 0 0 0]\n",
      "[0.12953465 0.30433276 0.09912094 0.46701157] [1 0 0 0]\n",
      "[0.12953465 0.30433276 0.09912094 0.46701157] [1 0 0 0]\n",
      "[0.12953465 0.30433276 0.09912094 0.46701157] [0 1 0 0]\n",
      "[0.08356787 0.33634683 0.063947   0.5161383 ] [0 1 0 0]\n",
      "[0.1637605  0.28049564 0.12531085 0.43043298] [0 1 0 0]\n",
      "[0.12953465 0.30433276 0.09912094 0.46701157] [0 1 0 0]\n",
      "[0.06686339 0.34798142 0.05116439 0.53399086] [0 1 0 0]\n",
      "[0.08356787 0.33634683 0.063947   0.5161383 ] [0 0 1 0]\n",
      "[0.1637605  0.28049564 0.12531085 0.43043298] [0 0 1 0]\n",
      "[0.08356787 0.33634683 0.063947   0.5161383 ] [0 0 1 0]\n",
      "[0.1637605  0.28049564 0.12531085 0.43043298] [0 0 1 0]\n",
      "[0.08371464 0.33624503 0.06406009 0.5159801 ] [0 0 1 0]\n",
      "[0.06686339 0.34798142 0.05116439 0.53399086] [0 0 0 1]\n",
      "[0.06686339 0.34798142 0.05116439 0.53399086] [0 0 0 1]\n",
      "[0.08371464 0.33624503 0.06406009 0.5159801 ] [0 0 0 1]\n",
      "[0.08371464 0.33624503 0.06406009 0.5159801 ] [0 0 0 1]\n",
      "[0.32511887 0.17765719 0.26814508 0.22907886] [1 0 0 0]\n",
      "[0.32511887 0.17765719 0.26814508 0.22907886] [1 0 0 0]\n",
      "[0.32511887 0.17765719 0.26814508 0.22907886] [1 0 0 0]\n",
      "[0.32511887 0.17765719 0.26814508 0.22907886] [1 0 0 0]\n",
      "[0.32511887 0.17765719 0.26814508 0.22907886] [1 0 0 0]\n",
      "[0.32511887 0.17765719 0.26814508 0.22907886] [0 1 0 0]\n",
      "[0.22342467 0.2587107  0.1842718  0.33359283] [0 1 0 0]\n",
      "[0.39101288 0.12513743 0.3224919  0.16135778] [0 1 0 0]\n",
      "[0.32511887 0.17765719 0.26814508 0.22907886] [0 1 0 0]\n",
      "[0.12134151 0.34007442 0.10007752 0.43850654] [0 1 0 0]\n",
      "[0.22342467 0.2587107  0.1842718  0.33359283] [0 0 1 0]\n",
      "[0.39101288 0.12513743 0.3224919  0.16135778] [0 0 1 0]\n",
      "[0.22342467 0.2587107  0.1842718  0.33359283] [0 0 1 0]\n",
      "[0.39101288 0.12513743 0.3224919  0.16135778] [0 0 1 0]\n",
      "[0.18184477 0.29185134 0.14997914 0.3763247 ] [0 0 1 0]\n",
      "[0.12134151 0.34007442 0.10007752 0.43850654] [0 0 0 1]\n",
      "[0.12134151 0.34007442 0.10007752 0.43850654] [0 0 0 1]\n",
      "[0.18184477 0.29185134 0.14997914 0.3763247 ] [0 0 0 1]\n",
      "[0.18184477 0.29185134 0.14997914 0.3763247 ] [0 0 0 1]\n",
      "[0.32009652 0.18192758 0.26691282 0.23106307] [1 0 0 0]\n",
      "[0.32009652 0.18192758 0.26691282 0.23106307] [1 0 0 0]\n",
      "[0.38676098 0.12807366 0.32250103 0.16266434] [0 1 0 0]\n",
      "[0.38676098 0.12807366 0.32250103 0.16266434] [0 1 0 0]\n",
      "[0.01389204 0.42928997 0.01158443 0.5452335 ] [0 0 1 0]\n",
      "Epoch: 100    train/loss: 5.999499797821045    valid/loss: 2.246999979019165    train/acc: 0.4737    valid/acc: 0.4\n",
      "[0.32840246 0.17423551 0.29890448 0.1984576 ] [1 0 0 0]\n",
      "[0.32840246 0.17423551 0.29890448 0.1984576 ] [1 0 0 0]\n",
      "[0.32840246 0.17423551 0.29890448 0.1984576 ] [1 0 0 0]\n",
      "[0.32840246 0.17423551 0.29890448 0.1984576 ] [1 0 0 0]\n",
      "[0.32840246 0.17423551 0.29890448 0.1984576 ] [1 0 0 0]\n",
      "[0.32840246 0.17423551 0.29890448 0.1984576 ] [0 1 0 0]\n",
      "[0.22752434 0.26432115 0.20708734 0.3010671 ] [0 1 0 0]\n",
      "[0.34880236 0.15601812 0.31747186 0.17770772] [0 1 0 0]\n",
      "[0.32840246 0.17423551 0.29890448 0.1984576 ] [0 1 0 0]\n",
      "[0.05346742 0.41975647 0.04866477 0.4781113 ] [0 1 0 0]\n",
      "[0.22752434 0.26432115 0.20708734 0.3010671 ] [0 0 1 0]\n",
      "[0.34880236 0.15601812 0.31747186 0.17770772] [0 0 1 0]\n",
      "[0.22752434 0.26432115 0.20708734 0.3010671 ] [0 0 1 0]\n",
      "[0.34880236 0.15601812 0.31747186 0.17770772] [0 0 1 0]\n",
      "[0.2037506  0.28555137 0.18544962 0.32524842] [0 0 1 0]\n",
      "[0.05346742 0.41975647 0.04866477 0.4781113 ] [0 0 0 1]\n",
      "[0.05346742 0.41975647 0.04866477 0.4781113 ] [0 0 0 1]\n",
      "[0.2037506  0.28555137 0.18544962 0.32524842] [0 0 0 1]\n",
      "[0.2037506  0.28555137 0.18544962 0.32524842] [0 0 0 1]\n",
      "[0.3602231  0.14112101 0.35228863 0.14636722] [1 0 0 0]\n",
      "[0.3602231  0.14112101 0.35228863 0.14636722] [1 0 0 0]\n",
      "[0.3602231  0.14112101 0.35228863 0.14636722] [1 0 0 0]\n",
      "[0.3602231  0.14112101 0.35228863 0.14636722] [1 0 0 0]\n",
      "[0.3602231  0.14112101 0.35228863 0.14636722] [1 0 0 0]\n",
      "[0.3602231  0.14112101 0.35228863 0.14636722] [0 1 0 0]\n",
      "[0.26567885 0.23291759 0.2598271  0.24157639] [0 1 0 0]\n",
      "[0.36920547 0.13239956 0.36107337 0.13732162] [0 1 0 0]\n",
      "[0.3602231  0.14112101 0.35228863 0.14636722] [0 1 0 0]\n",
      "[0.07116133 0.4217823  0.06959396 0.4374624 ] [0 1 0 0]\n",
      "[0.26567885 0.23291759 0.2598271  0.24157639] [0 0 1 0]\n",
      "[0.36920547 0.13239956 0.36107337 0.13732162] [0 0 1 0]\n",
      "[0.26567885 0.23291759 0.2598271  0.24157639] [0 0 1 0]\n",
      "[0.36920547 0.13239956 0.36107337 0.13732162] [0 0 1 0]\n",
      "[0.20996822 0.28700936 0.20534381 0.29767868] [0 0 1 0]\n",
      "[0.07116133 0.4217823  0.06959396 0.4374624 ] [0 0 0 1]\n",
      "[0.07116133 0.4217823  0.06959396 0.4374624 ] [0 0 0 1]\n",
      "[0.20996822 0.28700936 0.20534381 0.29767868] [0 0 0 1]\n",
      "[0.20996822 0.28700936 0.20534381 0.29767868] [0 0 0 1]\n",
      "[0.32087526 0.18150087 0.29201174 0.20561211] [1 0 0 0]\n",
      "[0.32087526 0.18150087 0.29201174 0.20561211] [1 0 0 0]\n",
      "[0.3774793  0.13080965 0.34352404 0.14818686] [0 1 0 0]\n",
      "[0.3774793  0.13080965 0.34352404 0.14818686] [0 1 0 0]\n",
      "[0.07074117 0.4055068  0.06437654 0.45937547] [0 0 1 0]\n",
      "Epoch: 200    train/loss: 6.175899982452393    valid/loss: 2.3671000003814697    train/acc: 0.3684    valid/acc: 0.4\n",
      "[0.397899   0.11447482 0.3542047  0.13342151] [1 0 0 0]\n",
      "[0.397899   0.11447482 0.3542047  0.13342151] [1 0 0 0]\n",
      "[0.397899   0.11447482 0.3542047  0.13342151] [1 0 0 0]\n",
      "[0.397899   0.11447482 0.3542047  0.13342151] [1 0 0 0]\n",
      "[0.397899   0.11447482 0.3542047  0.13342151] [1 0 0 0]\n",
      "[0.397899   0.11447482 0.3542047  0.13342151] [0 1 0 0]\n",
      "[0.31371146 0.18795842 0.279262   0.21906815] [0 1 0 0]\n",
      "[0.44572833 0.07272627 0.39678204 0.0847634 ] [0 1 0 0]\n",
      "[0.397899   0.11447482 0.3542047  0.13342151] [0 1 0 0]\n",
      "[0.10080744 0.3737938  0.08973851 0.43566027] [0 1 0 0]\n",
      "[0.31371146 0.18795842 0.279262   0.21906815] [0 0 1 0]\n",
      "[0.44572833 0.07272627 0.39678204 0.0847634 ] [0 0 1 0]\n",
      "[0.31371146 0.18795842 0.279262   0.21906815] [0 0 1 0]\n",
      "[0.44572833 0.07272627 0.39678204 0.0847634 ] [0 0 1 0]\n",
      "[0.32205665 0.18067475 0.2866916  0.21057704] [0 0 1 0]\n",
      "[0.10080744 0.3737938  0.08973851 0.43566027] [0 0 0 1]\n",
      "[0.10080744 0.3737938  0.08973851 0.43566027] [0 0 0 1]\n",
      "[0.32205665 0.18067475 0.2866916  0.21057704] [0 0 0 1]\n",
      "[0.32205665 0.18067475 0.2866916  0.21057704] [0 0 0 1]\n",
      "[0.42644906 0.10479365 0.3367021  0.13205513] [1 0 0 0]\n",
      "[0.42644906 0.10479365 0.3367021  0.13205513] [1 0 0 0]\n",
      "[0.42644906 0.10479365 0.3367021  0.13205513] [1 0 0 0]\n",
      "[0.42644906 0.10479365 0.3367021  0.13205513] [1 0 0 0]\n",
      "[0.42644906 0.10479365 0.3367021  0.13205513] [1 0 0 0]\n",
      "[0.42644906 0.10479365 0.3367021  0.13205513] [0 1 0 0]\n",
      "[0.34982297 0.16546474 0.27620223 0.20851003] [0 1 0 0]\n",
      "[0.45832944 0.07955115 0.3618735  0.10024588] [0 1 0 0]\n",
      "[0.42644906 0.10479365 0.3367021  0.13205513] [0 1 0 0]\n",
      "[0.0694385  0.38746938 0.05482391 0.4882682 ] [0 1 0 0]\n",
      "[0.34982297 0.16546474 0.27620223 0.20851003] [0 0 1 0]\n",
      "[0.45832944 0.07955115 0.3618735  0.10024588] [0 0 1 0]\n",
      "[0.34982297 0.16546474 0.27620223 0.20851003] [0 0 1 0]\n",
      "[0.45832944 0.07955115 0.3618735  0.10024588] [0 0 1 0]\n",
      "[0.3158213  0.19238654 0.2493593  0.24243288] [0 0 1 0]\n",
      "[0.0694385  0.38746938 0.05482391 0.4882682 ] [0 0 0 1]\n",
      "[0.0694385  0.38746938 0.05482391 0.4882682 ] [0 0 0 1]\n",
      "[0.3158213  0.19238654 0.2493593  0.24243288] [0 0 0 1]\n",
      "[0.3158213  0.19238654 0.2493593  0.24243288] [0 0 0 1]\n",
      "[0.42880145 0.1000577  0.34827584 0.12286498] [1 0 0 0]\n",
      "[0.42880145 0.1000577  0.34827584 0.12286498] [1 0 0 0]\n",
      "[0.45577872 0.07811446 0.37018743 0.09591938] [0 1 0 0]\n",
      "[0.45577872 0.07811446 0.37018743 0.09591938] [0 1 0 0]\n",
      "[0.03351976 0.4215806  0.02722549 0.51767415] [0 0 1 0]\n",
      "Epoch: 300    train/loss: 5.95989990234375    valid/loss: 2.853099822998047    train/acc: 0.3684    valid/acc: 0.4\n",
      "[0.3953118  0.128945   0.3150831  0.16066022] [1 0 0 0]\n",
      "[0.3953118  0.128945   0.3150831  0.16066022] [1 0 0 0]\n",
      "[0.3953118  0.128945   0.3150831  0.16066022] [1 0 0 0]\n",
      "[0.3953118  0.128945   0.3150831  0.16066022] [1 0 0 0]\n",
      "[0.3953118  0.128945   0.3150831  0.16066022] [1 0 0 0]\n",
      "[0.3953118  0.128945   0.3150831  0.16066022] [0 1 0 0]\n",
      "[0.2830131  0.21879876 0.22557405 0.2726141 ] [0 1 0 0]\n",
      "[0.41968992 0.10943942 0.3345135  0.13635725] [0 1 0 0]\n",
      "[0.3953118  0.128945   0.3150831  0.16066022] [0 1 0 0]\n",
      "[0.00430392 0.4417997  0.00343111 0.5504653 ] [0 1 0 0]\n",
      "[0.2830131  0.21879876 0.22557405 0.2726141 ] [0 0 1 0]\n",
      "[0.41968992 0.10943942 0.3345135  0.13635725] [0 0 1 0]\n",
      "[0.2830131  0.21879876 0.22557405 0.2726141 ] [0 0 1 0]\n",
      "[0.41968992 0.10943942 0.3345135  0.13635725] [0 0 1 0]\n",
      "[0.30098003 0.20442179 0.23989789 0.25470036] [0 0 1 0]\n",
      "[0.00430392 0.4417997  0.00343111 0.5504653 ] [0 0 0 1]\n",
      "[0.00430392 0.4417997  0.00343111 0.5504653 ] [0 0 0 1]\n",
      "[0.30098003 0.20442179 0.23989789 0.25470036] [0 0 0 1]\n",
      "[0.30098003 0.20442179 0.23989789 0.25470036] [0 0 0 1]\n",
      "[0.43015993 0.1031698  0.33768097 0.12898934] [1 0 0 0]\n",
      "[0.43015993 0.1031698  0.33768097 0.12898934] [1 0 0 0]\n",
      "[0.43015993 0.1031698  0.33768097 0.12898934] [1 0 0 0]\n",
      "[0.43015993 0.1031698  0.33768097 0.12898934] [1 0 0 0]\n",
      "[0.43015993 0.1031698  0.33768097 0.12898934] [1 0 0 0]\n",
      "[0.43015993 0.1031698  0.33768097 0.12898934] [0 1 0 0]\n",
      "[0.3149582  0.1945536  0.2472459  0.24324228] [0 1 0 0]\n",
      "[0.40206277 0.12545794 0.31562415 0.15685505] [0 1 0 0]\n",
      "[0.43015993 0.1031698  0.33768097 0.12898934] [0 1 0 0]\n",
      "[0.05616809 0.39983746 0.04409285 0.4999016 ] [0 1 0 0]\n",
      "[0.3149582  0.1945536  0.2472459  0.24324228] [0 0 1 0]\n",
      "[0.40206277 0.12545794 0.31562415 0.15685505] [0 0 1 0]\n",
      "[0.3149582  0.1945536  0.2472459  0.24324228] [0 0 1 0]\n",
      "[0.40206277 0.12545794 0.31562415 0.15685505] [0 0 1 0]\n",
      "[0.271188   0.22927378 0.21288706 0.28665116] [0 0 1 0]\n",
      "[0.05616809 0.39983746 0.04409285 0.4999016 ] [0 0 0 1]\n",
      "[0.05616809 0.39983746 0.04409285 0.4999016 ] [0 0 0 1]\n",
      "[0.271188   0.22927378 0.21288706 0.28665116] [0 0 0 1]\n",
      "[0.271188   0.22927378 0.21288706 0.28665116] [0 0 0 1]\n",
      "[0.4377491  0.09432315 0.3533906  0.11453719] [1 0 0 0]\n",
      "[0.4377491  0.09432315 0.3533906  0.11453719] [1 0 0 0]\n",
      "[0.4105701  0.11650592 0.3314494  0.14147459] [0 1 0 0]\n",
      "[0.4105701  0.11650592 0.3314494  0.14147459] [0 1 0 0]\n",
      "[0.04359813 0.4160236  0.03519647 0.50518185] [0 0 1 0]\n",
      "Epoch: 400    train/loss: 6.024499893188477    valid/loss: 2.217900037765503    train/acc: 0.3158    valid/acc: 0.4\n",
      "[0.41129157 0.08851057 0.41183758 0.0883602 ] [1 0 0 0]\n",
      "[0.41129157 0.08851057 0.41183758 0.0883602 ] [1 0 0 0]\n",
      "[0.41129157 0.08851057 0.41183758 0.0883602 ] [1 0 0 0]\n",
      "[0.41129157 0.08851057 0.41183758 0.0883602 ] [1 0 0 0]\n",
      "[0.41129157 0.08851057 0.41183758 0.0883602 ] [1 0 0 0]\n",
      "[0.41129157 0.08851057 0.41183758 0.0883602 ] [0 1 0 0]\n",
      "[0.31709206 0.18285185 0.3175135  0.18254256] [0 1 0 0]\n",
      "[0.3707735  0.12908974 0.37126562 0.12887114] [0 1 0 0]\n",
      "[0.41129157 0.08851057 0.41183758 0.0883602 ] [0 1 0 0]\n",
      "[0.05541721 0.44492313 0.05549062 0.44416904] [0 1 0 0]\n",
      "[0.31709206 0.18285185 0.3175135  0.18254256] [0 0 1 0]\n",
      "[0.3707735  0.12908974 0.37126562 0.12887114] [0 0 1 0]\n",
      "[0.31709206 0.18285185 0.3175135  0.18254256] [0 0 1 0]\n",
      "[0.3707735  0.12908974 0.37126562 0.12887114] [0 0 1 0]\n",
      "[0.27167386 0.2283391  0.27203456 0.22795245] [0 0 1 0]\n",
      "[0.05541721 0.44492313 0.05549062 0.44416904] [0 0 0 1]\n",
      "[0.05541721 0.44492313 0.05549062 0.44416904] [0 0 0 1]\n",
      "[0.27167386 0.2283391  0.27203456 0.22795245] [0 0 0 1]\n",
      "[0.27167386 0.2283391  0.27203456 0.22795245] [0 0 0 1]\n",
      "[0.40858808 0.09519403 0.3972167  0.09900123] [1 0 0 0]\n",
      "[0.40858808 0.09519403 0.3972167  0.09900123] [1 0 0 0]\n",
      "[0.40858808 0.09519403 0.3972167  0.09900123] [1 0 0 0]\n",
      "[0.40858808 0.09519403 0.3972167  0.09900123] [1 0 0 0]\n",
      "[0.40858808 0.09519403 0.3972167  0.09900123] [1 0 0 0]\n",
      "[0.40858808 0.09519403 0.3972167  0.09900123] [0 1 0 0]\n",
      "[0.31019786 0.19031265 0.30156368 0.19792579] [0 1 0 0]\n",
      "[0.3567893  0.1452706  0.34685937 0.15108079] [0 1 0 0]\n",
      "[0.40858808 0.09519403 0.3972167  0.09900123] [0 1 0 0]\n",
      "[0.02535409 0.4656858  0.02465015 0.48430997] [0 1 0 0]\n",
      "[0.31019786 0.19031265 0.30156368 0.19792579] [0 0 1 0]\n",
      "[0.3567893  0.1452706  0.34685937 0.15108079] [0 0 1 0]\n",
      "[0.31019786 0.19031265 0.30156368 0.19792579] [0 0 1 0]\n",
      "[0.3567893  0.1452706  0.34685937 0.15108079] [0 0 1 0]\n",
      "[0.24083486 0.2573698  0.23413214 0.26766327] [0 0 1 0]\n",
      "[0.02535409 0.4656858  0.02465015 0.48430997] [0 0 0 1]\n",
      "[0.02535409 0.4656858  0.02465015 0.48430997] [0 0 0 1]\n",
      "[0.24083486 0.2573698  0.23413214 0.26766327] [0 0 0 1]\n",
      "[0.24083486 0.2573698  0.23413214 0.26766327] [0 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "result = minimizeSPSA(train_cost_fn, x0=init_params_spsa, a = 0.01, c = 0.001, niter=EPOCHS, callback=callback_fn)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537aa180-ea99-48b1-90a3-097e4a9ecc6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ((ax_tl, ax_tr), (ax_bl, ax_br)) = plt.subplots(2, 2, sharex=True, sharey='row', figsize=(10, 6))\n",
    "ax_tl.set_title('Training set')\n",
    "ax_tr.set_title('Development set')\n",
    "ax_bl.set_xlabel('Iterations')\n",
    "ax_br.set_xlabel('Iterations')\n",
    "ax_bl.set_ylabel('Accuracy')\n",
    "ax_tl.set_ylabel('Loss')\n",
    "\n",
    "colours = iter(plt.rcParams['axes.prop_cycle'].by_key()['color'])\n",
    "ax_tl.plot(train_costs[1::2], color=next(colours))  # training evaluates twice per iteration\n",
    "ax_bl.plot(train_accs[1::2], color=next(colours))   # so take every other entry\n",
    "ax_tr.plot(dev_costs, color=next(colours))\n",
    "ax_br.plot(dev_accs, color=next(colours))\n",
    "\n",
    "# print test accuracy\n",
    "test_cost_fn, _, test_accs = make_cost_fn(test_pred_fn, test_data_labels_l)\n",
    "test_cost_fn(result.x)\n",
    "print('Test accuracy:', test_accs[0])\n",
    "\n",
    "plt.savefig(this_folder + \"//results//\" + workload + \"_\" + str(classification) + \"_\" + str(layers) + \"_\" + str(single_qubit_params) + \".png\") "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
