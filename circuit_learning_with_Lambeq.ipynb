{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b09952d6-99a3-41a5-865f-2170e9ee0247",
   "metadata": {},
   "source": [
    "# Circuit learning module: Lambeq's QuantumTrainer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb811fe4-d729-4a44-838d-9c02db4a644d",
   "metadata": {},
   "source": [
    "This module performs the optimization with Lambeq's native optimizer. Because the circuits are constructed with Lambeq and DisCoPy, this optimizer is the natural choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9a5783f-901a-4bfe-a622-4003b345fb1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\valte\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\lambeq\\text2diagram\\ccg_parser.py:24: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import glob\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from discopy.utils import loads\n",
    "from pytket.extensions.qiskit import AerBackend\n",
    "from lambeq import TketModel\n",
    "from lambeq import QuantumTrainer, SPSAOptimizer\n",
    "from lambeq import Dataset\n",
    "\n",
    "this_folder = os.path.abspath(os.getcwd())\n",
    "warnings.filterwarnings('ignore')\n",
    "os.environ['TOKENIZERS_PARALLELISM'] = 'true'\n",
    "\n",
    "BATCH_SIZE = 60\n",
    "EPOCHS = 1000\n",
    "SEED = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238fca40-5d8d-4ace-a65f-693885a8caf8",
   "metadata": {},
   "source": [
    "## Read circuit data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f6f00d7-b573-4c5d-a0d6-d5eafc54745e",
   "metadata": {},
   "source": [
    "We read the circuits from the pickled files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ff0a551-444c-40a7-bf66-8e929bc49a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_circuits_paths = glob.glob(this_folder + \"//simplified-JOB-diagrams//circuits//training//[0-9]*.p\")\n",
    "test_circuits_paths = glob.glob(this_folder + \"//simplified-JOB-diagrams//circuits//test//[0-9]*.p\")\n",
    "\n",
    "def read_diagrams(circuit_paths):\n",
    "    circuits = {}\n",
    "    for serialized_diagram in circuit_paths:\n",
    "        base_name = Path(serialized_diagram).stem\n",
    "        f = open(serialized_diagram, \"rb\")\n",
    "        diagram = pickle.load(f)\n",
    "        circuits[base_name] = diagram\n",
    "    return circuits\n",
    "\n",
    "\n",
    "training_circuits = read_diagrams(training_circuits_paths)\n",
    "test_circuits = read_diagrams(test_circuits_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2da3a7c-6a93-44e9-9640-7e9ead005cb2",
   "metadata": {},
   "source": [
    "## Read training and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "774e9f52-69c9-4e1c-8a70-76e1198d12f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data, test_data = None, None\n",
    "with open(this_folder + \"//data//training_data.json\", \"r\") as inputfile:\n",
    "    training_data = json.load(inputfile)['training_data']\n",
    "with open(this_folder + \"//data//test_data.json\", \"r\") as inputfile:\n",
    "    test_data = json.load(inputfile)['test_data']\n",
    "    \n",
    "\n",
    "def time_to_states(data):\n",
    "    labeled_data = {}\n",
    "    for elem in data:\n",
    "        if elem[\"time\"] < 2001:\n",
    "            labeled_data[elem[\"name\"]] = [1,0] # corresponds to |0>\n",
    "        else:\n",
    "            labeled_data[elem[\"name\"]] = [0,1] # corresponds to |1>\n",
    "    return labeled_data\n",
    "\n",
    "\n",
    "training_data_labels = time_to_states(training_data)\n",
    "test_data_labels = time_to_states(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6cad830-e6c3-4c29-9ce6-0d6bec2794bc",
   "metadata": {},
   "source": [
    "## Lambeq optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce559dbf-2b4b-4853-82ed-58832aa11e61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of circuits:  35\n",
      "Total number of variables:  1158\n"
     ]
    }
   ],
   "source": [
    "all_circuits = list(training_circuits.values()) + list(test_circuits.values())\n",
    "\n",
    "#print(all_circuits[0].free_symbols)\n",
    "\n",
    "print(\"Total number of circuits: \", len(all_circuits))\n",
    "print(\"Total number of variables: \", len([sym for circuit in all_circuits for sym in circuit.free_symbols]))\n",
    "\n",
    "backend = AerBackend()\n",
    "backend_config = {\n",
    "    'backend': backend,\n",
    "    'compilation': backend.default_compilation_pass(2),\n",
    "    'shots': 8192\n",
    "}\n",
    "\n",
    "model = TketModel.from_diagrams(all_circuits, backend_config=backend_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "868cf7e7-fcbf-4bad-b8bc-4ff0e6b29294",
   "metadata": {},
   "source": [
    "## Loss function and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7cde594c-ad61-4dd6-ac79-85496f2cfed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = lambda y_hat, y: -np.sum(y * np.log(y_hat)) / len(y)  # binary cross-entropy loss\n",
    "acc = lambda y_hat, y: np.sum(np.round(y_hat) == y) / len(y) / 2  # half due to double-counting\n",
    "eval_metrics = {\"acc\": acc}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3bb6805-facb-4ec9-9c38-8d1df42022b2",
   "metadata": {},
   "source": [
    "## Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "47dbc0e6-4261-498f-92fc-f71e28a8aab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = QuantumTrainer(\n",
    "    model,\n",
    "    loss_function=loss,\n",
    "    epochs=EPOCHS,\n",
    "    optimizer=SPSAOptimizer,\n",
    "    optim_hyperparams={'a': 0.05, 'c': 0.06, 'A':0.01*EPOCHS},\n",
    "    evaluate_functions=eval_metrics,\n",
    "    evaluate_on_train=True,\n",
    "    verbose = 'text',\n",
    "    seed=SEED\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6740fda4-4099-43b4-8843-fb3557f12540",
   "metadata": {},
   "outputs": [],
   "source": [
    "def randint(low=-1 << 31, high=(1 << 31)-1):\n",
    "    return np.random.randint(low, high, dtype = 'int32')\n",
    "\n",
    "print(randint())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a9dfb7-5f6d-4128-867b-54e9c4e21f0b",
   "metadata": {},
   "source": [
    "## Training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a37c01-0d77-49d7-a013-feae68278c3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:     train/loss: 2.4855   valid/loss: 2.0349   train/acc: 0.4400   valid/acc: 0.5000\n"
     ]
    }
   ],
   "source": [
    "train_dataset = Dataset(\n",
    "            list(training_circuits.values()),\n",
    "            list(training_data_labels.values()),\n",
    "            batch_size=BATCH_SIZE)\n",
    "\n",
    "val_dataset = Dataset(list(test_circuits.values()), list(test_data_labels.values()), shuffle=False)\n",
    "\n",
    "trainer.fit(train_dataset, val_dataset, evaluation_step=1, logging_step=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8105d305-9a1f-45d5-93d7-e68b43221112",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
