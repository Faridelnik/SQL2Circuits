{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff3f5c12-6bd0-4a42-858a-735cd4bdae4d",
   "metadata": {},
   "source": [
    "# Circuit learning method for SQL: training and test data generation for execution time prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb82685-19fb-4da9-a0fe-fefbf0a8dcc0",
   "metadata": {},
   "source": [
    "This notebook contains the data preparation and generation for the circuit learning process. Running the this notebook produces the training and test data which can be found from the `data` folder. This code is represented for reproducibility reasons and there is no need to rerun it every time. The queries are simplified versions of Join Order Benchmark queries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "172b13b2-8c0a-4890-b0bf-224dc24270e2",
   "metadata": {},
   "source": [
    "## Import queries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "864fd848-f148-4288-9dd1-1242490856ec",
   "metadata": {},
   "source": [
    "Training and test data are stored to `data` folder in json files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2058a87c-9c7b-4a3d-8dd9-f95eb024b0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read queries from the join order benchmark\n",
    "import glob\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import psycopg2\n",
    "from pathlib import Path\n",
    "\n",
    "this_folder = os.path.abspath(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8bd6adb-d296-4206-943d-f1bc190e62d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Database credentials\n",
    "\n",
    "port = \"5432\"\n",
    "pg_db_name = \"imdb2017\"\n",
    "pg_user = \"postgres\"\n",
    "pg_pw = \"0000\"\n",
    "imdb_file_path = \"C://Users//valte//Documents//frozendata\"\n",
    "\n",
    "pg_connection = \"postgresql://\" + pg_user + \":\" + pg_pw + \"@localhost:\" + port + \"/\" + pg_db_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32d39a19-436b-4394-89d8-33faa526a006",
   "metadata": {},
   "outputs": [],
   "source": [
    "#size = \"small\"\n",
    "#size = \"medium\"\n",
    "#size = \"large\"\n",
    "size = \"main\"\n",
    "workload = \"execution_time\"\n",
    "\n",
    "path = this_folder + \"//queries//\" + workload + \"//\" + size + \"//\"\n",
    "query_path_training = glob.glob(path + \"training//[0-9]*.sql\")\n",
    "query_path_validation = glob.glob(path + \"validation//[0-9]*.sql\")\n",
    "query_path_test = glob.glob(path + \"test//[0-9]*.sql\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee6695b7-6be8-4509-98b7-5f18163ee0cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training queries is  448\n",
      "Number of validation queries is  113\n",
      "Number of test queries is  112\n"
     ]
    }
   ],
   "source": [
    "def read_queries(files):\n",
    "    queries = []\n",
    "    for i, query in enumerate(files):\n",
    "        base_name = Path(query).stem\n",
    "        f = open(query, \"r\")\n",
    "        queries.append({ 'name': base_name, 'query': f.read() })\n",
    "    return queries\n",
    "    \n",
    "training_queries = read_queries(query_path_training)\n",
    "validation_queries = read_queries(query_path_validation)\n",
    "test_queries = read_queries(query_path_test)\n",
    "        \n",
    "print(\"Number of training queries is \", len(training_queries))\n",
    "print(\"Number of validation queries is \", len(validation_queries))\n",
    "print(\"Number of test queries is \", len(test_queries))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f3d53df-b01f-41a0-8144-417504da762e",
   "metadata": {},
   "source": [
    "### Generating training and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "36ef03cb-f5ba-4cbb-9193-3c82afea9cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def genereta_data(queries, workload, ty, size):\n",
    "    connection = psycopg2.connect(user=pg_user, password=pg_pw, host=\"localhost\", port=port, database=pg_db_name)\n",
    "    cursor = connection.cursor()\n",
    "    cursor.execute(\"SET statement_timeout = 20000; COMMIT;\")\n",
    "    shots_per_query = 10\n",
    "    data = []\n",
    "    file_name = \"data//\" + workload + \"//\" + size + \"//\" + ty + \"_data.json\"\n",
    "    root_name = ty + \"_data\"\n",
    "    \n",
    "    for query in queries:\n",
    "        try:\n",
    "            total_running_time = 0.0\n",
    "            for i in range(shots_per_query):\n",
    "                cursor = connection.cursor()\n",
    "                cursor.execute(\"EXPLAIN ANALYZE \" + query['query'])\n",
    "                res = cursor.fetchall()\n",
    "                ex_time = float(re.findall(\"\\d+\\.\\d+\", res[-1][0])[0])\n",
    "                plan_time = float(re.findall(\"\\d+\\.\\d+\", res[-2][0])[0])\n",
    "                total_running_time += ex_time + plan_time\n",
    "            data.append( {'name': query['name'], 'time': round(total_running_time / shots_per_query, 4) })\n",
    "\n",
    "        except (Exception, psycopg2.Error) as error:\n",
    "            print(\"Error while fetching data from PostgreSQL\", error)\n",
    "            print(query)\n",
    "\n",
    "    if connection:\n",
    "        cursor.close()\n",
    "        connection.close()\n",
    "        print(\"PostgreSQL connection is closed\")\n",
    "        \n",
    "    with open(file_name, 'w') as outfile:\n",
    "        json.dump({ root_name: data }, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a1ad441-d28d-46f3-a3e2-2bb7089e7715",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error while fetching data from PostgreSQL canceling statement due to statement timeout\n",
      "\n",
      "{'name': '128', 'query': \"SELECT MIN(mc.note) AS production_note FROM cast_info AS ci, movie_companies AS mc WHERE mc.note NOT LIKE '%(as Metro-Goldwyn-Mayer Pictures)%' AND mc.note IS NOT NULL AND ci.movie_id = mc.movie_id;\"}\n",
      "Error while fetching data from PostgreSQL canceling statement due to statement timeout\n",
      "\n",
      "{'name': '593', 'query': \"SELECT MIN(mi.info) AS release_date FROM movie_info AS mi, cast_info AS ci WHERE mi.info IN ('Sweden', 'USA', 'German') AND ci.movie_id = mi.movie_id;\"}\n",
      "PostgreSQL connection is closed\n",
      "PostgreSQL connection is closed\n",
      "PostgreSQL connection is closed\n"
     ]
    }
   ],
   "source": [
    "genereta_data(training_queries, workload, \"training\", size)\n",
    "genereta_data(validation_queries, workload, \"validation\", size)\n",
    "genereta_data(test_queries, workload, \"test\", size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
